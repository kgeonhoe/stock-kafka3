#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
FinanceDataReader ê¸°ë°˜ ëŒ€ëŸ‰ ë°ì´í„° ìˆ˜ì§‘ê¸° (yfinance í˜¸í™˜)
- HDD ë³‘ëª© ìµœì í™”: ë°°ì¹˜ ì²˜ë¦¬, ì²´í¬í¬ì¸íŠ¸ ê´€ë¦¬
- ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±: ë°°ì¹˜ ë‹¨ìœ„ I/O, ê°€ë¹„ì§€ ì»¬ë ‰ì…˜ ê°•í™”
- yfinance í˜¸í™˜ì„±: FDR adj_closeë¥¼ ë©”ì¸ closeë¡œ ë³€í™˜í•˜ì—¬ ì‹œìŠ¤í…œ ì¼ê´€ì„± í™•ë³´
- ì´ì¤‘ ì €ì¥: yfinance í˜¸í™˜ í˜•ì‹(stock_data) + FDR ì›ë³¸(stock_data_fdr_raw)
"""
- ë°°ì¹˜ ì²˜ë¦¬ë¡œ I/O ë³‘ëª© ìµœì†Œí™”
- ë©”ëª¨ë¦¬ íš¨ìœ¨ì  ì²˜ë¦¬
"""

import pandas as pd
import FinanceDataReader as fdr
import duckdb
import os
import time
from datetime import datetime, timedelta
from typing import List, Dict, Optional, Tuple
import logging
from concurrent.futures import ThreadPoolExecutor, as_completed
import gc
import threading

class BulkDataCollector:
    """ëŒ€ëŸ‰ ë°ì´í„° ìˆ˜ì§‘ ë° ìµœì í™”ëœ ì €ì¥"""
    
    def __init__(self, db_path: str = "/data/duckdb/stock_data.db", 
                 batch_size: int = 5000, max_workers: int = 4):
        """
        ì´ˆê¸°í™”
        
        Args:
            db_path: DuckDB íŒŒì¼ ê²½ë¡œ
            batch_size: ë°°ì¹˜ í¬ê¸° (ë©”ëª¨ë¦¬ ì œí•œ ê³ ë ¤)
            max_workers: ìµœëŒ€ ì›Œì»¤ ìŠ¤ë ˆë“œ ìˆ˜
        """
        self.db_path = db_path
        self.batch_size = batch_size
        self.max_workers = max_workers
        
        # ë””ë ‰í† ë¦¬ ìƒì„±
        os.makedirs(os.path.dirname(db_path), exist_ok=True)
        
        # ë¡œê¹… ì„¤ì •
        logging.basicConfig(level=logging.INFO)
        self.logger = logging.getLogger(__name__)
        
        # ì“°ê¸° ì „ìš© ì—°ê²° (ë‹¨ì¼ ìŠ¤ë ˆë“œ)
        self._write_lock = threading.Lock()
        self._write_conn = None
        
        self._initialize_database()
    
    def _initialize_database(self):
        """ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™” ë° ìµœì í™” ì„¤ì •"""
        with self._get_write_connection() as conn:
            # ë©”ëª¨ë¦¬ ë° ì„±ëŠ¥ ìµœì í™” ì„¤ì •
            conn.execute("PRAGMA memory_limit='1GB'")  # ë©”ëª¨ë¦¬ ì œí•œ
            conn.execute("PRAGMA threads=2")           # ìŠ¤ë ˆë“œ ì œí•œ
            conn.execute("PRAGMA checkpoint_threshold='1GB'")  # ì²´í¬í¬ì¸íŠ¸ ì„ê³„ê°’
            
            # yfinance í˜¸í™˜ì„±ì„ ìœ„í•œ ë°ì´í„° êµ¬ì¡° ìƒì„±
            # âš ï¸ ì¤‘ìš”: yfinance auto_adjust=Trueì™€ ë™ì¼í•œ ìŠ¤í‚¤ë§ˆ ì‚¬ìš©
            # close = Adjusted Close (ë¶„í• /ë°°ë‹¹ ë°˜ì˜)ë¡œ ì‹œìŠ¤í…œ ì¼ê´€ì„± í™•ë³´
            
            # 1. ë©”ì¸ í…Œì´ë¸” (yfinance í˜¸í™˜ ìŠ¤í‚¤ë§ˆ)
            conn.execute("""
                CREATE TABLE IF NOT EXISTS stock_data (
                    symbol VARCHAR,
                    date DATE,
                    open DOUBLE,            -- FDR adj_open (ë¶„í• /ë°°ë‹¹ ë°˜ì˜)
                    high DOUBLE,            -- FDR adj_high (ë¶„í• /ë°°ë‹¹ ë°˜ì˜)
                    low DOUBLE,             -- FDR adj_low (ë¶„í• /ë°°ë‹¹ ë°˜ì˜)
                    close DOUBLE,           -- FDR adj_close (ë¶„í• /ë°°ë‹¹ ë°˜ì˜) = yfinance close
                    volume BIGINT,          -- FDR volume (ì›ë³¸ ìœ ì§€)
                    collected_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                )
            """)
            
            # 2. FDR ì›ë³¸ ë°ì´í„° ë³´ê´€ìš© í…Œì´ë¸” (ë¶„ì„ ì°¸ê³ ìš©)
            conn.execute("""
                CREATE TABLE IF NOT EXISTS stock_data_fdr_raw (
                    symbol VARCHAR,
                    date DATE,
                    open DOUBLE,            -- FDR ì›ë³¸ Open (ë¶„í• /ë°°ë‹¹ ë¯¸ë°˜ì˜)
                    high DOUBLE,            -- FDR ì›ë³¸ High (ë¶„í• /ë°°ë‹¹ ë¯¸ë°˜ì˜)
                    low DOUBLE,             -- FDR ì›ë³¸ Low (ë¶„í• /ë°°ë‹¹ ë¯¸ë°˜ì˜)
                    close DOUBLE,           -- FDR ì›ë³¸ Close (ë¶„í• /ë°°ë‹¹ ë¯¸ë°˜ì˜)
                    volume BIGINT,          -- FDR volume
                    adj_close DOUBLE,       -- FDR Adj Close (ë¶„í• /ë°°ë‹¹ ë°˜ì˜)
                    collected_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                )
            """)
            
            # ì¸ë±ìŠ¤ ìƒì„± (yfinance í˜¸í™˜ í…Œì´ë¸”ê³¼ FDR ì›ë³¸ í…Œì´ë¸”)
            conn.execute("""
                CREATE INDEX IF NOT EXISTS idx_stock_data_symbol_date 
                ON stock_data(symbol, date)
            """)
            
            conn.execute("""
                CREATE INDEX IF NOT EXISTS idx_stock_data_fdr_raw_symbol_date 
                ON stock_data_fdr_raw(symbol, date)
            """)
            
            self.logger.info("ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ")
    
    def _get_write_connection(self):
        """ì“°ê¸° ì „ìš© ì—°ê²° ë°˜í™˜"""
        if self._write_conn is None:
            self._write_conn = duckdb.connect(self.db_path)
        return self._write_conn
    
    def get_nasdaq_symbols(self, limit: Optional[int] = None) -> List[str]:
        """
        ë‚˜ìŠ¤ë‹¥ ì¢…ëª© ë¦¬ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸°
        
        Args:
            limit: ì œí•œí•  ì¢…ëª© ìˆ˜ (í…ŒìŠ¤íŠ¸ìš©)
        
        Returns:
            ì¢…ëª© ì‹¬ë³¼ ë¦¬ìŠ¤íŠ¸
        """
        try:
            # FinanceDataReaderë¡œ ë‚˜ìŠ¤ë‹¥ ì¢…ëª© ë¦¬ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸°
            self.logger.info("ë‚˜ìŠ¤ë‹¥ ì¢…ëª© ë¦¬ìŠ¤íŠ¸ ìˆ˜ì§‘ ì¤‘...")
            nasdaq_df = fdr.StockListing('NASDAQ')
            
            # í™œì„± ì¢…ëª©ë§Œ í•„í„°ë§ (ê±°ë˜ëŸ‰ ìˆëŠ” ì¢…ëª©)
            active_symbols = nasdaq_df['Symbol'].tolist()
            
            if limit:
                active_symbols = active_symbols[:limit]
            
            self.logger.info(f"ìˆ˜ì§‘ëœ ë‚˜ìŠ¤ë‹¥ ì¢…ëª© ìˆ˜: {len(active_symbols)}")
            return active_symbols
            
        except Exception as e:
            self.logger.error(f"ë‚˜ìŠ¤ë‹¥ ì¢…ëª© ë¦¬ìŠ¤íŠ¸ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
            return []
    
    def collect_single_symbol_data(self, symbol: str, 
                                 start_date: str = '2019-01-01',
                                 end_date: Optional[str] = None) -> Optional[pd.DataFrame]:
        """
        ë‹¨ì¼ ì¢…ëª© ë°ì´í„° ìˆ˜ì§‘
        
        Args:
            symbol: ì¢…ëª© ì‹¬ë³¼
            start_date: ì‹œì‘ ë‚ ì§œ
            end_date: ì¢…ë£Œ ë‚ ì§œ
        
        Returns:
            ë°ì´í„°í”„ë ˆì„ ë˜ëŠ” None
        """
        try:
            if end_date is None:
                end_date = datetime.now().strftime('%Y-%m-%d')
            
            # FinanceDataReaderë¡œ ë°ì´í„° ìˆ˜ì§‘
            df = fdr.DataReader(symbol, start_date, end_date)
            
            if df.empty:
                self.logger.warning(f"ì¢…ëª© {symbol}: ë°ì´í„° ì—†ìŒ")
                return None
            
            # ì¸ë±ìŠ¤ë¥¼ ë‚ ì§œ ì»¬ëŸ¼ìœ¼ë¡œ ë³€í™˜
            df = df.reset_index()
            df['symbol'] = symbol
            
            # ì»¬ëŸ¼ëª… í†µì¼ (FinanceDataReader ì»¬ëŸ¼ëª… í™•ì¸)
            if 'Date' in df.columns:
                df.rename(columns={'Date': 'date'}, inplace=True)
            elif df.index.name == 'Date' or 'date' not in df.columns:
                # ì¸ë±ìŠ¤ê°€ ë‚ ì§œì¸ ê²½ìš° ë‹¤ì‹œ ì²˜ë¦¬
                if 'date' not in df.columns:
                    df['date'] = df.index
            
            # ë‚˜ë¨¸ì§€ ì»¬ëŸ¼ëª… í†µì¼ - FDR ì‹¤ì œ ì»¬ëŸ¼ëª…ì— ë§ì¶¤
            column_mapping = {
                'Open': 'open',
                'High': 'high', 
                'Low': 'low',
                'Close': 'close',
                'Volume': 'volume',
                'Adj Close': 'adj_close'  # FDRì˜ ì‹¤ì œ ì»¬ëŸ¼ëª…
            }
            
            df.rename(columns=column_mapping, inplace=True)
            
            # yfinance í˜¸í™˜ì„±ì„ ìœ„í•œ ë°ì´í„° ë³€í™˜
            # âš ï¸ ì¤‘ìš”: FDR adj_closeë¥¼ ë©”ì¸ closeë¡œ ì‚¬ìš©í•˜ì—¬ yfinanceì™€ ì¼ê´€ì„± í™•ë³´
            
            # Adj Close ê¸°ë°˜ OHLC ì¡°ì • ê³„ì‚° (yfinanceì™€ ë™ì¼í•œ ë°©ì‹)
            if 'adj_close' in df.columns and 'close' in df.columns:
                # ì¡°ì • ë¹„ìœ¨ ê³„ì‚° (adj_close / close)
                adjustment_ratio = df['adj_close'] / df['close']
                
                # ëª¨ë“  OHLC ê°€ê²©ì„ ì¡°ì • (yfinance auto_adjust=Trueì™€ ë™ì¼í•œ ë¡œì§)
                df['raw_open'] = df['open'].copy()      # ì›ë³¸ ë³´ê´€
                df['raw_high'] = df['high'].copy()
                df['raw_low'] = df['low'].copy()
                df['raw_close'] = df['close'].copy()
                
                # Adjusted OHLC ê³„ì‚° (yfinance ë°©ì‹)
                df['open'] = df['open'] * adjustment_ratio
                df['high'] = df['high'] * adjustment_ratio  
                df['low'] = df['low'] * adjustment_ratio
                df['close'] = df['adj_close']  # close = adj_close (yfinance ë°©ì‹)
                
                self.logger.debug(f"ì¢…ëª© {symbol}: Adjusted OHLC ë³€í™˜ ì™„ë£Œ (yfinance í˜¸í™˜)")
            
            # ìµœì¢… ì»¬ëŸ¼ ì •ë¦¬
            required_columns = ['symbol', 'date', 'open', 'high', 'low', 'close', 'volume']
            yfinance_compat_df = df[required_columns]
            
            # ì›ë³¸ ë°ì´í„° ë³´ê´€ìš© (ë¶„ì„ ì°¸ê³ )
            raw_columns = ['symbol', 'date', 'raw_open', 'raw_high', 'raw_low', 'raw_close', 'volume', 'adj_close']
            if all(col in df.columns for col in ['raw_open', 'raw_high', 'raw_low', 'raw_close', 'adj_close']):
                raw_df = df[['symbol', 'date'] + [col for col in raw_columns[2:] if col in df.columns]]
                # ì»¬ëŸ¼ëª… ì •ë¦¬ (raw_ prefix ì œê±°)
                raw_df.columns = ['symbol', 'date', 'open', 'high', 'low', 'close', 'volume', 'adj_close']
            else:
                raw_df = None
            
            # ë°ì´í„° íƒ€ì… ìµœì í™” 
            yfinance_compat_df['date'] = pd.to_datetime(yfinance_compat_df['date']).dt.date
            yfinance_compat_df['volume'] = yfinance_compat_df['volume'].fillna(0).astype('int64')
            
            # NaN ì œê±°
            yfinance_compat_df = yfinance_compat_df.dropna()
            
            self.logger.info(f"ì¢…ëª© {symbol}: {len(yfinance_compat_df)}ê°œ ë ˆì½”ë“œ ìˆ˜ì§‘ (yfinance í˜¸í™˜ í˜•ì‹)")
            
            # ë‘ ê°œì˜ ë°ì´í„°í”„ë ˆì„ ë°˜í™˜: yfinance í˜¸í™˜ìš©, ì›ë³¸ ë³´ê´€ìš©
            result = {
                'yfinance_compat': yfinance_compat_df,
                'raw_data': raw_df
            }
            return result
            
        except Exception as e:
            self.logger.error(f"ì¢…ëª© {symbol} ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
            return None
    
    def bulk_insert_data(self, data_batch: List[Dict]):
        """
        yfinance í˜¸í™˜ ë°°ì¹˜ ë°ì´í„° ì‚½ì… (HDD ìµœì í™”)
        
        Args:
            data_batch: {'yfinance_compat': df, 'raw_data': df} í˜•íƒœì˜ ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸
        """
        if not data_batch:
            return
        
        try:
            # yfinance í˜¸í™˜ ë°ì´í„°ì™€ ì›ë³¸ ë°ì´í„° ë¶„ë¦¬
            yfinance_dfs = []
            raw_dfs = []
            
            for data_dict in data_batch:
                if data_dict is None:
                    continue
                    
                if 'yfinance_compat' in data_dict and data_dict['yfinance_compat'] is not None:
                    yfinance_dfs.append(data_dict['yfinance_compat'])
                
                if 'raw_data' in data_dict and data_dict['raw_data'] is not None:
                    raw_dfs.append(data_dict['raw_data'])
            
            with self._write_lock:
                with self._get_write_connection() as conn:
                    # 1. ë©”ì¸ í…Œì´ë¸”ì— yfinance í˜¸í™˜ ë°ì´í„° ì €ì¥
                    if yfinance_dfs:
                        combined_yfinance_df = pd.concat(yfinance_dfs, ignore_index=True)
                        
                        # stock_data í…Œì´ë¸” (yfinance í˜¸í™˜ ìŠ¤í‚¤ë§ˆ)ì— ì €ì¥
                        conn.execute("""
                            INSERT INTO stock_data (symbol, date, open, high, low, close, volume, collected_at)
                            SELECT symbol, date, open, high, low, close, volume, CURRENT_TIMESTAMP
                            FROM combined_yfinance_df
                        """)
                        
                        self.logger.info(f"yfinance í˜¸í™˜ ë°ì´í„° ì €ì¥: {len(combined_yfinance_df)} ë ˆì½”ë“œ")
                    
                    # 2. ì›ë³¸ ë°ì´í„° ë³´ê´€ (ì„ íƒì )
                    if raw_dfs:
                        combined_raw_df = pd.concat(raw_dfs, ignore_index=True)
                        
                        # stock_data_fdr_raw í…Œì´ë¸”ì— ì›ë³¸ ë°ì´í„° ì €ì¥
                        conn.execute("""
                            INSERT INTO stock_data_fdr_raw (symbol, date, open, high, low, close, volume, adj_close, collected_at)
                            SELECT symbol, date, open, high, low, close, volume, adj_close, CURRENT_TIMESTAMP
                            FROM combined_raw_df
                        """)
                        
                        self.logger.info(f"FDR ì›ë³¸ ë°ì´í„° ì €ì¥: {len(combined_raw_df)} ë ˆì½”ë“œ")
                    
                    # ì£¼ê¸°ì  ì²´í¬í¬ì¸íŠ¸ (WAL flush)
                    conn.execute("CHECKPOINT")
                    
            self.logger.info("ë°°ì¹˜ ì‚½ì… ì™„ë£Œ (yfinance í˜¸í™˜ + ì›ë³¸ ë°ì´í„° ë³´ê´€)")
            
            # ë©”ëª¨ë¦¬ ì •ë¦¬ ê°•í™”
            if 'combined_yfinance_df' in locals():
                del combined_yfinance_df
            if 'combined_raw_df' in locals():
                del combined_raw_df
            gc.collect()
            
        except Exception as e:
            self.logger.error(f"ë°°ì¹˜ ì‚½ì… ì‹¤íŒ¨: {e}")
            raise
    
    def collect_bulk_data(self, symbols: List[str], 
                         start_date: str = '2019-01-01',
                         batch_symbols: int = 50) -> bool:
        """
        ëŒ€ëŸ‰ ë°ì´í„° ìˆ˜ì§‘ (ë³‘ë ¬ ì²˜ë¦¬ + ë°°ì¹˜ ì €ì¥)
        
        Args:
            symbols: ì¢…ëª© ë¦¬ìŠ¤íŠ¸
            start_date: ì‹œì‘ ë‚ ì§œ
            batch_symbols: ë°°ì¹˜ ì²˜ë¦¬í•  ì¢…ëª© ìˆ˜
        
        Returns:
            ì„±ê³µ ì—¬ë¶€
        """
        total_symbols = len(symbols)
        processed_count = 0
        failed_count = 0
        
        self.logger.info(f"ëŒ€ëŸ‰ ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘: {total_symbols}ê°œ ì¢…ëª©")
        
        try:
            # ì¢…ëª©ì„ ë°°ì¹˜ë¡œ ë‚˜ëˆ„ì–´ ì²˜ë¦¬
            for i in range(0, total_symbols, batch_symbols):
                batch_symbols_list = symbols[i:i + batch_symbols]
                self.logger.info(f"ë°°ì¹˜ {i//batch_symbols + 1} ì²˜ë¦¬ ì¤‘: {len(batch_symbols_list)}ê°œ ì¢…ëª©")
                
                # ë³‘ë ¬ ë°ì´í„° ìˆ˜ì§‘
                data_batch = []
                
                with ThreadPoolExecutor(max_workers=self.max_workers) as executor:
                    # ì‘ì—… ì œì¶œ
                    future_to_symbol = {
                        executor.submit(
                            self.collect_single_symbol_data, 
                            symbol, 
                            start_date
                        ): symbol 
                        for symbol in batch_symbols_list
                    }
                    
                    # ê²°ê³¼ ìˆ˜ì§‘
                    for future in as_completed(future_to_symbol):
                        symbol = future_to_symbol[future]
                        try:
                            df = future.result(timeout=60)  # 60ì´ˆ íƒ€ì„ì•„ì›ƒ
                            if df is not None:
                                data_batch.append(df)
                                processed_count += 1
                            else:
                                failed_count += 1
                                
                        except Exception as e:
                            self.logger.error(f"ì¢…ëª© {symbol} ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
                            failed_count += 1
                
                # ë°°ì¹˜ ë°ì´í„° ì €ì¥
                if data_batch:
                    self.bulk_insert_data(data_batch)
                
                # ì§„í–‰ë¥  ì¶œë ¥
                progress = (i + len(batch_symbols_list)) / total_symbols * 100
                self.logger.info(f"ì§„í–‰ë¥ : {progress:.1f}% ({processed_count} ì„±ê³µ, {failed_count} ì‹¤íŒ¨)")
                
                # ë©”ëª¨ë¦¬ ì •ë¦¬
                del data_batch
                gc.collect()
                
                # HDD ë¶€í•˜ ë°©ì§€ë¥¼ ìœ„í•œ íœ´ì‹
                time.sleep(1)
            
            self.logger.info(f"ëŒ€ëŸ‰ ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ: {processed_count} ì„±ê³µ, {failed_count} ì‹¤íŒ¨")
            return True
            
        except Exception as e:
            self.logger.error(f"ëŒ€ëŸ‰ ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
            return False
    
    def optimize_database(self):
        """ë°ì´í„°ë² ì´ìŠ¤ ìµœì í™” (ìˆ˜ì§‘ ì™„ë£Œ í›„) - yfinance í˜¸í™˜ êµ¬ì¡°"""
        try:
            with self._write_lock:
                with self._get_write_connection() as conn:
                    self.logger.info("ë°ì´í„°ë² ì´ìŠ¤ ìµœì í™” ì‹œì‘...")
                    
                    # 1. ìµœì¢… ì²´í¬í¬ì¸íŠ¸
                    conn.execute("CHECKPOINT")
                    
                    # 2. í†µê³„ ì—…ë°ì´íŠ¸ (yfinance í˜¸í™˜ í…Œì´ë¸”ê³¼ ì›ë³¸ í…Œì´ë¸”)
                    conn.execute("ANALYZE stock_data")
                    conn.execute("ANALYZE stock_data_fdr_raw")
                    
                    # 3. ì¤‘ë³µ ì œê±° (yfinance í˜¸í™˜ í…Œì´ë¸”)
                    conn.execute("""
                        CREATE TABLE stock_data_clean AS 
                        SELECT DISTINCT symbol, date, open, high, low, close, volume, 
                               MIN(collected_at) as collected_at
                        FROM stock_data
                        GROUP BY symbol, date, open, high, low, close, volume
                    """)
                    
                    # 4. ì›ë³¸ í…Œì´ë¸” êµì²´
                    conn.execute("DROP TABLE stock_data")
                    conn.execute("ALTER TABLE stock_data_clean RENAME TO stock_data")
                    
                    # 5. ì¸ë±ìŠ¤ ì¬ìƒì„± (yfinance í˜¸í™˜ í…Œì´ë¸”)
                    conn.execute("""
                        CREATE INDEX idx_stock_data_symbol_date 
                        ON stock_data(symbol, date)
                    """)
                    
                    # 6. ì›ë³¸ ë°ì´í„° í…Œì´ë¸” ì¤‘ë³µ ì œê±° (ì„ íƒì )
                    try:
                        conn.execute("""
                            CREATE TABLE stock_data_fdr_raw_clean AS 
                            SELECT DISTINCT symbol, date, open, high, low, close, volume, adj_close,
                                   MIN(collected_at) as collected_at
                            FROM stock_data_fdr_raw
                            GROUP BY symbol, date, open, high, low, close, volume, adj_close
                        """)
                        
                        conn.execute("DROP TABLE stock_data_fdr_raw")
                        conn.execute("ALTER TABLE stock_data_fdr_raw_clean RENAME TO stock_data_fdr_raw")
                        
                        conn.execute("""
                            CREATE INDEX idx_stock_data_fdr_raw_symbol_date 
                            ON stock_data_fdr_raw(symbol, date)
                        """)
                    except Exception as e:
                        self.logger.warning(f"ì›ë³¸ ë°ì´í„° í…Œì´ë¸” ìµœì í™” ê±´ë„ˆëœ€: {e}")
                    
                    self.logger.info("ë°ì´í„°ë² ì´ìŠ¤ ìµœì í™” ì™„ë£Œ (yfinance í˜¸í™˜ + FDR ì›ë³¸)")
                    
        except Exception as e:
            self.logger.error(f"ë°ì´í„°ë² ì´ìŠ¤ ìµœì í™” ì‹¤íŒ¨: {e}")
    
    def get_collection_stats(self) -> Dict:
        """ìˆ˜ì§‘ í†µê³„ ì¡°íšŒ - yfinance í˜¸í™˜ êµ¬ì¡° ê¸°ì¤€"""
        try:
            with duckdb.connect(self.db_path) as conn:
                # yfinance í˜¸í™˜ í…Œì´ë¸” ê¸°ì¤€ í†µê³„
                symbol_count = conn.execute("""
                    SELECT COUNT(DISTINCT symbol) FROM stock_data
                """).fetchone()[0]
                
                total_records = conn.execute("""
                    SELECT COUNT(*) FROM stock_data
                """).fetchone()[0]
                
                date_range = conn.execute("""
                    SELECT MIN(date), MAX(date) FROM stock_data
                """).fetchone()
                
                # ìµœê·¼ ìˆ˜ì§‘ ì‹œê°„
                last_collection = conn.execute("""
                    SELECT MAX(collected_at) FROM stock_data
                """).fetchone()[0]
                
                # FDR ì›ë³¸ ë°ì´í„° í†µê³„ (ìˆëŠ” ê²½ìš°)
                fdr_stats = {}
                try:
                    fdr_records = conn.execute("""
                        SELECT COUNT(*) FROM stock_data_fdr_raw
                    """).fetchone()[0]
                    fdr_stats = {'fdr_raw_records': fdr_records}
                except:
                    fdr_stats = {'fdr_raw_records': 0}
                
                return {
                    'symbols': symbol_count,
                    'total_records': total_records,
                    'date_range': {
                        'start': date_range[0],
                        'end': date_range[1]
                    },
                    'last_collection': last_collection,
                    'data_type': 'yfinance_compatible',
                    **fdr_stats
                }
                
        except Exception as e:
            self.logger.error(f"í†µê³„ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return {}
    
    def close(self):
        """ì—°ê²° ì •ë¦¬"""
        if self._write_conn:
            self._write_conn.close()
            self._write_conn = None


# ì‚¬ìš© ì˜ˆì‹œ ë° í…ŒìŠ¤íŠ¸ - yfinance í˜¸í™˜ ë°©ì‹
if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    collector = BulkDataCollector(
        db_path="/tmp/test_stock_yfinance_compat.db",
        batch_size=1000,
        max_workers=2
    )
    
    try:
        print("ğŸ”§ yfinance í˜¸í™˜ FDR ëŒ€ëŸ‰ ìˆ˜ì§‘ê¸° í…ŒìŠ¤íŠ¸ ì‹œì‘")
        
        # ì†ŒëŸ‰ í…ŒìŠ¤íŠ¸ (ìƒìœ„ 10ê°œ ì¢…ëª©)
        symbols = collector.get_nasdaq_symbols(limit=10)
        
        if symbols:
            print(f"ğŸ“Š í…ŒìŠ¤íŠ¸ ì¢…ëª©: {symbols}")
            
            success = collector.collect_bulk_data(
                symbols=symbols,
                start_date='2022-01-01',
                batch_symbols=5
            )
            
            if success:
                print("ğŸ”§ ë°ì´í„°ë² ì´ìŠ¤ ìµœì í™” ì¤‘...")
                collector.optimize_database()
                
                stats = collector.get_collection_stats()
                print(f"ğŸ“ˆ ìˆ˜ì§‘ í†µê³„: {stats}")
                print("âœ… yfinance í˜¸í™˜ FDR ìˆ˜ì§‘ í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
            else:
                print("âŒ ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨")
        else:
            print("âŒ ì¢…ëª© ë¦¬ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨")
    
    finally:
        collector.close()
