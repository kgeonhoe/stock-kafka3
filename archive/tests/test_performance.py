#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import time
import random
from datetime import datetime, timedelta
import sys
import os

# í˜„ì¬ ë””ë ‰í† ë¦¬ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
sys.path.append('/home/grey1/stock-kafka3')
sys.path.append('/home/grey1/stock-kafka3/common')

from common.db_sharding import DBShardManager
from common.database import DuckDBManager

def generate_test_data(symbol: str, days: int = 100) -> list:
    """í…ŒìŠ¤íŠ¸ìš© ì£¼ì‹ ë°ì´í„° ìƒì„±"""
    data = []
    base_date = datetime.now() - timedelta(days=days)
    base_price = random.uniform(50, 300)
    
    for i in range(days):
        # ëœë¤ ê°€ê²© ë³€ë™ (-5% ~ +5%)
        change = random.uniform(-0.05, 0.05)
        base_price *= (1 + change)
        
        stock_data = {
            'symbol': symbol,
            'date': (base_date + timedelta(days=i)).date(),
            'open': round(base_price * random.uniform(0.98, 1.02), 2),
            'high': round(base_price * random.uniform(1.00, 1.05), 2),
            'low': round(base_price * random.uniform(0.95, 1.00), 2),
            'close': round(base_price, 2),
            'volume': random.randint(100000, 10000000)
        }
        data.append(stock_data)
    
    return data

def test_single_db_performance(symbols: list, days_per_symbol: int = 100):
    """ë‹¨ì¼ DB ì„±ëŠ¥ í…ŒìŠ¤íŠ¸"""
    print(f"ğŸ” ë‹¨ì¼ DB ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ({len(symbols)}ê°œ ì¢…ëª©, {days_per_symbol}ì¼)")
    
    # ë‹¨ì¼ DB ë§¤ë‹ˆì € ìƒì„±
    db_manager = DuckDBManager("/tmp/single_test.db")
    
    start_time = time.time()
    total_records = 0
    
    for i, symbol in enumerate(symbols):
        symbol_start = time.time()
        
        # í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„±
        test_data = generate_test_data(symbol, days_per_symbol)
        
        # ë°°ì¹˜ ì €ì¥
        saved_count = db_manager.save_stock_data_batch(test_data)
        total_records += saved_count
        
        symbol_end = time.time()
        symbol_duration = symbol_end - symbol_start
        
        if (i + 1) % 10 == 0:  # 10ê°œë§ˆë‹¤ ì§„í–‰ìƒí™© ì¶œë ¥
            print(f"  ğŸ“Š {i+1}/{len(symbols)} ì™„ë£Œ - {symbol}: {saved_count}ê°œ ì €ì¥ ({symbol_duration:.2f}ì´ˆ)")
    
    total_time = time.time() - start_time
    
    print(f"âœ… ë‹¨ì¼ DB ì™„ë£Œ: {total_records}ê°œ ë ˆì½”ë“œ, {total_time:.2f}ì´ˆ")
    print(f"  - í‰ê·  ì¢…ëª©ë‹¹: {total_time/len(symbols):.3f}ì´ˆ")
    print(f"  - í‰ê·  ë ˆì½”ë“œë‹¹: {total_time/total_records:.6f}ì´ˆ")
    
    # ì •ë¦¬
    try:
        db_manager.close()
        os.remove("/tmp/single_test.db")
    except:
        pass
    
    return total_time, total_records

def test_sharded_db_performance(symbols: list, days_per_symbol: int = 100):
    """ìƒ¤ë”© DB ì„±ëŠ¥ í…ŒìŠ¤íŠ¸"""
    print(f"ğŸ” ìƒ¤ë”© DB ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ({len(symbols)}ê°œ ì¢…ëª©, {days_per_symbol}ì¼)")
    
    # ìƒ¤ë“œ ë§¤ë‹ˆì € ìƒì„±
    shard_manager = DBShardManager("/tmp/shard_test")
    
    start_time = time.time()
    total_records = 0
    
    for i, symbol in enumerate(symbols):
        symbol_start = time.time()
        
        # í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„±
        test_data = generate_test_data(symbol, days_per_symbol)
        
        # ë°°ì¹˜ ì €ì¥ (ìƒ¤ë”©)
        saved_count = shard_manager.save_stock_data_batch_sharded(test_data)
        total_records += saved_count
        
        symbol_end = time.time()
        symbol_duration = symbol_end - symbol_start
        
        if (i + 1) % 10 == 0:  # 10ê°œë§ˆë‹¤ ì§„í–‰ìƒí™© ì¶œë ¥
            shard_num = shard_manager.get_shard_number(symbol)
            print(f"  ğŸ“Š {i+1}/{len(symbols)} ì™„ë£Œ - {symbol} (ìƒ¤ë“œ {shard_num}): {saved_count}ê°œ ì €ì¥ ({symbol_duration:.2f}ì´ˆ)")
    
    total_time = time.time() - start_time
    
    print(f"âœ… ìƒ¤ë”© DB ì™„ë£Œ: {total_records}ê°œ ë ˆì½”ë“œ, {total_time:.2f}ì´ˆ")
    print(f"  - í‰ê·  ì¢…ëª©ë‹¹: {total_time/len(symbols):.3f}ì´ˆ")
    print(f"  - í‰ê·  ë ˆì½”ë“œë‹¹: {total_time/total_records:.6f}ì´ˆ")
    
    # ìƒ¤ë“œ í†µê³„ ì¶œë ¥
    print("\nğŸ“ˆ ìƒ¤ë“œë³„ í†µê³„:")
    stats = shard_manager.get_shard_statistics()
    for shard_name, stat in stats.items():
        if 'error' not in stat:
            print(f"  {shard_name}: {stat['symbol_count']}ê°œ ì¢…ëª©, {stat['record_count']}ê°œ ë ˆì½”ë“œ")
    
    # ì •ë¦¬
    shard_manager.close_all()
    import shutil
    try:
        shutil.rmtree("/tmp/shard_test")
    except:
        pass
    
    return total_time, total_records

def test_hash_distribution_large():
    """ëŒ€ëŸ‰ ì¢…ëª©ìœ¼ë¡œ í•´ì‹œ ë¶„ì‚° í…ŒìŠ¤íŠ¸"""
    print("ğŸ” ëŒ€ëŸ‰ ì¢…ëª© í•´ì‹œ ë¶„ì‚° í…ŒìŠ¤íŠ¸")
    
    # 7000+ ì¢…ëª© ì‹œë®¬ë ˆì´ì…˜ (ì‹¤ì œ ë‚˜ìŠ¤ë‹¥ ë¹„ìŠ·í•œ ê·œëª¨)
    test_symbols = []
    
    # ì‹¤ì œ í˜•íƒœì˜ ì¢…ëª© ì½”ë“œ ìƒì„±
    for i in range(7000):
        if i < 1000:
            # Aë¡œ ì‹œì‘í•˜ëŠ” ì¢…ëª©ë“¤
            symbol = f"A{chr(65 + (i % 26))}{chr(65 + ((i // 26) % 26))}{i%10}"
        elif i < 2000:
            # Bë¡œ ì‹œì‘í•˜ëŠ” ì¢…ëª©ë“¤
            symbol = f"B{chr(65 + (i % 26))}{chr(65 + ((i // 26) % 26))}{i%10}"
        elif i < 3000:
            # Cë¡œ ì‹œì‘í•˜ëŠ” ì¢…ëª©ë“¤
            symbol = f"C{chr(65 + (i % 26))}{chr(65 + ((i // 26) % 26))}{i%10}"
        else:
            # ê¸°íƒ€ ëœë¤ ì¢…ëª©ë“¤
            symbol = f"{chr(65 + (i % 26))}{chr(65 + ((i // 26) % 26))}{chr(65 + ((i // 676) % 26))}{i%10}"
        
        test_symbols.append(symbol)
    
    # ìƒ¤ë“œ ë§¤ë‹ˆì €ë¡œ ë¶„ì‚° í…ŒìŠ¤íŠ¸
    shard_manager = DBShardManager("/tmp/hash_test")
    distribution = shard_manager.test_hash_distribution(test_symbols)
    
    # ë¶„ì‚° í’ˆì§ˆ ë¶„ì„
    total_symbols = len(test_symbols)
    expected_per_shard = total_symbols / 5
    max_deviation = 0
    
    print(f"\nğŸ“Š ë¶„ì‚° í’ˆì§ˆ ë¶„ì„:")
    print(f"  ì´ ì¢…ëª© ìˆ˜: {total_symbols}ê°œ")
    print(f"  ìƒ¤ë“œë‹¹ ì˜ˆìƒ: {expected_per_shard:.1f}ê°œ")
    
    for shard_num, count in distribution.items():
        deviation = abs(count - expected_per_shard)
        deviation_percent = (deviation / expected_per_shard) * 100
        max_deviation = max(max_deviation, deviation_percent)
        
        print(f"  ìƒ¤ë“œ {shard_num}: {count}ê°œ (í¸ì°¨: {deviation_percent:.1f}%)")
    
    print(f"  ìµœëŒ€ í¸ì°¨: {max_deviation:.1f}%")
    
    if max_deviation < 5:
        print("âœ… ìš°ìˆ˜í•œ ë¶„ì‚° í’ˆì§ˆ (í¸ì°¨ < 5%)")
    elif max_deviation < 10:
        print("âš ï¸ ì–‘í˜¸í•œ ë¶„ì‚° í’ˆì§ˆ (í¸ì°¨ < 10%)")
    else:
        print("âŒ ë¶„ì‚° í’ˆì§ˆ ê°œì„  í•„ìš” (í¸ì°¨ >= 10%)")
    
    return distribution

def run_performance_comparison():
    """ì„±ëŠ¥ ë¹„êµ í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    print("ğŸš€ DB ì„±ëŠ¥ ë¹„êµ í…ŒìŠ¤íŠ¸ ì‹œì‘")
    print("=" * 60)
    
    # í…ŒìŠ¤íŠ¸ ì„¤ì •
    test_symbols = [
        'AAPL', 'MSFT', 'GOOGL', 'AMZN', 'TSLA', 'NVDA', 'META', 'NFLX', 'ADBE', 'CRM',
        'ORCL', 'CSCO', 'INTC', 'IBM', 'HPQ', 'DELL', 'VMW', 'CRM', 'NOW', 'WDAY',
        'OKTA', 'ZM', 'TEAM', 'ATLR', 'MDB', 'SNOW', 'DDOG', 'CRWD', 'NET', 'FSLY'
    ]
    days_per_symbol = 200  # ì•½ 8ê°œì›” ë°ì´í„°
    
    print(f"í…ŒìŠ¤íŠ¸ ì¡°ê±´: {len(test_symbols)}ê°œ ì¢…ëª©, ì¢…ëª©ë‹¹ {days_per_symbol}ì¼ ë°ì´í„°")
    print("=" * 60)
    
    # 1. í•´ì‹œ ë¶„ì‚° í…ŒìŠ¤íŠ¸
    test_hash_distribution_large()
    print("=" * 60)
    
    # 2. ë‹¨ì¼ DB ì„±ëŠ¥ í…ŒìŠ¤íŠ¸
    single_time, single_records = test_single_db_performance(test_symbols, days_per_symbol)
    print("=" * 60)
    
    # 3. ìƒ¤ë”© DB ì„±ëŠ¥ í…ŒìŠ¤íŠ¸
    shard_time, shard_records = test_sharded_db_performance(test_symbols, days_per_symbol)
    print("=" * 60)
    
    # 4. ê²°ê³¼ ë¹„êµ
    print("ğŸ“Š ì„±ëŠ¥ ë¹„êµ ê²°ê³¼:")
    print(f"  ë‹¨ì¼ DB: {single_time:.2f}ì´ˆ ({single_records}ê°œ ë ˆì½”ë“œ)")
    print(f"  ìƒ¤ë”© DB: {shard_time:.2f}ì´ˆ ({shard_records}ê°œ ë ˆì½”ë“œ)")
    
    if shard_time < single_time:
        improvement = ((single_time - shard_time) / single_time) * 100
        print(f"  ğŸ‰ ìƒ¤ë”©ì´ {improvement:.1f}% ë” ë¹ ë¦„!")
    else:
        degradation = ((shard_time - single_time) / single_time) * 100
        print(f"  âš ï¸ ìƒ¤ë”©ì´ {degradation:.1f}% ë” ëŠë¦¼")
    
    print("=" * 60)
    print("âœ… ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì™„ë£Œ")

if __name__ == "__main__":
    run_performance_comparison()
