#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
Enhanced NASDAQ Bulk Data Collection DAG - PostgreSQL Version
ÎåÄÎüâ NASDAQ Îç∞Ïù¥ÌÑ∞ ÏàòÏßë Î∞è Ï≤òÎ¶¨ ÌååÏù¥ÌîÑÎùºÏù∏
"""

import os
import sys
from datetime import datetime, timedelta, date
from typing import List, Dict, Any

from airflow import DAG
from airflow.operators.python import PythonOperator
from airflow.operators.bash import BashOperator
from airflow.models import Variable
from airflow.utils.dates import days_ago

# Í∏∞Î≥∏ ÏÑ§Ï†ï
default_args = {
    'owner': 'stock-pipeline',
    'depends_on_past': False,
    'email_on_failure': False,
    'email_on_retry': False,
    'retries': 2,
    'retry_delay': timedelta(minutes=10),
    'start_date': days_ago(1),
}

# DAG Ï†ïÏùò
dag = DAG(
    'enhanced_nasdaq_bulk_collection_postgres',
    default_args=default_args,
    description='NASDAQ Ï†ÑÏ≤¥ Îç∞Ïù¥ÌÑ∞ ÏàòÏßë (Ï£ºÏãùÎ∂ÑÌï†/Î∞∞Îãπ ÎåÄÏùë, PostgreSQL)',
    schedule_interval='0 7 * * *',  # ÌèâÏùº Ïò§Ï†Ñ 7Ïãú Ïã§Ìñâ (daily bulk collection)
    catchup=False,
    max_active_runs=1,
    tags=['nasdaq', 'bulk-collection', 'postgresql', 'stock-data']
)

def collect_nasdaq_symbols_task(**kwargs):
    """NASDAQ Ïã¨Î≥º ÎåÄÎüâ ÏàòÏßë"""
    import sys
    sys.path.insert(0, '/opt/airflow/common')
    
    from database import PostgreSQLManager
    from bulk_data_collector import BulkDataCollector
    
    print("üöÄ NASDAQ Ïã¨Î≥º ÎåÄÎüâ ÏàòÏßë ÏãúÏûë...")
    
    try:
        # PostgreSQL Ïó∞Í≤∞
        db = PostgreSQLManager()
        print("‚úÖ PostgreSQL Ïó∞Í≤∞ ÏÑ±Í≥µ")
        
        # Ïò§Îäò Ïù¥ÎØ∏ ÏàòÏßëÎêòÏóàÎäîÏßÄ ÌôïÏù∏
        if db.is_nasdaq_symbols_collected_today():
            print("üìÖ Ïò§Îäò Ïù¥ÎØ∏ NASDAQ Ïã¨Î≥ºÏù¥ ÏàòÏßëÎêòÏóàÏäµÎãàÎã§.")
            return {"status": "already_collected", "count": 0}
        
        # ÎåÄÎüâ ÏàòÏßëÍ∏∞ Ï¥àÍ∏∞Ìôî (FinanceDataReader ÏÇ¨Ïö©ÏúºÎ°ú Î∞∞Ïπò ÌÅ¨Í∏∞ Ï¶ùÍ∞Ä Í∞ÄÎä•)
        collector = BulkDataCollector(batch_size=200, max_workers=4)
        
        # NASDAQ Ïã¨Î≥º ÏàòÏßë
        symbols_count = collector.collect_nasdaq_symbols()
        
        if symbols_count > 0:
            print(f"‚úÖ NASDAQ Ïã¨Î≥º ÏàòÏßë ÏôÑÎ£å: {symbols_count:,}Í∞ú")
            return {"status": "success", "count": symbols_count}
        else:
            print("‚ö†Ô∏è ÏàòÏßëÎêú Ïã¨Î≥ºÏù¥ ÏóÜÏäµÎãàÎã§.")
            return {"status": "no_data", "count": 0}
            
    except Exception as e:
        print(f"‚ùå NASDAQ Ïã¨Î≥º ÏàòÏßë Ïã§Ìå®: {e}")
        import traceback
        traceback.print_exc()
        raise
    finally:
        if 'db' in locals():
            db.close()
        if 'collector' in locals():
            collector.close()

def bulk_collect_stock_data_task(**kwargs):
    """Ï£ºÍ∞Ä Îç∞Ïù¥ÌÑ∞ ÎåÄÎüâ ÏàòÏßë"""
    import sys
    sys.path.insert(0, '/opt/airflow/common')
    
    from database import PostgreSQLManager
    from bulk_data_collector import BulkDataCollector
    
    print("üöÄ Ï£ºÍ∞Ä Îç∞Ïù¥ÌÑ∞ ÎåÄÎüâ ÏàòÏßë ÏãúÏûë...")
    
    try:
        # PostgreSQL Ïó∞Í≤∞
        db = PostgreSQLManager()
        print("‚úÖ PostgreSQL Ïó∞Í≤∞ ÏÑ±Í≥µ")
        
        # ÌôúÏÑ± Ïã¨Î≥º Ï°∞Ìöå (Ï†ÑÏ≤¥)
        symbols = db.get_active_symbols()  # Ï†ÑÏ≤¥ ÎÇòÏä§Îã• Ïã¨Î≥º ÏàòÏßë
        print(f"üìä ÏàòÏßë ÎåÄÏÉÅ Ïã¨Î≥º: {len(symbols):,}Í∞ú")
        
        if not symbols:
            print("‚ö†Ô∏è ÏàòÏßëÌï† Ïã¨Î≥ºÏù¥ ÏóÜÏäµÎãàÎã§.")
            return {"status": "no_symbols", "success": 0, "failed": 0}
        
        # ÎåÄÎüâ ÏàòÏßëÍ∏∞ Ï¥àÍ∏∞Ìôî (FinanceDataReader ÏÇ¨Ïö©ÏúºÎ°ú Î∞∞Ïπò ÌÅ¨Í∏∞ Ï¶ùÍ∞Ä Í∞ÄÎä•)
        collector = BulkDataCollector(batch_size=50, max_workers=4)
        
        # Î∞∞Ïπò Ï£ºÍ∞Ä Îç∞Ïù¥ÌÑ∞ ÏàòÏßë (Í≥ºÍ±∞ 5ÎÖÑ Îç∞Ïù¥ÌÑ∞ - FinanceDataReader ÏÇ¨Ïö©)
        success_count, fail_count = collector.collect_stock_data_batch(
            symbols=symbols, 
            days_back=1825  # 5ÎÖÑ * 365Ïùº
        )
        
        print(f"‚úÖ Ï£ºÍ∞Ä Îç∞Ïù¥ÌÑ∞ ÏàòÏßë ÏôÑÎ£å:")
        print(f"  - ÏÑ±Í≥µ: {success_count:,}Í∞ú")
        print(f"  - Ïã§Ìå®: {fail_count:,}Í∞ú")
        print(f"  - ÏÑ±Í≥µÎ•†: {(success_count/(success_count+fail_count)*100):.1f}%")
        
        return {
            "status": "completed",
            "success": success_count,
            "failed": fail_count,
            "total": len(symbols)
        }
        
    except Exception as e:
        print(f"‚ùå Ï£ºÍ∞Ä Îç∞Ïù¥ÌÑ∞ ÏàòÏßë Ïã§Ìå®: {e}")
        import traceback
        traceback.print_exc()
        raise
    finally:
        if 'db' in locals():
            db.close()
        if 'collector' in locals():
            collector.close()

def calculate_technical_indicators_task(**kwargs):
    """Í∏∞Ïà†Ï†Å ÏßÄÌëú ÎåÄÎüâ Í≥ÑÏÇ∞"""
    import sys
    sys.path.insert(0, '/opt/airflow/common')
    
    from database import PostgreSQLManager
    from technical_indicator_calculator_postgres import TechnicalIndicatorCalculatorPostgreSQL
    
    print("üöÄ Í∏∞Ïà†Ï†Å ÏßÄÌëú ÎåÄÎüâ Í≥ÑÏÇ∞ ÏãúÏûë...")
    
    try:
        # PostgreSQL Ïó∞Í≤∞
        db = PostgreSQLManager()
        print("‚úÖ PostgreSQL Ïó∞Í≤∞ ÏÑ±Í≥µ")
        
        # Îç∞Ïù¥ÌÑ∞Í∞Ä ÏûàÎäî Ïã¨Î≥º Ï°∞Ìöå
        query = """
            SELECT DISTINCT symbol 
            FROM stock_data 
            WHERE date >= CURRENT_DATE - INTERVAL '7 days'
            ORDER BY symbol
            LIMIT 200
        """
        
        with db.get_connection() as conn:
            with conn.cursor() as cur:
                cur.execute(query)
                symbols = [row[0] for row in cur.fetchall()]
        
        print(f"üìä Í≥ÑÏÇ∞ ÎåÄÏÉÅ Ïã¨Î≥º: {len(symbols):,}Í∞ú")
        
        if not symbols:
            print("‚ö†Ô∏è Í≥ÑÏÇ∞Ìï† Ïã¨Î≥ºÏù¥ ÏóÜÏäµÎãàÎã§.")
            return {"status": "no_symbols", "calculated": 0}
        
        # Í∏∞Ïà†Ï†Å ÏßÄÌëú Í≥ÑÏÇ∞Í∏∞ Ï¥àÍ∏∞Ìôî
        calculator = TechnicalIndicatorCalculatorPostgreSQL()
        
        calculated_count = 0
        for i, symbol in enumerate(symbols):
            try:
                # ÏµúÍ∑º 60Ïùº Îç∞Ïù¥ÌÑ∞ Ï°∞Ìöå
                stock_data = db.get_stock_data(symbol, days=60)
                
                if stock_data and len(stock_data) >= 20:
                    # Í∏∞Ïà†Ï†Å ÏßÄÌëú Í≥ÑÏÇ∞
                    indicators = calculator.calculate_all_indicators(stock_data)
                    
                    # Î∞∞Ïπò Ï†ÄÏû•
                    if indicators:
                        saved_count = calculator.save_indicators_batch(indicators)
                        if saved_count > 0:
                            calculated_count += 1
                    
                    if (i + 1) % 50 == 0:
                        print(f"üìà ÏßÑÌñâÎ•†: {i+1}/{len(symbols)} ({((i+1)/len(symbols)*100):.1f}%)")
                
            except Exception as e:
                print(f"‚ö†Ô∏è {symbol}: Í∏∞Ïà†Ï†Å ÏßÄÌëú Í≥ÑÏÇ∞ Ïò§Î•ò - {e}")
        
        print(f"‚úÖ Í∏∞Ïà†Ï†Å ÏßÄÌëú Í≥ÑÏÇ∞ ÏôÑÎ£å: {calculated_count:,}Í∞ú")
        
        return {
            "status": "completed",
            "calculated": calculated_count,
            "total": len(symbols)
        }
        
    except Exception as e:
        print(f"‚ùå Í∏∞Ïà†Ï†Å ÏßÄÌëú Í≥ÑÏÇ∞ Ïã§Ìå®: {e}")
        import traceback
        traceback.print_exc()
        raise
    finally:
        if 'db' in locals():
            db.close()

def generate_daily_watchlist_task(**kwargs):
    """ÏùºÏùº Í¥ÄÏã¨Ï¢ÖÎ™© ÏÉùÏÑ±"""
    import sys
    sys.path.insert(0, '/opt/airflow/common')
    
    from database import PostgreSQLManager
    from datetime import date
    
    print("üöÄ ÏùºÏùº Í¥ÄÏã¨Ï¢ÖÎ™© ÏÉùÏÑ± ÏãúÏûë...")
    
    try:
        # PostgreSQL Ïó∞Í≤∞
        db = PostgreSQLManager()
        print("‚úÖ PostgreSQL Ïó∞Í≤∞ ÏÑ±Í≥µ")
        
        today = date.today()
        watchlist_conditions = [
            {
                'name': 'bollinger_upper_touch',
                'query': """
                    SELECT DISTINCT s.symbol, s.close, t.bb_upper, t.bb_middle, t.bb_lower
                    FROM stock_data s
                    JOIN stock_data_technical_indicators t ON s.symbol = t.symbol AND s.date = t.date
                    WHERE s.date = CURRENT_DATE - INTERVAL '1 day'
                      AND s.close >= t.bb_upper * 0.99
                      AND t.bb_upper IS NOT NULL
                    ORDER BY s.symbol
                    LIMIT 50
                """
            },
            {
                'name': 'rsi_oversold',
                'query': """
                    SELECT DISTINCT s.symbol, s.close, t.rsi
                    FROM stock_data s
                    JOIN stock_data_technical_indicators t ON s.symbol = t.symbol AND s.date = t.date
                    WHERE s.date = CURRENT_DATE - INTERVAL '1 day'
                      AND t.rsi <= 30
                      AND t.rsi IS NOT NULL
                    ORDER BY s.symbol
                    LIMIT 30
                """
            },
            {
                'name': 'volume_spike',
                'query': """
                    SELECT DISTINCT s1.symbol, s1.close, s1.volume,
                           AVG(s2.volume) as avg_volume
                    FROM stock_data s1
                    JOIN stock_data s2 ON s1.symbol = s2.symbol 
                        AND s2.date BETWEEN s1.date - INTERVAL '20 days' AND s1.date - INTERVAL '1 day'
                    WHERE s1.date = CURRENT_DATE - INTERVAL '1 day'
                    GROUP BY s1.symbol, s1.close, s1.volume
                    HAVING s1.volume > AVG(s2.volume) * 2
                    ORDER BY s1.symbol
                    LIMIT 30
                """
            }
        ]
        
        total_added = 0
        
        for condition in watchlist_conditions:
            try:
                with db.get_connection() as conn:
                    with conn.cursor() as cur:
                        cur.execute(condition['query'])
                        results = cur.fetchall()
                        
                        for row in results:
                            try:
                                cur.execute("""
                                    INSERT INTO daily_watchlist (symbol, date, condition_type, condition_value)
                                    VALUES (%s, %s, %s, %s)
                                    ON CONFLICT (symbol, date, condition_type) DO NOTHING
                                """, (row[0], today, condition['name'], float(row[1])))
                                
                            except Exception as e:
                                print(f"‚ö†Ô∏è {row[0]}: Í¥ÄÏã¨Ï¢ÖÎ™© Ï†ÄÏû• Ïò§Î•ò - {e}")
                        
                        conn.commit()
                        added_count = len(results)
                        total_added += added_count
                        print(f"‚úÖ {condition['name']}: {added_count}Í∞ú Ï∂îÍ∞Ä")
                        
            except Exception as e:
                print(f"‚ùå {condition['name']} Ï°∞Í±¥ Ï≤òÎ¶¨ Ïò§Î•ò: {e}")
        
        print(f"‚úÖ ÏùºÏùº Í¥ÄÏã¨Ï¢ÖÎ™© ÏÉùÏÑ± ÏôÑÎ£å: Ï¥ù {total_added}Í∞ú")
        
        return {
            "status": "completed",
            "total_added": total_added,
            "date": str(today)
        }
        
    except Exception as e:
        print(f"‚ùå ÏùºÏùº Í¥ÄÏã¨Ï¢ÖÎ™© ÏÉùÏÑ± Ïã§Ìå®: {e}")
        import traceback
        traceback.print_exc()
        raise
    finally:
        if 'db' in locals():
            db.close()

def cleanup_old_data_task(**kwargs):
    """Ïò§ÎûòÎêú Îç∞Ïù¥ÌÑ∞ Ï†ïÎ¶¨"""
    import sys
    sys.path.insert(0, '/opt/airflow/common')
    
    from database import PostgreSQLManager
    from bulk_data_collector import BulkDataCollector
    
    print("üöÄ Ïò§ÎûòÎêú Îç∞Ïù¥ÌÑ∞ Ï†ïÎ¶¨ ÏãúÏûë...")
    
    try:
        # ÎåÄÎüâ ÏàòÏßëÍ∏∞ Ï¥àÍ∏∞Ìôî (Ï†ïÎ¶¨ Í∏∞Îä• ÏÇ¨Ïö©)
        collector = BulkDataCollector()
        
        # 365Ïùº Ïù¥ÏÉÅ Îêú Îç∞Ïù¥ÌÑ∞ Ï†ïÎ¶¨
        deleted_count = collector.cleanup_old_data(days_to_keep=365)
        
        print(f"‚úÖ Ïò§ÎûòÎêú Îç∞Ïù¥ÌÑ∞ Ï†ïÎ¶¨ ÏôÑÎ£å: {deleted_count:,}Í∞ú Î†àÏΩîÎìú ÏÇ≠Ï†ú")
        
        return {
            "status": "completed",
            "deleted_count": deleted_count
        }
        
    except Exception as e:
        print(f"‚ùå Îç∞Ïù¥ÌÑ∞ Ï†ïÎ¶¨ Ïã§Ìå®: {e}")
        import traceback
        traceback.print_exc()
        raise
    finally:
        if 'collector' in locals():
            collector.close()

def check_and_adjust_splits_task(**kwargs):
    """Ï£ºÏãùÎ∂ÑÌï†/Î∞∞Îãπ Ï≤¥ÌÅ¨ Î∞è Îç∞Ïù¥ÌÑ∞ Ï°∞Ï†ï"""
    import sys
    sys.path.insert(0, '/opt/airflow/common')
    
    from database import PostgreSQLManager
    import yfinance as yf
    from datetime import date, timedelta
    
    print("üöÄ Ï£ºÏãùÎ∂ÑÌï†/Î∞∞Îãπ Ï≤¥ÌÅ¨ Î∞è Ï°∞Ï†ï ÏãúÏûë...")
    
    try:
        # PostgreSQL Ïó∞Í≤∞
        db = PostgreSQLManager()
        print("‚úÖ PostgreSQL Ïó∞Í≤∞ ÏÑ±Í≥µ")
        
        # ÏµúÍ∑º Í±∞Îûò ÏûàÎäî Î™®Îì† Ïã¨Î≥ºÎì§ Ï°∞Ìöå
        query = """
            SELECT DISTINCT symbol 
            FROM stock_data 
            WHERE date >= CURRENT_DATE - INTERVAL '7 days'
            ORDER BY symbol
            -- Î™®Îì† ÌôúÏÑ± Ï¢ÖÎ™© Ï≤¥ÌÅ¨ (Ï£ºÏãùÎ∂ÑÌï†ÏùÄ ÏòàÏ∏° Î∂àÍ∞ÄÎä•ÌïòÎØÄÎ°ú)
        """
        
        with db.get_connection() as conn:
            with conn.cursor() as cur:
                cur.execute(query)
                symbols = [row[0] for row in cur.fetchall()]
        
        print(f"üìä Î∂ÑÌï†/Î∞∞Îãπ Ï≤¥ÌÅ¨ ÎåÄÏÉÅ: {len(symbols)}Í∞ú Ïã¨Î≥º")
        
        splits_detected = 0
        adjustments_made = 0
        error_count = 0
        
        # Î∞∞Ïπò Ï≤òÎ¶¨Î•º ÏúÑÌïú ÏßÑÌñâÎ•† ÌëúÏãú
        for i, symbol in enumerate(symbols):
            try:
                # ÏßÑÌñâÎ•† ÌëúÏãú (Îß§ 50Í∞úÎßàÎã§)
                if (i + 1) % 50 == 0:
                    print(f"üìà ÏßÑÌñâÎ•†: {i+1}/{len(symbols)} ({((i+1)/len(symbols)*100):.1f}%)")
                
                # API Ï†úÌïú Î∞©ÏßÄÎ•º ÏúÑÌïú Í∏∞Î≥∏ ÎåÄÍ∏∞ (Îß§ ÏöîÏ≤≠ÎßàÎã§)
                import time
                time.sleep(0.1)  # 100ms ÎåÄÍ∏∞
                
                # Ïö∞ÏÑ† FinanceDataReaderÎ°ú ÏãúÎèÑ (Îçî ÏïàÏ†ïÏ†Å)
                split_detected = False
                try:
                    import FinanceDataReader as fdr
                    
                    # FDRÎ°ú ÏµúÍ∑º 30ÏùºÍ∞Ñ Îç∞Ïù¥ÌÑ∞ ÌôïÏù∏ÌïòÏó¨ Î∂ÑÌï† Í∞êÏßÄ
                    end_date = date.today()
                    start_date = end_date - timedelta(days=30)
                    
                    df = fdr.DataReader(symbol, start=start_date, end=end_date)
                    if not df.empty and len(df) > 1:
                        # Í∞ÄÍ≤© Ï†êÌîÑÎ°ú Î∂ÑÌï† Í∞êÏßÄ (Ï†ÑÏùº ÎåÄÎπÑ 40% Ïù¥ÏÉÅ Î≥ÄÌôîÏãú)
                        df['price_change'] = df['Close'].pct_change()
                        potential_splits = df[abs(df['price_change']) > 0.4]  # 40% Ïù¥ÏÉÅ Î≥ÄÌôî
                        
                        if not potential_splits.empty:
                            for split_date, row in potential_splits.iterrows():
                                change_ratio = 1 + row['price_change']
                                if change_ratio < 0.7:  # Í∞ÄÍ≤©Ïù¥ 30% Ïù¥ÏÉÅ Îñ®Ïñ¥Ïßê (Î∂ÑÌï†)
                                    split_ratio = 1 / change_ratio  # Î∂ÑÌï† ÎπÑÏú® Ï∂îÏ†ï
                                    splits_detected += 1
                                    split_detected = True
                                    print(f"üîç {symbol}: FDRÏóêÏÑú Î∂ÑÌï† Í∞êÏßÄ - {split_date.date()}: Ï∂îÏ†ï ÎπÑÏú® {split_ratio:.2f}")
                                    
                                    adjusted = adjust_historical_data(db, symbol, split_date.date(), split_ratio)
                                    if adjusted:
                                        adjustments_made += 1
                                        print(f"‚úÖ {symbol}: {split_date.date()} Î∂ÑÌï† Ï°∞Ï†ï ÏôÑÎ£å (Ï∂îÏ†ï ÎπÑÏú®: {split_ratio:.2f})")
                except:
                    pass  # FDR Ïã§Ìå®Ïãú yfinanceÎ°ú Ìè¥Î∞±
                
                # FDRÏóêÏÑú Î∂ÑÌï†ÏùÑ Ï∞æÏßÄ Î™ªÌñàÏúºÎ©¥ yfinanceÎ°ú Ìè¥Î∞±
                if not split_detected:
                    # yfinanceÎ°ú ÏµúÍ∑º 1Í∞úÏõîÍ∞Ñ Î∂ÑÌï†/Î∞∞Îãπ Ï†ïÎ≥¥ ÌôïÏù∏
                    ticker = yf.Ticker(symbol)
                    
                    # Ï£ºÏãùÎ∂ÑÌï† Ï†ïÎ≥¥
                    splits = ticker.splits
                    if not splits.empty:
                        recent_splits = splits[splits.index >= (date.today() - timedelta(days=30))]
                        
                        if not recent_splits.empty:
                            splits_detected += 1
                            print(f"üîç {symbol}: yfinanceÏóêÏÑú Ï£ºÏãùÎ∂ÑÌï† Î∞úÍ≤¨ - {recent_splits.to_dict()}")
                            
                            # Î∂ÑÌï† ÎπÑÏú®Ïóê Îî∞Î•∏ Í≥ºÍ±∞ Îç∞Ïù¥ÌÑ∞ Ï°∞Ï†ï
                            for split_date, split_ratio in recent_splits.items():
                                if split_ratio != 1.0:  # Ïã§Ï†ú Î∂ÑÌï†Ïù¥ ÏûàÎäî Í≤ΩÏö∞
                                    adjusted = adjust_historical_data(db, symbol, split_date.date(), split_ratio)
                                    if adjusted:
                                        adjustments_made += 1
                                        print(f"‚úÖ {symbol}: {split_date.date()} Î∂ÑÌï† Ï°∞Ï†ï ÏôÑÎ£å (ÎπÑÏú®: {split_ratio})")
                
                    # Î∞∞Îãπ Ï†ïÎ≥¥ (ÌÅ∞ ÌäπÎ≥ÑÎ∞∞ÎãπÏùò Í≤ΩÏö∞ÏóêÎßå Ï°∞Ï†ï)
                    dividends = ticker.dividends
                    if not dividends.empty:
                        recent_dividends = dividends[dividends.index >= (date.today() - timedelta(days=7))]
                        
                        # ÌäπÎ≥ÑÎ∞∞Îãπ (ÏùºÎ∞ò Î∞∞Îãπ ÎåÄÎπÑ 3Î∞∞ Ïù¥ÏÉÅ) Ï≤¥ÌÅ¨
                        if not recent_dividends.empty:
                            avg_dividend = dividends.tail(8).mean()  # ÏµúÍ∑º 2ÎÖÑ ÌèâÍ∑†
                            for div_date, div_amount in recent_dividends.items():
                                if div_amount > avg_dividend * 3:  # ÌäπÎ≥ÑÎ∞∞ÎãπÏúºÎ°ú ÌåêÎã®
                                    print(f"üîç {symbol}: ÌäπÎ≥ÑÎ∞∞Îãπ Î∞úÍ≤¨ - {div_date.date()}: ${div_amount}")
                                    # ÌäπÎ≥ÑÎ∞∞Îãπ Ï°∞Ï†ïÏùÄ ÏÑ†ÌÉùÏ†ÅÏúºÎ°ú Íµ¨ÌòÑ Í∞ÄÎä•
                
            except Exception as e:
                error_count += 1
                print(f"‚ö†Ô∏è {symbol}: Î∂ÑÌï†/Î∞∞Îãπ Ï≤¥ÌÅ¨ Ïò§Î•ò - {e}")
                
                # API Ï†úÌïú Ïò§Î•ò Ï≤òÎ¶¨
                if "Rate limited" in str(e) or "Too Many Requests" in str(e):
                    print(f"üîÑ API ÏöîÏ≤≠ Ï†úÌïú Í∞êÏßÄ, 5Ï¥à ÎåÄÍ∏∞...")
                    import time
                    time.sleep(5)
                elif error_count % 10 == 0:
                    print(f"üîÑ API Ïò§Î•ò {error_count}Í∞ú Î∞úÏÉù, 3Ï¥à ÎåÄÍ∏∞...")
                    import time
                    time.sleep(3)
                continue
        
        print(f"‚úÖ Ï£ºÏãùÎ∂ÑÌï†/Î∞∞Îãπ Ï≤¥ÌÅ¨ ÏôÑÎ£å:")
        print(f"  - Ï¥ù Ï≤¥ÌÅ¨ Ï¢ÖÎ™©: {len(symbols)}Í∞ú")
        print(f"  - Î∂ÑÌï† Î∞úÍ≤¨: {splits_detected}Í∞ú")
        print(f"  - Ï°∞Ï†ï ÏôÑÎ£å: {adjustments_made}Í∞ú")
        print(f"  - Ïò§Î•ò Î∞úÏÉù: {error_count}Í∞ú")
        
        return {
            "status": "completed",
            "splits_detected": splits_detected,
            "adjustments_made": adjustments_made
        }
        
    except Exception as e:
        print(f"‚ùå Ï£ºÏãùÎ∂ÑÌï†/Î∞∞Îãπ Ï≤¥ÌÅ¨ Ïã§Ìå®: {e}")
        import traceback
        traceback.print_exc()
        raise
    finally:
        if 'db' in locals():
            db.close()

def adjust_historical_data(db, symbol: str, split_date: date, split_ratio: float) -> bool:
    """Ï£ºÏãùÎ∂ÑÌï†Ïóê Îî∞Î•∏ Í≥ºÍ±∞ Îç∞Ïù¥ÌÑ∞ Ï°∞Ï†ï"""
    try:
        with db.get_connection() as conn:
            with conn.cursor() as cur:
                # Î∂ÑÌï† Ïù¥Ï†Ñ Îç∞Ïù¥ÌÑ∞Îßå Ï°∞Ï†ï
                adjust_query = """
                    UPDATE stock_data 
                    SET 
                        open = open / %s,
                        high = high / %s,
                        low = low / %s,
                        close = close / %s,
                        volume = volume * %s
                    WHERE symbol = %s 
                      AND date < %s
                      AND open IS NOT NULL
                """
                
                cur.execute(adjust_query, (
                    split_ratio, split_ratio, split_ratio, split_ratio,
                    split_ratio, symbol, split_date
                ))
                
                adjusted_rows = cur.rowcount
                
                # Í∏∞Ïà†Ï†Å ÏßÄÌëúÎèÑ Ï°∞Ï†ï
                if adjusted_rows > 0:
                    indicator_query = """
                        UPDATE stock_data_technical_indicators
                        SET
                            sma_20 = sma_20 / %s,
                            sma_50 = sma_50 / %s,
                            ema_12 = ema_12 / %s,
                            ema_26 = ema_26 / %s,
                            macd = macd / %s,
                            macd_signal = macd_signal / %s,
                            bb_upper = bb_upper / %s,
                            bb_middle = bb_middle / %s,
                            bb_lower = bb_lower / %s
                        WHERE symbol = %s 
                          AND date < %s
                    """
                    
                    cur.execute(indicator_query, (
                        split_ratio, split_ratio, split_ratio, split_ratio,
                        split_ratio, split_ratio, split_ratio, split_ratio,
                        split_ratio, symbol, split_date
                    ))
                
                conn.commit()
                return adjusted_rows > 0
                
    except Exception as e:
        print(f"‚ùå {symbol} Îç∞Ïù¥ÌÑ∞ Ï°∞Ï†ï Ïò§Î•ò: {e}")
        return False

def database_status_check_task(**kwargs):
    """Îç∞Ïù¥ÌÑ∞Î≤†Ïù¥Ïä§ ÏÉÅÌÉú ÌôïÏù∏"""
    import sys
    sys.path.insert(0, '/opt/airflow/common')
    
    from database import PostgreSQLManager
    from bulk_data_collector import BulkDataCollector
    
    print("üöÄ Îç∞Ïù¥ÌÑ∞Î≤†Ïù¥Ïä§ ÏÉÅÌÉú ÌôïÏù∏ ÏãúÏûë...")
    
    try:
        # ÎåÄÎüâ ÏàòÏßëÍ∏∞ Ï¥àÍ∏∞Ìôî
        collector = BulkDataCollector()
        
        # ÏàòÏßë ÏÉÅÌÉú Ï°∞Ìöå
        status = collector.get_collection_status()
        
        print("üìä Îç∞Ïù¥ÌÑ∞Î≤†Ïù¥Ïä§ ÏÉÅÌÉú:")
        print(f"  - Ï¥ù Ïã¨Î≥º Ïàò: {status.get('total_symbols', 0):,}Í∞ú")
        print(f"  - Ï¥ù Ï£ºÍ∞Ä Î†àÏΩîÎìú: {status.get('total_stock_records', 0):,}Í∞ú")
        print(f"  - Í∏∞Ïà†Ï†Å ÏßÄÌëú Î†àÏΩîÎìú: {status.get('technical_indicators_records', 0):,}Í∞ú")
        print(f"  - ÏµúÏã† Îç∞Ïù¥ÌÑ∞ ÎÇ†Ïßú: {status.get('latest_date', 'N/A')}")
        print(f"  - Ïò§Îäò Îç∞Ïù¥ÌÑ∞Í∞Ä ÏûàÎäî Ïã¨Î≥º: {status.get('symbols_with_today_data', 0):,}Í∞ú")
        
        return {
            "status": "completed",
            "database_status": status
        }
        
    except Exception as e:
        print(f"‚ùå ÏÉÅÌÉú ÌôïÏù∏ Ïã§Ìå®: {e}")
        import traceback
        traceback.print_exc()
        raise
    finally:
        if 'collector' in locals():
            collector.close()

# Task Ï†ïÏùò
collect_symbols = PythonOperator(
    task_id='collect_nasdaq_symbols',
    python_callable=collect_nasdaq_symbols_task,
    dag=dag,
)

check_splits = PythonOperator(
    task_id='check_and_adjust_splits',
    python_callable=check_and_adjust_splits_task,
    dag=dag,
)

collect_stock_data = PythonOperator(
    task_id='bulk_collect_stock_data',
    python_callable=bulk_collect_stock_data_task,
    dag=dag,
)

calculate_indicators = PythonOperator(
    task_id='calculate_technical_indicators',
    python_callable=calculate_technical_indicators_task,
    dag=dag,
)

generate_watchlist = PythonOperator(
    task_id='generate_daily_watchlist',
    python_callable=generate_daily_watchlist_task,
    dag=dag,
)

cleanup_data = PythonOperator(
    task_id='cleanup_old_data',
    python_callable=cleanup_old_data_task,
    dag=dag,
)

status_check = PythonOperator(
    task_id='database_status_check',
    python_callable=database_status_check_task,
    dag=dag,
)

# Task Ï¢ÖÏÜçÏÑ± Ï†ïÏùò (Ï£ºÏãùÎ∂ÑÌï† Ï≤¥ÌÅ¨Î•º Îç∞Ïù¥ÌÑ∞ ÏàòÏßë Ï†ÑÏóê Ïã§Ìñâ)
collect_symbols >> check_splits >> collect_stock_data >> calculate_indicators >> generate_watchlist >> cleanup_data >> status_check
