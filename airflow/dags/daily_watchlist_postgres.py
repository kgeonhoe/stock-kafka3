#!/usr/bin/env python3
# -*- coding: utf-8 -*-

from datetime import datetime, timedelta
from airflow import DAG
from airflow.operators.python import PythonOperator
from airflow.operators.bash import BashOperator
from airflow.sensors.external_task import ExternalTaskSensor
import sys
import os

# í™˜ê²½ì— ë”°ë¼ ëª¨ë“ˆ ê²½ë¡œ ì„¤ì •
if '/opt/airflow/common' not in sys.path:
    sys.path.insert(0, '/opt/airflow/common')
if '/home/grey1/stock-kafka3/common' not in sys.path:
    sys.path.insert(0, '/home/grey1/stock-kafka3/common')

from technical_scanner_postgres import TechnicalScannerPostgreSQL
import pytz

def market_aware_setup(**context):
    """ì‹œì¥ ì‹œê°„ëŒ€ë³„ ìŠ¤ìº” ê°•ë„ ê²°ì •"""
    
    # í˜„ì¬ ë¯¸êµ­ ë™ë¶€ ì‹œê°„ (NYSE/NASDAQ ê¸°ì¤€)
    est = pytz.timezone('US/Eastern')
    current_est = datetime.now(est)
    current_hour = current_est.hour
    current_minute = current_est.minute
    weekday = current_est.weekday()  # 0=ì›”ìš”ì¼, 6=ì¼ìš”ì¼
    
    # ì£¼ë§ì€ LOW ê°•ë„ë¡œ ê³ ì •
    if weekday >= 5:  # í† ìš”ì¼, ì¼ìš”ì¼
        scan_intensity = 'LOW'
        conditions = ['bollinger_bands']
        reason = "ì£¼ë§ - ìµœì†Œ ëª¨ë‹ˆí„°ë§"
    else:
        # í‰ì¼ ì‹œê°„ëŒ€ë³„ ë¶„ë¥˜
        if 9 <= current_hour < 16:  # 09:30-16:00 ì •ê·œ ê±°ë˜ì‹œê°„
            if current_hour == 9 and current_minute < 30:
                # 9:00-9:30ì€ í”„ë¦¬ë§ˆì¼“ ë§ˆì§€ë§‰
                scan_intensity = 'MEDIUM'
                conditions = ['bollinger_bands', 'volume_spike']
                reason = "í”„ë¦¬ë§ˆì¼“ ë§ˆì§€ë§‰ 30ë¶„"
            else:
                # ì •ê·œ ê±°ë˜ì‹œê°„
                scan_intensity = 'HIGH'
                conditions = ['bollinger_bands', 'rsi_oversold', 'macd_bullish', 'volume_spike']
                reason = "ì •ê·œ ê±°ë˜ì‹œê°„ - ìµœê³  í™œë™ì„±"
                
        elif 4 <= current_hour < 9 or 16 <= current_hour <= 20:
            # í”„ë¦¬ë§ˆì¼“(4:00-9:30) ë˜ëŠ” ì• í”„í„°ë§ˆì¼“(16:00-20:00)
            scan_intensity = 'MEDIUM'
            conditions = ['bollinger_bands', 'volume_spike']
            reason = "í™•ì¥ ê±°ë˜ì‹œê°„ - ì¤‘ê°„ ëª¨ë‹ˆí„°ë§"
            
        else:  # 20:00-04:00 ì‹œì¥ ì™„ì „ ë§ˆê°
            scan_intensity = 'LOW'
            conditions = ['bollinger_bands']
            reason = "ì‹œì¥ ë§ˆê° - ìµœì†Œ ëª¨ë‹ˆí„°ë§"
    
    print(f"ğŸ• í˜„ì¬ EST: {current_est.strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"âš¡ ìŠ¤ìº” ê°•ë„: {scan_intensity}")
    print(f"ğŸ¯ í™œì„± ì¡°ê±´: {conditions}")
    print(f"ğŸ’¡ ì´ìœ : {reason}")
    
    # XComìœ¼ë¡œ í›„ì† íƒœìŠ¤í¬ì— ì „ë‹¬
    context['task_instance'].xcom_push(key='scan_conditions', value=conditions)
    context['task_instance'].xcom_push(key='scan_intensity', value=scan_intensity)
    context['task_instance'].xcom_push(key='scan_reason', value=reason)
    
    return f"âœ… {scan_intensity} ê°•ë„ ì„¤ì •: {len(conditions)}ê°œ ì¡°ê±´"

def scan_and_update_watchlist(**context):
    """ì‹œì¥ ìƒí™©ì— ë”°ë¥¸ ë™ì  ë³¼ë¦°ì € ë°´ë“œ ìŠ¤ìº” (PostgreSQL)"""
    
    # ì´ì „ íƒœìŠ¤í¬ì—ì„œ ìŠ¤ìº” ì¡°ê±´ ê°€ì ¸ì˜¤ê¸°
    scan_conditions = context['task_instance'].xcom_pull(
        task_ids='market_aware_setup', 
        key='scan_conditions'
    ) or ['bollinger_bands']  # ê¸°ë³¸ê°’
    
    scan_intensity = context['task_instance'].xcom_pull(
        task_ids='market_aware_setup', 
        key='scan_intensity'
    ) or 'MEDIUM'
    
    # ë³¼ë¦°ì € ë°´ë“œ ì¡°ê±´ì´ í¬í•¨ëœ ê²½ìš°ì—ë§Œ ì‹¤í–‰
    if 'bollinger_bands' not in scan_conditions:
        print(f"â­ï¸ {scan_intensity} ê°•ë„ì—ì„œ ë³¼ë¦°ì € ë°´ë“œ ìŠ¤ìº” ì œì™¸ë¨")
        context['task_instance'].xcom_push(key='watchlist_count', value=0)
        context['task_instance'].xcom_push(key='scan_date', value=str((datetime.now() - timedelta(days=1)).date()))
        return f"âœ… ìŠ¤ìº” ìŠ¤í‚µ ({scan_intensity})"
    
    # ìŠ¤ìº” ë‚ ì§œ (ì–´ì œ ë‚ ì§œ ì‚¬ìš© - ì¥ë§ˆê° í›„ ì²˜ë¦¬)
    scan_date = (datetime.now() - timedelta(days=1)).date()
    
    try:
        # PostgreSQL ê¸°ìˆ ì  ìŠ¤ìºë„ˆ ì´ˆê¸°í™”
        scanner = TechnicalScannerPostgreSQL()
        
        # ê°•ë„ë³„ ìŠ¤ìº” íŒŒë¼ë¯¸í„° ì¡°ì •
        if scan_intensity == 'HIGH':
            # ì •ê·œ ê±°ë˜ì‹œê°„ - ë” ë¯¼ê°í•œ ì¡°ê±´
            threshold = 0.995  # ë³¼ë¦°ì € ìƒë‹¨ì˜ 99.5% í„°ì¹˜
            limit = 50         # ìµœëŒ€ 50ê°œ ì¢…ëª©
        elif scan_intensity == 'MEDIUM':
            # í™•ì¥ ê±°ë˜ì‹œê°„ - ì ë‹¹í•œ ì¡°ê±´  
            threshold = 0.99   # ë³¼ë¦°ì € ìƒë‹¨ì˜ 99% í„°ì¹˜
            limit = 30         # ìµœëŒ€ 30ê°œ ì¢…ëª©
        else:  # LOW
            # ì‹œì¥ ë§ˆê° ì‹œê°„ - ë³´ìˆ˜ì  ì¡°ê±´
            threshold = 0.985  # ë³¼ë¦°ì € ìƒë‹¨ì˜ 98.5% í„°ì¹˜  
            limit = 20         # ìµœëŒ€ 20ê°œ ì¢…ëª©
        
        print(f"ğŸ¯ {scan_intensity} ê°•ë„ ìŠ¤ìº”: ì„ê³„ê°’={threshold:.3f}, ìµœëŒ€={limit}ê°œ")
        
        # ë³¼ë¦°ì € ë°´ë“œ ìƒë‹¨ í„°ì¹˜ ì¢…ëª© ìŠ¤ìº”
        bb_signals = scanner.scan_bollinger_band_signals(scan_date)
        
        # ê°•ë„ë³„ í•„í„°ë§ ì ìš©
        filtered_signals = []
        for signal in bb_signals:
            # ì„ê³„ê°’ ì¡°ê±´ í™•ì¸ (ìƒë‹¨ì„  ëŒ€ë¹„ ë¹„ìœ¨)
            if signal.get('condition_value', 0) >= threshold:
                filtered_signals.append(signal)
        
        # ìƒìœ„ Nê°œë¡œ ì œí•œ
        watchlist_signals = filtered_signals[:limit]
        
        # í•„í„°ë§ëœ ì‹ í˜¸ë“¤ì„ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥
        if watchlist_signals:
            try:
                with scanner.db.get_connection() as conn:
                    with conn.cursor() as cur:
                        for signal in watchlist_signals:
                            cur.execute("""
                                INSERT INTO daily_watchlist 
                                (symbol, date, condition_type, condition_value, market_cap_tier)
                                VALUES (%s, %s, %s, %s, %s)
                                ON CONFLICT (symbol, date, condition_type) DO UPDATE SET
                                    condition_value = EXCLUDED.condition_value,
                                    market_cap_tier = EXCLUDED.market_cap_tier
                            """, (
                                signal['symbol'],
                                signal['date'], 
                                signal['condition_type'],
                                signal['condition_value'],
                                signal.get('market_cap_tier', 3)
                            ))
                        conn.commit()
                        print(f"ğŸ’¾ {len(watchlist_signals)}ê°œ ì‹ í˜¸ DB ì €ì¥ ì™„ë£Œ")
            except Exception as db_error:
                print(f"âŒ DB ì €ì¥ ì˜¤ë¥˜: {db_error}")
                raise
        
        print(f"ğŸ“ˆ {scan_date} ë³¼ë¦°ì € ë°´ë“œ ìƒë‹¨ í„°ì¹˜ ì¢…ëª©: {len(watchlist_signals)}ê°œ")
        
        # ê²°ê³¼ ìƒì„¸ ì¶œë ¥
        for signal in watchlist_signals[:10]:  # ìƒìœ„ 10ê°œë§Œ ì¶œë ¥
            print(f"  - {signal['symbol']}: ${signal['close_price']:.2f} (ìƒë‹¨ì„  ëŒ€ë¹„ {signal['condition_value']:.3f})")
        
        # XComì— ê²°ê³¼ ì €ì¥
        context['task_instance'].xcom_push(key='watchlist_count', value=len(watchlist_signals))
        context['task_instance'].xcom_push(key='scan_date', value=str(scan_date))
        
        scanner.close()
        return f"âœ… {scan_intensity} ê°•ë„ ìŠ¤ìº” ì™„ë£Œ: {len(watchlist_signals)}ê°œ"
        
    except Exception as e:
        print(f"âŒ ê´€ì‹¬ì¢…ëª© ìŠ¤ìº” ì‹¤íŒ¨: {str(e)}")
        raise

def scan_rsi_oversold(**context):
    """ì‹œì¥ ê°•ë„ì— ë”°ë¥¸ RSI ê³¼ë§¤ë„ ìŠ¤ìº” (PostgreSQL)"""
    
    # ì‹œì¥ ê°•ë„ í™•ì¸
    scan_conditions = context['task_instance'].xcom_pull(
        task_ids='market_aware_setup', 
        key='scan_conditions'
    ) or []
    
    scan_intensity = context['task_instance'].xcom_pull(
        task_ids='market_aware_setup', 
        key='scan_intensity'
    ) or 'MEDIUM'
    
    # RSI ìŠ¤ìº”ì´ í™œì„±í™”ëœ ê²½ìš°ì—ë§Œ ì‹¤í–‰ (HIGH ê°•ë„ì—ë§Œ)
    if 'rsi_oversold' not in scan_conditions:
        print(f"â­ï¸ {scan_intensity} ê°•ë„ì—ì„œ RSI ìŠ¤ìº” ì œì™¸ë¨")
        context['task_instance'].xcom_push(key='rsi_count', value=0)
        return f"âœ… RSI ìŠ¤ìº” ìŠ¤í‚µ ({scan_intensity})"
    
    scan_date = (datetime.now() - timedelta(days=1)).date()
    
    try:
        scanner = TechnicalScannerPostgreSQL()
        
        # HIGH ê°•ë„ì—ì„œë§Œ ì‹¤í–‰ë˜ë¯€ë¡œ ë” ì ê·¹ì ì¸ íŒŒë¼ë¯¸í„°
        rsi_threshold = 35    # HIGH ê°•ë„ì—ì„œëŠ” RSI 35 ì´í•˜ê¹Œì§€ í™•ì¥
        limit = 25           # ìµœëŒ€ 25ê°œ ì¢…ëª©
        
        print(f"ğŸ¯ {scan_intensity} RSI ìŠ¤ìº”: RSIâ‰¤{rsi_threshold}, ìµœëŒ€={limit}ê°œ")
        
        # RSI ê³¼ë§¤ë„ ì‹ í˜¸ ìŠ¤ìº”
        all_rsi_signals = scanner.scan_rsi_oversold_signals(scan_date)
        
        # ê°•ë„ë³„ í•„í„°ë§ ì ìš©
        filtered_signals = []
        for signal in all_rsi_signals:
            # RSI ì„ê³„ê°’ ì¡°ê±´ í™•ì¸
            if signal.get('rsi', 100) <= rsi_threshold:
                filtered_signals.append(signal)
        
        # ìƒìœ„ Nê°œë¡œ ì œí•œ
        rsi_signals = filtered_signals[:limit]
        
        # í•„í„°ë§ëœ ì‹ í˜¸ë“¤ì„ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥
        if rsi_signals:
            try:
                with scanner.db.get_connection() as conn:
                    with conn.cursor() as cur:
                        for signal in rsi_signals:
                            cur.execute("""
                                INSERT INTO daily_watchlist 
                                (symbol, date, condition_type, condition_value, market_cap_tier)
                                VALUES (%s, %s, %s, %s, %s)
                                ON CONFLICT (symbol, date, condition_type) DO UPDATE SET
                                    condition_value = EXCLUDED.condition_value,
                                    market_cap_tier = EXCLUDED.market_cap_tier
                            """, (
                                signal['symbol'],
                                signal['date'], 
                                signal['condition_type'],
                                signal['condition_value'],
                                signal.get('market_cap_tier', 3)
                            ))
                        conn.commit()
                        print(f"ğŸ’¾ {len(rsi_signals)}ê°œ RSI ì‹ í˜¸ DB ì €ì¥ ì™„ë£Œ")
            except Exception as db_error:
                print(f"âŒ RSI ì‹ í˜¸ DB ì €ì¥ ì˜¤ë¥˜: {db_error}")
                raise
        
        print(f"ğŸ“‰ {scan_date} RSI ê³¼ë§¤ë„ ì¢…ëª©: {len(rsi_signals)}ê°œ")
        
        # ê²°ê³¼ ìƒì„¸ ì¶œë ¥
        for signal in rsi_signals[:5]:  # ìƒìœ„ 5ê°œë§Œ ì¶œë ¥
            print(f"  - {signal['symbol']}: RSI {signal['rsi']:.1f} (${signal['close_price']:.2f})")
        
        context['task_instance'].xcom_push(key='rsi_count', value=len(rsi_signals))
        
        scanner.close()
        return f"âœ… RSI ê³¼ë§¤ë„ ìŠ¤ìº” ì™„ë£Œ: {len(rsi_signals)}ê°œ"
        
    except Exception as e:
        print(f"âŒ RSI ìŠ¤ìº” ì‹¤íŒ¨: {str(e)}")
        raise

def scan_macd_bullish(**context):
    """MACD ê°•ì„¸ ì¢…ëª© ìŠ¤ìº” (PostgreSQL)"""
    
    scan_date = (datetime.now() - timedelta(days=1)).date()
    
    try:
        scanner = TechnicalScannerPostgreSQL()
        
        # MACD ê°•ì„¸ ì‹ í˜¸ ìŠ¤ìº”
        macd_signals = scanner.scan_macd_bullish_signals(scan_date)
        
        print(f"ğŸ“ˆ {scan_date} MACD ê°•ì„¸ ì¢…ëª©: {len(macd_signals)}ê°œ")
        
        # ê²°ê³¼ ìƒì„¸ ì¶œë ¥
        for signal in macd_signals[:5]:  # ìƒìœ„ 5ê°œë§Œ ì¶œë ¥
            hist = signal['condition_value']
            print(f"  - {signal['symbol']}: MACD íˆìŠ¤í† ê·¸ë¨ {hist:.4f} (${signal['close_price']:.2f})")
        
        context['task_instance'].xcom_push(key='macd_count', value=len(macd_signals))
        
        scanner.close()
        return f"âœ… MACD ê°•ì„¸ ìŠ¤ìº” ì™„ë£Œ: {len(macd_signals)}ê°œ"
        
    except Exception as e:
        print(f"âŒ MACD ìŠ¤ìº” ì‹¤íŒ¨: {str(e)}")
        raise

def cleanup_old_watchlist(**context):
    """30ì¼ ì´ì „ ê´€ì‹¬ì¢…ëª© ë°ì´í„° ì •ë¦¬ (PostgreSQL)"""
    
    try:
        scanner = TechnicalScannerPostgreSQL()
        
        # 30ì¼ ì´ì „ ë°ì´í„° ì‚­ì œ
        cutoff_date = (datetime.now() - timedelta(days=30)).date()
        
        deleted_count = 0
        try:
            with scanner.db.get_connection() as conn:
                with conn.cursor() as cur:
                    cur.execute("""
                        DELETE FROM daily_watchlist 
                        WHERE date < %s
                    """, (cutoff_date,))
                    deleted_count = cur.rowcount
                    conn.commit()
        except Exception as e:
            print(f"âš ï¸ í…Œì´ë¸”ì´ ì¡´ì¬í•˜ì§€ ì•Šê±°ë‚˜ ì‚­ì œ ì‹¤íŒ¨: {e}")
            deleted_count = 0
        
        print(f"ğŸ§¹ {cutoff_date} ì´ì „ ê´€ì‹¬ì¢…ëª© ë°ì´í„° {deleted_count}ê°œ ì‚­ì œ")
        
        scanner.close()
        return f"âœ… ì˜¤ë˜ëœ ë°ì´í„° ì •ë¦¬ ì™„ë£Œ: {deleted_count}ê°œ ì‚­ì œ"
        
    except Exception as e:
        print(f"âŒ ë°ì´í„° ì •ë¦¬ ì‹¤íŒ¨: {str(e)}")
        raise

def get_top_performers(**context):
    """ìƒìœ„ ì„±ê³¼ ì¢…ëª© ì¡°íšŒ (PostgreSQL)"""
    
    scan_date = (datetime.now() - timedelta(days=1)).date()
    
    try:
        scanner = TechnicalScannerPostgreSQL()
        
        # ìƒìœ„ ì„±ê³¼ ì¢…ëª© ì¡°íšŒ
        performers = scanner.get_top_performers(scan_date, limit=10)
        
        print(f"ğŸ† {scan_date} ìƒìœ„ ì„±ê³¼ ì¢…ëª©:")
        for perf in performers:
            change = perf.get('change_percent', 0)
            print(f"  - {perf['symbol']}: {change:+.2f}% (${perf['close_price']:.2f})")
        
        context['task_instance'].xcom_push(key='top_performers', value=len(performers))
        
        scanner.close()
        return f"âœ… ìƒìœ„ ì„±ê³¼ ì¡°íšŒ ì™„ë£Œ: {len(performers)}ê°œ"
        
    except Exception as e:
        print(f"âŒ ìƒìœ„ ì„±ê³¼ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")
        raise

def send_watchlist_summary(**context):
    """ê´€ì‹¬ì¢…ëª© ìš”ì•½ ì •ë³´ ì¶œë ¥ (PostgreSQL)"""
    
    # ì´ì „ íƒœìŠ¤í¬ì—ì„œ ê²°ê³¼ ê°€ì ¸ì˜¤ê¸°
    watchlist_count = context['task_instance'].xcom_pull(task_ids='scan_bollinger_bands', key='watchlist_count') or 0
    rsi_count = context['task_instance'].xcom_pull(task_ids='scan_rsi_oversold', key='rsi_count') or 0
    macd_count = context['task_instance'].xcom_pull(task_ids='scan_macd_bullish', key='macd_count') or 0
    top_performers = context['task_instance'].xcom_pull(task_ids='get_top_performers', key='top_performers') or 0
    scan_date = context['task_instance'].xcom_pull(task_ids='scan_bollinger_bands', key='scan_date')
    
    print(f"""
    ğŸ“Š ì¼ë³„ ê´€ì‹¬ì¢…ëª© ìŠ¤ìº” ê²°ê³¼ ({scan_date}) - PostgreSQL
    ================================
    ğŸ¯ ë³¼ë¦°ì € ë°´ë“œ ìƒë‹¨ í„°ì¹˜: {watchlist_count}ê°œ
    ğŸ“‰ RSI ê³¼ë§¤ë„ ì‹ í˜¸: {rsi_count}ê°œ
    ğŸ“ˆ MACD ê°•ì„¸ ì‹ í˜¸: {macd_count}ê°œ
    ğŸ† ìƒìœ„ ì„±ê³¼ ì¢…ëª©: {top_performers}ê°œ
    ğŸ“… ìŠ¤ìº” ë‚ ì§œ: {scan_date}
    â° ì²˜ë¦¬ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
    ğŸ’¾ ë°ì´í„°ë² ì´ìŠ¤: PostgreSQL
    """)
    
    return f"ìš”ì•½ ì „ì†¡ ì™„ë£Œ"

def sync_watchlist_to_redis(**context):
    """PostgreSQL ê´€ì‹¬ì¢…ëª©ì„ Redisë¡œ ë™ê¸°í™”"""
    try:
        from database import PostgreSQLManager
        import redis
        import json
        from datetime import date, timedelta
        
        print("ğŸš€ PostgreSQL â†’ Redis ê´€ì‹¬ì¢…ëª© ë™ê¸°í™” ì‹œì‘...")
        
        # PostgreSQL ì—°ê²°
        db = PostgreSQLManager()
        print("âœ… PostgreSQL ì—°ê²° ì„±ê³µ")
        
        # Redis ì—°ê²° (ë‹¤ì–‘í•œ ì£¼ì†Œ ì‹œë„)
        redis_client = None
        redis_hosts = [
            {'host': 'redis', 'port': 6379},      # Docker ì»¨í…Œì´ë„ˆëª…
            {'host': 'localhost', 'port': 6379},   # ë¡œì»¬í˜¸ìŠ¤íŠ¸
            {'host': '127.0.0.1', 'port': 6379},   # IP ì£¼ì†Œ
        ]
        
        for redis_config in redis_hosts:
            try:
                test_client = redis.Redis(
                    host=redis_config['host'],
                    port=redis_config['port'],
                    db=0,
                    decode_responses=True,
                    socket_connect_timeout=5,  # 5ì´ˆ íƒ€ì„ì•„ì›ƒ
                    socket_timeout=5
                )
                # ì—°ê²° í…ŒìŠ¤íŠ¸
                test_client.ping()
                redis_client = test_client
                print(f"âœ… Redis ì—°ê²° ì„±ê³µ: {redis_config['host']}:{redis_config['port']}")
                break
            except Exception as e:
                print(f"âš ï¸ Redis ì—°ê²° ì‹¤íŒ¨ ({redis_config['host']}:{redis_config['port']}): {e}")
                continue
        
        if redis_client is None:
            print("âš ï¸ Redis ì„œë²„ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. PostgreSQLë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤.")
            # Redis ì—†ì´ë„ ê³„ì† ì§„í–‰
            redis_client = None
        
        # ìµœê·¼ 3ì¼ê°„ì˜ ê´€ì‹¬ì¢…ëª© ì¡°íšŒ (ë°°ì¹˜ ëˆ„ë½ ëŒ€ë¹„)
        today = date.today()
        start_date = today - timedelta(days=3)
        
        query = """
            SELECT DISTINCT 
                symbol, 
                date, 
                condition_type, 
                condition_value,
                created_at
            FROM daily_watchlist 
            WHERE date >= %s
            ORDER BY date DESC, symbol
        """
        
        redis_updated = 0
        
        with db.get_connection() as conn:
            with conn.cursor() as cur:
                cur.execute(query, (start_date,))
                results = cur.fetchall()
                
                print(f"ğŸ“Š PostgreSQLì—ì„œ ì¡°íšŒëœ ê´€ì‹¬ì¢…ëª©: {len(results)}ê°œ")
                
                # ë‚ ì§œë³„ë¡œ ê·¸ë£¹í™”
                watchlist_by_date = {}
                for row in results:
                    symbol, date_val, condition_type, condition_value, created_at = row
                    date_str = date_val.strftime('%Y-%m-%d')
                    
                    if date_str not in watchlist_by_date:
                        watchlist_by_date[date_str] = {}
                    
                    if symbol not in watchlist_by_date[date_str]:
                        watchlist_by_date[date_str][symbol] = {
                            'symbol': symbol,
                            'conditions': [],
                            'date': date_str,
                            'last_updated': created_at.isoformat() if created_at else None
                        }
                    
                    watchlist_by_date[date_str][symbol]['conditions'].append({
                        'type': condition_type,
                        'value': float(condition_value)
                    })
        
        # Redisì— ì €ì¥ (Redisê°€ ìˆëŠ” ê²½ìš°ì—ë§Œ)
        redis_updated = 0
        if redis_client is not None:
            for date_str, symbols_data in watchlist_by_date.items():
                try:
                    # ë‚ ì§œë³„ ê´€ì‹¬ì¢…ëª© í‚¤
                    redis_key = f"watchlist:{date_str}"
                    
                    # ê¸°ì¡´ Redis ë°ì´í„°ì™€ ë¹„êµ
                    existing_data = redis_client.get(redis_key)
                    existing_symbols = set()
                    
                    if existing_data:
                        try:
                            existing_dict = json.loads(existing_data)
                            existing_symbols = set(existing_dict.keys())
                        except:
                            pass
                    
                    # ìƒˆë¡œìš´ ì‹¬ë³¼ì´ ìˆëŠ”ì§€ í™•ì¸
                    new_symbols = set(symbols_data.keys()) - existing_symbols
                    
                    if new_symbols or not existing_data:
                        # Redisì— ì €ì¥ (JSON í˜•íƒœ)
                        redis_data = json.dumps(symbols_data, ensure_ascii=False, indent=2)
                        redis_client.setex(redis_key, 86400 * 7, redis_data)  # 7ì¼ TTL
                        
                        redis_updated += 1
                        print(f"âœ… Redis ì—…ë°ì´íŠ¸: {date_str} - {len(symbols_data)}ê°œ ì‹¬ë³¼")
                        
                        if new_symbols:
                            print(f"   ğŸ†• ìƒˆë¡œìš´ ì‹¬ë³¼: {', '.join(list(new_symbols)[:5])}{'...' if len(new_symbols) > 5 else ''}")
                    else:
                        print(f"â­ï¸  Redis ìŠ¤í‚µ: {date_str} - ë³€ê²½ì‚¬í•­ ì—†ìŒ")
                    
                    # ìµœì‹  ê´€ì‹¬ì¢…ëª© (ì˜¤ëŠ˜) ë³„ë„ í‚¤ë¡œ ì €ì¥
                    if date_str == today.strftime('%Y-%m-%d'):
                        latest_key = "watchlist:latest"
                        redis_client.setex(latest_key, 86400, redis_data)  # 1ì¼ TTL
                        print(f"âœ… ìµœì‹  ê´€ì‹¬ì¢…ëª© ì—…ë°ì´íŠ¸: {len(symbols_data)}ê°œ ì‹¬ë³¼")
                    
                except Exception as e:
                    print(f"âŒ Redis ì €ì¥ ì˜¤ë¥˜ ({date_str}): {e}")
        else:
            print("âš ï¸ Redis ë¯¸ì‚¬ìš© - PostgreSQLì—ë§Œ ì €ì¥ë¨")
        
        # í†µê³„ ì •ë³´ Redisì— ì €ì¥ (Redisê°€ ìˆëŠ” ê²½ìš°ì—ë§Œ)
        stats = {
            'total_dates': len(watchlist_by_date),
            'total_symbols': sum(len(symbols) for symbols in watchlist_by_date.values()),
            'last_sync': datetime.now().isoformat(),
            'redis_updates': redis_updated,
            'redis_available': redis_client is not None
        }
        
        if redis_client is not None:
            try:
                redis_client.setex("watchlist:stats", 3600, json.dumps(stats))  # 1ì‹œê°„ TTL
                print("âœ… Redis í†µê³„ ì €ì¥ ì™„ë£Œ")
            except Exception as e:
                print(f"âš ï¸ Redis í†µê³„ ì €ì¥ ì‹¤íŒ¨: {e}")
        
        print(f"âœ… PostgreSQL â†’ Redis ë™ê¸°í™” ì™„ë£Œ:")
        print(f"  - ì²˜ë¦¬ëœ ë‚ ì§œ: {len(watchlist_by_date)}ê°œ")
        print(f"  - ì´ ì‹¬ë³¼ ìˆ˜: {stats['total_symbols']}ê°œ")
        print(f"  - Redis ì—…ë°ì´íŠ¸: {redis_updated}ê°œ")
        print(f"  - Redis ì‚¬ìš© ê°€ëŠ¥: {'ì˜ˆ' if redis_client else 'ì•„ë‹ˆì˜¤'}")
        
        # XComì— ê²°ê³¼ ì €ì¥
        context['task_instance'].xcom_push(key='redis_sync_count', value=redis_updated)
        context['task_instance'].xcom_push(key='total_symbols', value=stats['total_symbols'])
        
        db.close()
        if redis_client is not None:
            redis_client.close()
        
        return f"âœ… ë™ê¸°í™” ì™„ë£Œ: Redis {redis_updated}ê°œ ì—…ë°ì´íŠ¸, PostgreSQL {stats['total_symbols']}ê°œ ì‹¬ë³¼"
        
    except Exception as e:
        print(f"âŒ ë™ê¸°í™” ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        raise

def generate_additional_watchlist(**context):
    """ì¶”ê°€ ê´€ì‹¬ì¢…ëª© ìƒì„± (ë°°ì¹˜ ëˆ„ë½ ëŒ€ë¹„)"""
    try:
        from database import PostgreSQLManager
        from datetime import date, timedelta
        
        print("ğŸš€ ì¶”ê°€ ê´€ì‹¬ì¢…ëª© ìƒì„± ì‹œì‘...")
        
        # PostgreSQL ì—°ê²°
        db = PostgreSQLManager()
        print("âœ… PostgreSQL ì—°ê²° ì„±ê³µ")
        
        today = date.today()
        
        # ì˜¤ëŠ˜ ê´€ì‹¬ì¢…ëª©ì´ ìˆëŠ”ì§€ í™•ì¸
        with db.get_connection() as conn:
            with conn.cursor() as cur:
                cur.execute("""
                    SELECT COUNT(*) 
                    FROM daily_watchlist 
                    WHERE date = %s
                """, (today,))
                
                today_count = cur.fetchone()[0]
                
                if today_count > 0:
                    print(f"ğŸ“… ì˜¤ëŠ˜ ê´€ì‹¬ì¢…ëª©ì´ ì´ë¯¸ ìˆìŠµë‹ˆë‹¤: {today_count}ê°œ")
                    context['task_instance'].xcom_push(key='additional_generated', value=0)
                    db.close()
                    return f"âœ… ì´ë¯¸ ì¡´ì¬: {today_count}ê°œ"
        
        print("ğŸ” ì˜¤ëŠ˜ ê´€ì‹¬ì¢…ëª©ì´ ì—†ìŠµë‹ˆë‹¤. ì¶”ê°€ ìƒì„±ì„ ì‹œë„í•©ë‹ˆë‹¤...")
        
        # ì‹¤ì‹œê°„ ê´€ì‹¬ì¢…ëª© ì¡°ê±´ë“¤
        realtime_conditions = [
            {
                'name': 'price_momentum',
                'query': """
                    SELECT DISTINCT s.symbol, s.close, 
                           (s.close - prev.close) / prev.close * 100 as price_change
                    FROM stock_data s
                    JOIN stock_data prev ON s.symbol = prev.symbol 
                        AND prev.date = s.date - INTERVAL '1 day'
                    WHERE s.date >= CURRENT_DATE - INTERVAL '2 days'
                      AND s.close > 5  -- ìµœì†Œ ê°€ê²© í•„í„°
                      AND s.volume > 100000  -- ìµœì†Œ ê±°ë˜ëŸ‰
                      AND ABS((s.close - prev.close) / prev.close * 100) > 3  -- 3% ì´ìƒ ë³€í™”
                    ORDER BY ABS((s.close - prev.close) / prev.close) DESC
                    LIMIT 30
                """
            },
            {
                'name': 'volume_breakout',
                'query': """
                    SELECT DISTINCT s1.symbol, s1.close, s1.volume
                    FROM stock_data s1
                    JOIN stock_data s2 ON s1.symbol = s2.symbol 
                        AND s2.date BETWEEN s1.date - INTERVAL '10 days' AND s1.date - INTERVAL '1 day'
                    WHERE s1.date >= CURRENT_DATE - INTERVAL '2 days'
                      AND s1.volume > 50000
                    GROUP BY s1.symbol, s1.close, s1.volume
                    HAVING s1.volume > AVG(s2.volume) * 1.5  -- 1.5ë°° ì´ìƒ
                    ORDER BY s1.volume / AVG(s2.volume) DESC
                    LIMIT 25
                """
            }
        ]
        
        total_added = 0
        
        for condition in realtime_conditions:
            try:
                with db.get_connection() as conn:
                    with conn.cursor() as cur:
                        cur.execute(condition['query'])
                        results = cur.fetchall()
                        
                        added_count = 0
                        for row in results:
                            try:
                                # ì˜¤ëŠ˜ ë‚ ì§œë¡œ ì¶”ê°€
                                cur.execute("""
                                    INSERT INTO daily_watchlist (symbol, date, condition_type, condition_value)
                                    VALUES (%s, %s, %s, %s)
                                    ON CONFLICT (symbol, date, condition_type) DO NOTHING
                                """, (row[0], today, condition['name'], float(row[1])))
                                
                                if cur.rowcount > 0:
                                    added_count += 1
                                
                            except Exception as e:
                                print(f"âš ï¸ {row[0]}: ê´€ì‹¬ì¢…ëª© ì €ì¥ ì˜¤ë¥˜ - {e}")
                        
                        conn.commit()
                        total_added += added_count
                        print(f"âœ… {condition['name']}: {added_count}ê°œ ì¶”ê°€")
                        
            except Exception as e:
                print(f"âŒ {condition['name']} ì¡°ê±´ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
        
        context['task_instance'].xcom_push(key='additional_generated', value=total_added)
        
        db.close()
        
        if total_added > 0:
            print(f"âœ… ì¶”ê°€ ê´€ì‹¬ì¢…ëª© ìƒì„± ì™„ë£Œ: ì´ {total_added}ê°œ")
        else:
            print("âš ï¸ ì¶”ê°€í•  ê´€ì‹¬ì¢…ëª©ì´ ì—†ìŠµë‹ˆë‹¤.")
        
        return f"âœ… ì¶”ê°€ ìƒì„±: {total_added}ê°œ"
        
    except Exception as e:
        print(f"âŒ ì¶”ê°€ ê´€ì‹¬ì¢…ëª© ìƒì„± ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        raise

# DAG ê¸°ë³¸ ì„¤ì •
default_args = {
    'owner': 'stock-team',
    'depends_on_past': False,
    'start_date': datetime(2024, 1, 1),
    'email_on_failure': False,
    'email_on_retry': False,
    'retries': 1,
    'retry_delay': timedelta(minutes=5),
}

# DAG ì •ì˜
dag = DAG(
    'daily_watchlist_scanner_postgres',
    default_args=default_args,
    description='ì¼ë³„ ê¸°ìˆ ì  ì§€í‘œ ê¸°ë°˜ ê´€ì‹¬ì¢…ëª© ìŠ¤ìº” ë° Redis ë™ê¸°í™” (PostgreSQL)',
    schedule_interval='*/30 * * * *',  # 30ë¶„ë§ˆë‹¤ ì‹¤í–‰ (ì§€ì†ì  ëª¨ë‹ˆí„°ë§)
    catchup=False,
    max_active_runs=1,
    tags=['watchlist', 'postgresql', 'redis', 'technical-analysis']
)

# íƒœìŠ¤í¬ ì •ì˜
scan_bollinger_task = PythonOperator(
    task_id='scan_bollinger_bands',
    python_callable=scan_and_update_watchlist,
    dag=dag,
    doc_md="""
    ## ë³¼ë¦°ì € ë°´ë“œ ìƒë‹¨ í„°ì¹˜ ì¢…ëª© ìŠ¤ìº” (PostgreSQL)
    
    - ì „ì¼ ì¢…ê°€ ê¸°ì¤€ìœ¼ë¡œ ë³¼ë¦°ì € ë°´ë“œ ìƒë‹¨ì„  98% ì´ìƒ í„°ì¹˜í•œ ì¢…ëª© ê²€ìƒ‰
    - ì‹œê°€ì´ì•¡ë³„ í‹°ì–´ ë¶„ë¥˜ (ëŒ€í˜•ì£¼: 1, ì¤‘í˜•ì£¼: 2, ì†Œí˜•ì£¼: 3)
    - daily_watchlist í…Œì´ë¸”ì— ê²°ê³¼ ì €ì¥
    """
)

scan_rsi_task = PythonOperator(
    task_id='scan_rsi_oversold',
    python_callable=scan_rsi_oversold,
    dag=dag,
    doc_md="""
    ## RSI ê³¼ë§¤ë„ ì¢…ëª© ìŠ¤ìº” (PostgreSQL)
    
    - RSI 30 ì´í•˜ ê³¼ë§¤ë„ ì¢…ëª© ê²€ìƒ‰
    - ì ì¬ì  ë°˜ë“± í›„ë³´ ì¢…ëª© ì‹ë³„
    """
)

scan_macd_task = PythonOperator(
    task_id='scan_macd_bullish',
    python_callable=scan_macd_bullish,
    dag=dag,
    doc_md="""
    ## MACD ê°•ì„¸ ì¢…ëª© ìŠ¤ìº” (PostgreSQL)
    
    - MACD ë¼ì¸ì´ ì‹œê·¸ë„ ë¼ì¸ ìœ„ì— ìˆê³  ì–‘ìˆ˜ì¸ ì¢…ëª© ê²€ìƒ‰
    - ê°•ì„¸ ëª¨ë©˜í…€ ì¢…ëª© ì‹ë³„
    """
)

top_performers_task = PythonOperator(
    task_id='get_top_performers',
    python_callable=get_top_performers,
    dag=dag,
    doc_md="""
    ## ìƒìœ„ ì„±ê³¼ ì¢…ëª© ì¡°íšŒ (PostgreSQL)
    
    - ì „ì¼ ëŒ€ë¹„ ìƒìŠ¹ë¥  ìƒìœ„ ì¢…ëª© ì¡°íšŒ
    - ê±°ë˜ëŸ‰ ì¡°ê±´ ì ìš© (ìµœì†Œ 10ë§Œì£¼)
    """
)

cleanup_task = PythonOperator(
    task_id='cleanup_old_data',
    python_callable=cleanup_old_watchlist,
    dag=dag,
    doc_md="""
    ## ì˜¤ë˜ëœ ê´€ì‹¬ì¢…ëª© ë°ì´í„° ì •ë¦¬ (PostgreSQL)
    
    - 30ì¼ ì´ì „ ê´€ì‹¬ì¢…ëª© ë°ì´í„° ì‚­ì œ
    - ë°ì´í„°ë² ì´ìŠ¤ ìš©ëŸ‰ ê´€ë¦¬
    """
)

summary_task = PythonOperator(
    task_id='send_summary',
    python_callable=send_watchlist_summary,
    dag=dag,
    doc_md="""
    ## ìŠ¤ìº” ê²°ê³¼ ìš”ì•½ (PostgreSQL)
    
    - ëª¨ë“  ìŠ¤ìº” ê²°ê³¼ í†µê³„ ì¶œë ¥
    - ë¡œê·¸ì— ìš”ì•½ ì •ë³´ ê¸°ë¡
    """
)

# ì‹œì¥ ìƒí™© ì¸ì‹ íƒœìŠ¤í¬ ì¶”ê°€
market_setup_task = PythonOperator(
    task_id='market_aware_setup',
    python_callable=market_aware_setup,
    dag=dag,
    doc_md="""
    ## ì‹œì¥ ì‹œê°„ëŒ€ë³„ ìŠ¤ìº” ê°•ë„ ì„¤ì •
    
    - í˜„ì¬ EST ì‹œê°„ëŒ€ í™•ì¸
    - HIGH/MEDIUM/LOW ê°•ë„ ê²°ì •
    - í™œì„±í™”í•  ìŠ¤ìº” ì¡°ê±´ ì„ íƒ
    
    ### ê°•ë„ë³„ ê¸°ì¤€:
    - **HIGH** (09:30-16:00 EST): ì •ê·œ ê±°ë˜ì‹œê°„, ëª¨ë“  ì¡°ê±´ í™œì„±í™”
    - **MEDIUM** (04:00-09:30, 16:00-20:00 EST): í™•ì¥ ê±°ë˜ì‹œê°„, í•µì‹¬ ì¡°ê±´ë§Œ 
    - **LOW** (20:00-04:00 EST, ì£¼ë§): ì‹œì¥ ë§ˆê°, ìµœì†Œ ëª¨ë‹ˆí„°ë§
    """
)

# ìƒˆë¡œìš´ íƒœìŠ¤í¬ë“¤ ì¶”ê°€
generate_additional_task = PythonOperator(
    task_id='generate_additional_watchlist',
    python_callable=generate_additional_watchlist,
    dag=dag,
    doc_md="""
    ## ì¶”ê°€ ê´€ì‹¬ì¢…ëª© ìƒì„±
    
    - ë°°ì¹˜ ëˆ„ë½ ëŒ€ë¹„ ì¶”ê°€ ê´€ì‹¬ì¢…ëª© ìƒì„±
    - ì‹¤ì‹œê°„ ì¡°ê±´ìœ¼ë¡œ ê´€ì‹¬ì¢…ëª© ë°œêµ´
    """
)

redis_sync_task = PythonOperator(
    task_id='sync_to_redis',
    python_callable=sync_watchlist_to_redis,
    dag=dag,
    doc_md="""
    ## PostgreSQL â†’ Redis ë™ê¸°í™”
    
    - PostgreSQL ê´€ì‹¬ì¢…ëª©ì„ Redisë¡œ ë™ê¸°í™”
    - ìµœê·¼ 3ì¼ê°„ ë°ì´í„° í™•ì¸ ë° ì—…ë°ì´íŠ¸
    - ì§€ì†ì  ëª¨ë‹ˆí„°ë§ìœ¼ë¡œ ëˆ„ë½ ë°©ì§€
    """
)

# íƒœìŠ¤í¬ ì˜ì¡´ì„± ì„¤ì • - ì‹œì¥ ìƒí™© ì¸ì‹ í›„ ì¡°ê±´ë¶€ ìŠ¤ìº”
# 1. ì‹œì¥ ìƒí™© ë¶„ì„ â†’ 2. ì¡°ê±´ë¶€ ìŠ¤ìº”ë“¤ ë³‘ë ¬ ì‹¤í–‰ â†’ 3. Redis ë™ê¸°í™” â†’ 4. ì •ë¦¬ ë° ìš”ì•½

market_setup_task >> [generate_additional_task, scan_bollinger_task, scan_rsi_task, scan_macd_task, top_performers_task]
[generate_additional_task, scan_bollinger_task, scan_rsi_task, scan_macd_task, top_performers_task] >> redis_sync_task >> cleanup_task >> summary_task
