#!/usr/bin/env python3
# -*- coding: utf-8 -*-

from datetime import datetime, timedelta
from airflow import DAG
from airflow.operators.python import PythonOperator
from airflow.operators.bash import BashOperator
from airflow.sensors.external_task import ExternalTaskSensor
import sys
import os

# í™˜ê²½ì— ë”°ë¼ ëª¨ë“ˆ ê²½ë¡œ ì„¤ì •
if '/opt/airflow/common' not in sys.path:
    sys.path.insert(0, '/opt/airflow/common')
if '/home/grey1/stock-kafka3/common' not in sys.path:
    sys.path.insert(0, '/home/grey1/stock-kafka3/common')

from technical_scanner_postgres import TechnicalScannerPostgreSQL

def scan_and_update_watchlist(**context):
    """ë³¼ë¦°ì € ë°´ë“œ ìƒë‹¨ í„°ì¹˜ ì¢…ëª© ìŠ¤ìº” ë° ê´€ì‹¬ì¢…ëª© ì—…ë°ì´íŠ¸ (PostgreSQL)"""
    
    # ìŠ¤ìº” ë‚ ì§œ (ì–´ì œ ë‚ ì§œ ì‚¬ìš© - ì¥ë§ˆê° í›„ ì²˜ë¦¬)
    scan_date = (datetime.now() - timedelta(days=1)).date()
    
    try:
        # PostgreSQL ê¸°ìˆ ì  ìŠ¤ìºë„ˆ ì´ˆê¸°í™”
        scanner = TechnicalScannerPostgreSQL()
        
        # ë³¼ë¦°ì € ë°´ë“œ ìƒë‹¨ í„°ì¹˜ ì¢…ëª© ìŠ¤ìº”
        watchlist_signals = scanner.update_daily_watchlist(scan_date)
        
        print(f"ğŸ“ˆ {scan_date} ë³¼ë¦°ì € ë°´ë“œ ìƒë‹¨ í„°ì¹˜ ì¢…ëª©: {len(watchlist_signals)}ê°œ")
        
        # ê²°ê³¼ ìƒì„¸ ì¶œë ¥
        for signal in watchlist_signals[:10]:  # ìƒìœ„ 10ê°œë§Œ ì¶œë ¥
            print(f"  - {signal['symbol']}: ${signal['close_price']:.2f} (ìƒë‹¨ì„  ëŒ€ë¹„ {signal['condition_value']:.3f})")
        
        # XComì— ê²°ê³¼ ì €ì¥
        context['task_instance'].xcom_push(key='watchlist_count', value=len(watchlist_signals))
        context['task_instance'].xcom_push(key='scan_date', value=str(scan_date))
        
        scanner.close()
        return f"âœ… ê´€ì‹¬ì¢…ëª© ìŠ¤ìº” ì™„ë£Œ: {len(watchlist_signals)}ê°œ"
        
    except Exception as e:
        print(f"âŒ ê´€ì‹¬ì¢…ëª© ìŠ¤ìº” ì‹¤íŒ¨: {str(e)}")
        raise

def scan_rsi_oversold(**context):
    """RSI ê³¼ë§¤ë„ ì¢…ëª© ìŠ¤ìº” (PostgreSQL)"""
    
    scan_date = (datetime.now() - timedelta(days=1)).date()
    
    try:
        scanner = TechnicalScannerPostgreSQL()
        
        # RSI ê³¼ë§¤ë„ ì‹ í˜¸ ìŠ¤ìº”
        rsi_signals = scanner.scan_rsi_oversold_signals(scan_date)
        
        print(f"ğŸ“‰ {scan_date} RSI ê³¼ë§¤ë„ ì¢…ëª©: {len(rsi_signals)}ê°œ")
        
        # ê²°ê³¼ ìƒì„¸ ì¶œë ¥
        for signal in rsi_signals[:5]:  # ìƒìœ„ 5ê°œë§Œ ì¶œë ¥
            print(f"  - {signal['symbol']}: RSI {signal['rsi']:.1f} (${signal['close_price']:.2f})")
        
        context['task_instance'].xcom_push(key='rsi_count', value=len(rsi_signals))
        
        scanner.close()
        return f"âœ… RSI ê³¼ë§¤ë„ ìŠ¤ìº” ì™„ë£Œ: {len(rsi_signals)}ê°œ"
        
    except Exception as e:
        print(f"âŒ RSI ìŠ¤ìº” ì‹¤íŒ¨: {str(e)}")
        raise

def scan_macd_bullish(**context):
    """MACD ê°•ì„¸ ì¢…ëª© ìŠ¤ìº” (PostgreSQL)"""
    
    scan_date = (datetime.now() - timedelta(days=1)).date()
    
    try:
        scanner = TechnicalScannerPostgreSQL()
        
        # MACD ê°•ì„¸ ì‹ í˜¸ ìŠ¤ìº”
        macd_signals = scanner.scan_macd_bullish_signals(scan_date)
        
        print(f"ğŸ“ˆ {scan_date} MACD ê°•ì„¸ ì¢…ëª©: {len(macd_signals)}ê°œ")
        
        # ê²°ê³¼ ìƒì„¸ ì¶œë ¥
        for signal in macd_signals[:5]:  # ìƒìœ„ 5ê°œë§Œ ì¶œë ¥
            hist = signal['condition_value']
            print(f"  - {signal['symbol']}: MACD íˆìŠ¤í† ê·¸ë¨ {hist:.4f} (${signal['close_price']:.2f})")
        
        context['task_instance'].xcom_push(key='macd_count', value=len(macd_signals))
        
        scanner.close()
        return f"âœ… MACD ê°•ì„¸ ìŠ¤ìº” ì™„ë£Œ: {len(macd_signals)}ê°œ"
        
    except Exception as e:
        print(f"âŒ MACD ìŠ¤ìº” ì‹¤íŒ¨: {str(e)}")
        raise

def cleanup_old_watchlist(**context):
    """30ì¼ ì´ì „ ê´€ì‹¬ì¢…ëª© ë°ì´í„° ì •ë¦¬ (PostgreSQL)"""
    
    try:
        scanner = TechnicalScannerPostgreSQL()
        
        # 30ì¼ ì´ì „ ë°ì´í„° ì‚­ì œ
        cutoff_date = (datetime.now() - timedelta(days=30)).date()
        
        deleted_count = 0
        try:
            with scanner.db.get_connection() as conn:
                with conn.cursor() as cur:
                    cur.execute("""
                        DELETE FROM daily_watchlist 
                        WHERE date < %s
                    """, (cutoff_date,))
                    deleted_count = cur.rowcount
                    conn.commit()
        except Exception as e:
            print(f"âš ï¸ í…Œì´ë¸”ì´ ì¡´ì¬í•˜ì§€ ì•Šê±°ë‚˜ ì‚­ì œ ì‹¤íŒ¨: {e}")
            deleted_count = 0
        
        print(f"ğŸ§¹ {cutoff_date} ì´ì „ ê´€ì‹¬ì¢…ëª© ë°ì´í„° {deleted_count}ê°œ ì‚­ì œ")
        
        scanner.close()
        return f"âœ… ì˜¤ë˜ëœ ë°ì´í„° ì •ë¦¬ ì™„ë£Œ: {deleted_count}ê°œ ì‚­ì œ"
        
    except Exception as e:
        print(f"âŒ ë°ì´í„° ì •ë¦¬ ì‹¤íŒ¨: {str(e)}")
        raise

def get_top_performers(**context):
    """ìƒìœ„ ì„±ê³¼ ì¢…ëª© ì¡°íšŒ (PostgreSQL)"""
    
    scan_date = (datetime.now() - timedelta(days=1)).date()
    
    try:
        scanner = TechnicalScannerPostgreSQL()
        
        # ìƒìœ„ ì„±ê³¼ ì¢…ëª© ì¡°íšŒ
        performers = scanner.get_top_performers(scan_date, limit=10)
        
        print(f"ğŸ† {scan_date} ìƒìœ„ ì„±ê³¼ ì¢…ëª©:")
        for perf in performers:
            change = perf.get('change_percent', 0)
            print(f"  - {perf['symbol']}: {change:+.2f}% (${perf['close_price']:.2f})")
        
        context['task_instance'].xcom_push(key='top_performers', value=len(performers))
        
        scanner.close()
        return f"âœ… ìƒìœ„ ì„±ê³¼ ì¡°íšŒ ì™„ë£Œ: {len(performers)}ê°œ"
        
    except Exception as e:
        print(f"âŒ ìƒìœ„ ì„±ê³¼ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")
        raise

def send_watchlist_summary(**context):
    """ê´€ì‹¬ì¢…ëª© ìš”ì•½ ì •ë³´ ì¶œë ¥ (PostgreSQL)"""
    
    # ì´ì „ íƒœìŠ¤í¬ì—ì„œ ê²°ê³¼ ê°€ì ¸ì˜¤ê¸°
    watchlist_count = context['task_instance'].xcom_pull(task_ids='scan_bollinger_bands', key='watchlist_count') or 0
    rsi_count = context['task_instance'].xcom_pull(task_ids='scan_rsi_oversold', key='rsi_count') or 0
    macd_count = context['task_instance'].xcom_pull(task_ids='scan_macd_bullish', key='macd_count') or 0
    top_performers = context['task_instance'].xcom_pull(task_ids='get_top_performers', key='top_performers') or 0
    scan_date = context['task_instance'].xcom_pull(task_ids='scan_bollinger_bands', key='scan_date')
    
    print(f"""
    ğŸ“Š ì¼ë³„ ê´€ì‹¬ì¢…ëª© ìŠ¤ìº” ê²°ê³¼ ({scan_date}) - PostgreSQL
    ================================
    ğŸ¯ ë³¼ë¦°ì € ë°´ë“œ ìƒë‹¨ í„°ì¹˜: {watchlist_count}ê°œ
    ğŸ“‰ RSI ê³¼ë§¤ë„ ì‹ í˜¸: {rsi_count}ê°œ
    ğŸ“ˆ MACD ê°•ì„¸ ì‹ í˜¸: {macd_count}ê°œ
    ğŸ† ìƒìœ„ ì„±ê³¼ ì¢…ëª©: {top_performers}ê°œ
    ğŸ“… ìŠ¤ìº” ë‚ ì§œ: {scan_date}
    â° ì²˜ë¦¬ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
    ğŸ’¾ ë°ì´í„°ë² ì´ìŠ¤: PostgreSQL
    """)
    
    return f"ìš”ì•½ ì „ì†¡ ì™„ë£Œ"

def sync_watchlist_to_redis(**context):
    """PostgreSQL ê´€ì‹¬ì¢…ëª©ì„ Redisë¡œ ë™ê¸°í™”"""
    try:
        from database import PostgreSQLManager
        import redis
        import json
        from datetime import date, timedelta
        
        print("ğŸš€ PostgreSQL â†’ Redis ê´€ì‹¬ì¢…ëª© ë™ê¸°í™” ì‹œì‘...")
        
        # PostgreSQL ì—°ê²°
        db = PostgreSQLManager()
        print("âœ… PostgreSQL ì—°ê²° ì„±ê³µ")
        
        # Redis ì—°ê²° (ë‹¤ì–‘í•œ ì£¼ì†Œ ì‹œë„)
        redis_client = None
        redis_hosts = [
            {'host': 'redis', 'port': 6379},      # Docker ì»¨í…Œì´ë„ˆëª…
            {'host': 'localhost', 'port': 6379},   # ë¡œì»¬í˜¸ìŠ¤íŠ¸
            {'host': '127.0.0.1', 'port': 6379},   # IP ì£¼ì†Œ
        ]
        
        for redis_config in redis_hosts:
            try:
                test_client = redis.Redis(
                    host=redis_config['host'],
                    port=redis_config['port'],
                    db=0,
                    decode_responses=True,
                    socket_connect_timeout=5,  # 5ì´ˆ íƒ€ì„ì•„ì›ƒ
                    socket_timeout=5
                )
                # ì—°ê²° í…ŒìŠ¤íŠ¸
                test_client.ping()
                redis_client = test_client
                print(f"âœ… Redis ì—°ê²° ì„±ê³µ: {redis_config['host']}:{redis_config['port']}")
                break
            except Exception as e:
                print(f"âš ï¸ Redis ì—°ê²° ì‹¤íŒ¨ ({redis_config['host']}:{redis_config['port']}): {e}")
                continue
        
        if redis_client is None:
            print("âš ï¸ Redis ì„œë²„ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. PostgreSQLë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤.")
            # Redis ì—†ì´ë„ ê³„ì† ì§„í–‰
            redis_client = None
        
        # ìµœê·¼ 3ì¼ê°„ì˜ ê´€ì‹¬ì¢…ëª© ì¡°íšŒ (ë°°ì¹˜ ëˆ„ë½ ëŒ€ë¹„)
        today = date.today()
        start_date = today - timedelta(days=3)
        
        query = """
            SELECT DISTINCT 
                symbol, 
                date, 
                condition_type, 
                condition_value,
                created_at
            FROM daily_watchlist 
            WHERE date >= %s
            ORDER BY date DESC, symbol
        """
        
        redis_updated = 0
        
        with db.get_connection() as conn:
            with conn.cursor() as cur:
                cur.execute(query, (start_date,))
                results = cur.fetchall()
                
                print(f"ğŸ“Š PostgreSQLì—ì„œ ì¡°íšŒëœ ê´€ì‹¬ì¢…ëª©: {len(results)}ê°œ")
                
                # ë‚ ì§œë³„ë¡œ ê·¸ë£¹í™”
                watchlist_by_date = {}
                for row in results:
                    symbol, date_val, condition_type, condition_value, created_at = row
                    date_str = date_val.strftime('%Y-%m-%d')
                    
                    if date_str not in watchlist_by_date:
                        watchlist_by_date[date_str] = {}
                    
                    if symbol not in watchlist_by_date[date_str]:
                        watchlist_by_date[date_str][symbol] = {
                            'symbol': symbol,
                            'conditions': [],
                            'date': date_str,
                            'last_updated': created_at.isoformat() if created_at else None
                        }
                    
                    watchlist_by_date[date_str][symbol]['conditions'].append({
                        'type': condition_type,
                        'value': float(condition_value)
                    })
        
        # Redisì— ì €ì¥ (Redisê°€ ìˆëŠ” ê²½ìš°ì—ë§Œ)
        redis_updated = 0
        if redis_client is not None:
            for date_str, symbols_data in watchlist_by_date.items():
                try:
                    # ë‚ ì§œë³„ ê´€ì‹¬ì¢…ëª© í‚¤
                    redis_key = f"watchlist:{date_str}"
                    
                    # ê¸°ì¡´ Redis ë°ì´í„°ì™€ ë¹„êµ
                    existing_data = redis_client.get(redis_key)
                    existing_symbols = set()
                    
                    if existing_data:
                        try:
                            existing_dict = json.loads(existing_data)
                            existing_symbols = set(existing_dict.keys())
                        except:
                            pass
                    
                    # ìƒˆë¡œìš´ ì‹¬ë³¼ì´ ìˆëŠ”ì§€ í™•ì¸
                    new_symbols = set(symbols_data.keys()) - existing_symbols
                    
                    if new_symbols or not existing_data:
                        # Redisì— ì €ì¥ (JSON í˜•íƒœ)
                        redis_data = json.dumps(symbols_data, ensure_ascii=False, indent=2)
                        redis_client.setex(redis_key, 86400 * 7, redis_data)  # 7ì¼ TTL
                        
                        redis_updated += 1
                        print(f"âœ… Redis ì—…ë°ì´íŠ¸: {date_str} - {len(symbols_data)}ê°œ ì‹¬ë³¼")
                        
                        if new_symbols:
                            print(f"   ğŸ†• ìƒˆë¡œìš´ ì‹¬ë³¼: {', '.join(list(new_symbols)[:5])}{'...' if len(new_symbols) > 5 else ''}")
                    else:
                        print(f"â­ï¸  Redis ìŠ¤í‚µ: {date_str} - ë³€ê²½ì‚¬í•­ ì—†ìŒ")
                    
                    # ìµœì‹  ê´€ì‹¬ì¢…ëª© (ì˜¤ëŠ˜) ë³„ë„ í‚¤ë¡œ ì €ì¥
                    if date_str == today.strftime('%Y-%m-%d'):
                        latest_key = "watchlist:latest"
                        redis_client.setex(latest_key, 86400, redis_data)  # 1ì¼ TTL
                        print(f"âœ… ìµœì‹  ê´€ì‹¬ì¢…ëª© ì—…ë°ì´íŠ¸: {len(symbols_data)}ê°œ ì‹¬ë³¼")
                    
                except Exception as e:
                    print(f"âŒ Redis ì €ì¥ ì˜¤ë¥˜ ({date_str}): {e}")
        else:
            print("âš ï¸ Redis ë¯¸ì‚¬ìš© - PostgreSQLì—ë§Œ ì €ì¥ë¨")
        
        # í†µê³„ ì •ë³´ Redisì— ì €ì¥ (Redisê°€ ìˆëŠ” ê²½ìš°ì—ë§Œ)
        stats = {
            'total_dates': len(watchlist_by_date),
            'total_symbols': sum(len(symbols) for symbols in watchlist_by_date.values()),
            'last_sync': datetime.now().isoformat(),
            'redis_updates': redis_updated,
            'redis_available': redis_client is not None
        }
        
        if redis_client is not None:
            try:
                redis_client.setex("watchlist:stats", 3600, json.dumps(stats))  # 1ì‹œê°„ TTL
                print("âœ… Redis í†µê³„ ì €ì¥ ì™„ë£Œ")
            except Exception as e:
                print(f"âš ï¸ Redis í†µê³„ ì €ì¥ ì‹¤íŒ¨: {e}")
        
        print(f"âœ… PostgreSQL â†’ Redis ë™ê¸°í™” ì™„ë£Œ:")
        print(f"  - ì²˜ë¦¬ëœ ë‚ ì§œ: {len(watchlist_by_date)}ê°œ")
        print(f"  - ì´ ì‹¬ë³¼ ìˆ˜: {stats['total_symbols']}ê°œ")
        print(f"  - Redis ì—…ë°ì´íŠ¸: {redis_updated}ê°œ")
        print(f"  - Redis ì‚¬ìš© ê°€ëŠ¥: {'ì˜ˆ' if redis_client else 'ì•„ë‹ˆì˜¤'}")
        
        # XComì— ê²°ê³¼ ì €ì¥
        context['task_instance'].xcom_push(key='redis_sync_count', value=redis_updated)
        context['task_instance'].xcom_push(key='total_symbols', value=stats['total_symbols'])
        
        db.close()
        if redis_client is not None:
            redis_client.close()
        
        return f"âœ… ë™ê¸°í™” ì™„ë£Œ: Redis {redis_updated}ê°œ ì—…ë°ì´íŠ¸, PostgreSQL {stats['total_symbols']}ê°œ ì‹¬ë³¼"
        
    except Exception as e:
        print(f"âŒ ë™ê¸°í™” ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        raise

def generate_additional_watchlist(**context):
    """ì¶”ê°€ ê´€ì‹¬ì¢…ëª© ìƒì„± (ë°°ì¹˜ ëˆ„ë½ ëŒ€ë¹„)"""
    try:
        from database import PostgreSQLManager
        from datetime import date, timedelta
        
        print("ğŸš€ ì¶”ê°€ ê´€ì‹¬ì¢…ëª© ìƒì„± ì‹œì‘...")
        
        # PostgreSQL ì—°ê²°
        db = PostgreSQLManager()
        print("âœ… PostgreSQL ì—°ê²° ì„±ê³µ")
        
        today = date.today()
        
        # ì˜¤ëŠ˜ ê´€ì‹¬ì¢…ëª©ì´ ìˆëŠ”ì§€ í™•ì¸
        with db.get_connection() as conn:
            with conn.cursor() as cur:
                cur.execute("""
                    SELECT COUNT(*) 
                    FROM daily_watchlist 
                    WHERE date = %s
                """, (today,))
                
                today_count = cur.fetchone()[0]
                
                if today_count > 0:
                    print(f"ğŸ“… ì˜¤ëŠ˜ ê´€ì‹¬ì¢…ëª©ì´ ì´ë¯¸ ìˆìŠµë‹ˆë‹¤: {today_count}ê°œ")
                    context['task_instance'].xcom_push(key='additional_generated', value=0)
                    db.close()
                    return f"âœ… ì´ë¯¸ ì¡´ì¬: {today_count}ê°œ"
        
        print("ğŸ” ì˜¤ëŠ˜ ê´€ì‹¬ì¢…ëª©ì´ ì—†ìŠµë‹ˆë‹¤. ì¶”ê°€ ìƒì„±ì„ ì‹œë„í•©ë‹ˆë‹¤...")
        
        # ì‹¤ì‹œê°„ ê´€ì‹¬ì¢…ëª© ì¡°ê±´ë“¤
        realtime_conditions = [
            {
                'name': 'price_momentum',
                'query': """
                    SELECT DISTINCT s.symbol, s.close, 
                           (s.close - prev.close) / prev.close * 100 as price_change
                    FROM stock_data s
                    JOIN stock_data prev ON s.symbol = prev.symbol 
                        AND prev.date = s.date - INTERVAL '1 day'
                    WHERE s.date >= CURRENT_DATE - INTERVAL '2 days'
                      AND s.close > 5  -- ìµœì†Œ ê°€ê²© í•„í„°
                      AND s.volume > 100000  -- ìµœì†Œ ê±°ë˜ëŸ‰
                      AND ABS((s.close - prev.close) / prev.close * 100) > 3  -- 3% ì´ìƒ ë³€í™”
                    ORDER BY ABS((s.close - prev.close) / prev.close) DESC
                    LIMIT 30
                """
            },
            {
                'name': 'volume_breakout',
                'query': """
                    SELECT DISTINCT s1.symbol, s1.close, s1.volume
                    FROM stock_data s1
                    JOIN stock_data s2 ON s1.symbol = s2.symbol 
                        AND s2.date BETWEEN s1.date - INTERVAL '10 days' AND s1.date - INTERVAL '1 day'
                    WHERE s1.date >= CURRENT_DATE - INTERVAL '2 days'
                      AND s1.volume > 50000
                    GROUP BY s1.symbol, s1.close, s1.volume
                    HAVING s1.volume > AVG(s2.volume) * 1.5  -- 1.5ë°° ì´ìƒ
                    ORDER BY s1.volume / AVG(s2.volume) DESC
                    LIMIT 25
                """
            }
        ]
        
        total_added = 0
        
        for condition in realtime_conditions:
            try:
                with db.get_connection() as conn:
                    with conn.cursor() as cur:
                        cur.execute(condition['query'])
                        results = cur.fetchall()
                        
                        added_count = 0
                        for row in results:
                            try:
                                # ì˜¤ëŠ˜ ë‚ ì§œë¡œ ì¶”ê°€
                                cur.execute("""
                                    INSERT INTO daily_watchlist (symbol, date, condition_type, condition_value)
                                    VALUES (%s, %s, %s, %s)
                                    ON CONFLICT (symbol, date, condition_type) DO NOTHING
                                """, (row[0], today, condition['name'], float(row[1])))
                                
                                if cur.rowcount > 0:
                                    added_count += 1
                                
                            except Exception as e:
                                print(f"âš ï¸ {row[0]}: ê´€ì‹¬ì¢…ëª© ì €ì¥ ì˜¤ë¥˜ - {e}")
                        
                        conn.commit()
                        total_added += added_count
                        print(f"âœ… {condition['name']}: {added_count}ê°œ ì¶”ê°€")
                        
            except Exception as e:
                print(f"âŒ {condition['name']} ì¡°ê±´ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
        
        context['task_instance'].xcom_push(key='additional_generated', value=total_added)
        
        db.close()
        
        if total_added > 0:
            print(f"âœ… ì¶”ê°€ ê´€ì‹¬ì¢…ëª© ìƒì„± ì™„ë£Œ: ì´ {total_added}ê°œ")
        else:
            print("âš ï¸ ì¶”ê°€í•  ê´€ì‹¬ì¢…ëª©ì´ ì—†ìŠµë‹ˆë‹¤.")
        
        return f"âœ… ì¶”ê°€ ìƒì„±: {total_added}ê°œ"
        
    except Exception as e:
        print(f"âŒ ì¶”ê°€ ê´€ì‹¬ì¢…ëª© ìƒì„± ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        raise

# DAG ê¸°ë³¸ ì„¤ì •
default_args = {
    'owner': 'stock-team',
    'depends_on_past': False,
    'start_date': datetime(2024, 1, 1),
    'email_on_failure': False,
    'email_on_retry': False,
    'retries': 1,
    'retry_delay': timedelta(minutes=5),
}

# DAG ì •ì˜
dag = DAG(
    'daily_watchlist_scanner_postgres',
    default_args=default_args,
    description='ì¼ë³„ ê¸°ìˆ ì  ì§€í‘œ ê¸°ë°˜ ê´€ì‹¬ì¢…ëª© ìŠ¤ìº” ë° Redis ë™ê¸°í™” (PostgreSQL)',
    schedule_interval='*/30 * * * *',  # 30ë¶„ë§ˆë‹¤ ì‹¤í–‰ (ì§€ì†ì  ëª¨ë‹ˆí„°ë§)
    catchup=False,
    max_active_runs=1,
    tags=['watchlist', 'postgresql', 'redis', 'technical-analysis']
)

# íƒœìŠ¤í¬ ì •ì˜
scan_bollinger_task = PythonOperator(
    task_id='scan_bollinger_bands',
    python_callable=scan_and_update_watchlist,
    dag=dag,
    doc_md="""
    ## ë³¼ë¦°ì € ë°´ë“œ ìƒë‹¨ í„°ì¹˜ ì¢…ëª© ìŠ¤ìº” (PostgreSQL)
    
    - ì „ì¼ ì¢…ê°€ ê¸°ì¤€ìœ¼ë¡œ ë³¼ë¦°ì € ë°´ë“œ ìƒë‹¨ì„  98% ì´ìƒ í„°ì¹˜í•œ ì¢…ëª© ê²€ìƒ‰
    - ì‹œê°€ì´ì•¡ë³„ í‹°ì–´ ë¶„ë¥˜ (ëŒ€í˜•ì£¼: 1, ì¤‘í˜•ì£¼: 2, ì†Œí˜•ì£¼: 3)
    - daily_watchlist í…Œì´ë¸”ì— ê²°ê³¼ ì €ì¥
    """
)

scan_rsi_task = PythonOperator(
    task_id='scan_rsi_oversold',
    python_callable=scan_rsi_oversold,
    dag=dag,
    doc_md="""
    ## RSI ê³¼ë§¤ë„ ì¢…ëª© ìŠ¤ìº” (PostgreSQL)
    
    - RSI 30 ì´í•˜ ê³¼ë§¤ë„ ì¢…ëª© ê²€ìƒ‰
    - ì ì¬ì  ë°˜ë“± í›„ë³´ ì¢…ëª© ì‹ë³„
    """
)

scan_macd_task = PythonOperator(
    task_id='scan_macd_bullish',
    python_callable=scan_macd_bullish,
    dag=dag,
    doc_md="""
    ## MACD ê°•ì„¸ ì¢…ëª© ìŠ¤ìº” (PostgreSQL)
    
    - MACD ë¼ì¸ì´ ì‹œê·¸ë„ ë¼ì¸ ìœ„ì— ìˆê³  ì–‘ìˆ˜ì¸ ì¢…ëª© ê²€ìƒ‰
    - ê°•ì„¸ ëª¨ë©˜í…€ ì¢…ëª© ì‹ë³„
    """
)

top_performers_task = PythonOperator(
    task_id='get_top_performers',
    python_callable=get_top_performers,
    dag=dag,
    doc_md="""
    ## ìƒìœ„ ì„±ê³¼ ì¢…ëª© ì¡°íšŒ (PostgreSQL)
    
    - ì „ì¼ ëŒ€ë¹„ ìƒìŠ¹ë¥  ìƒìœ„ ì¢…ëª© ì¡°íšŒ
    - ê±°ë˜ëŸ‰ ì¡°ê±´ ì ìš© (ìµœì†Œ 10ë§Œì£¼)
    """
)

cleanup_task = PythonOperator(
    task_id='cleanup_old_data',
    python_callable=cleanup_old_watchlist,
    dag=dag,
    doc_md="""
    ## ì˜¤ë˜ëœ ê´€ì‹¬ì¢…ëª© ë°ì´í„° ì •ë¦¬ (PostgreSQL)
    
    - 30ì¼ ì´ì „ ê´€ì‹¬ì¢…ëª© ë°ì´í„° ì‚­ì œ
    - ë°ì´í„°ë² ì´ìŠ¤ ìš©ëŸ‰ ê´€ë¦¬
    """
)

summary_task = PythonOperator(
    task_id='send_summary',
    python_callable=send_watchlist_summary,
    dag=dag,
    doc_md="""
    ## ìŠ¤ìº” ê²°ê³¼ ìš”ì•½ (PostgreSQL)
    
    - ëª¨ë“  ìŠ¤ìº” ê²°ê³¼ í†µê³„ ì¶œë ¥
    - ë¡œê·¸ì— ìš”ì•½ ì •ë³´ ê¸°ë¡
    """
)

# ìƒˆë¡œìš´ íƒœìŠ¤í¬ë“¤ ì¶”ê°€
generate_additional_task = PythonOperator(
    task_id='generate_additional_watchlist',
    python_callable=generate_additional_watchlist,
    dag=dag,
    doc_md="""
    ## ì¶”ê°€ ê´€ì‹¬ì¢…ëª© ìƒì„±
    
    - ë°°ì¹˜ ëˆ„ë½ ëŒ€ë¹„ ì¶”ê°€ ê´€ì‹¬ì¢…ëª© ìƒì„±
    - ì‹¤ì‹œê°„ ì¡°ê±´ìœ¼ë¡œ ê´€ì‹¬ì¢…ëª© ë°œêµ´
    """
)

redis_sync_task = PythonOperator(
    task_id='sync_to_redis',
    python_callable=sync_watchlist_to_redis,
    dag=dag,
    doc_md="""
    ## PostgreSQL â†’ Redis ë™ê¸°í™”
    
    - PostgreSQL ê´€ì‹¬ì¢…ëª©ì„ Redisë¡œ ë™ê¸°í™”
    - ìµœê·¼ 3ì¼ê°„ ë°ì´í„° í™•ì¸ ë° ì—…ë°ì´íŠ¸
    - ì§€ì†ì  ëª¨ë‹ˆí„°ë§ìœ¼ë¡œ ëˆ„ë½ ë°©ì§€
    """
)

# íƒœìŠ¤í¬ ì˜ì¡´ì„± ì„¤ì • (ExternalTaskSensor ì œê±°í•˜ê³  ë…ë¦½ì ìœ¼ë¡œ ì‹¤í–‰)
# ì¶”ê°€ ê´€ì‹¬ì¢…ëª© ìƒì„± â†’ ê¸°ì¡´ ìŠ¤ìº”ë“¤ê³¼ ë³‘ë ¬ ì‹¤í–‰ â†’ Redis ë™ê¸°í™” â†’ ì •ë¦¬ â†’ ìš”ì•½
generate_additional_task >> [scan_bollinger_task, scan_rsi_task, scan_macd_task, top_performers_task]
[scan_bollinger_task, scan_rsi_task, scan_macd_task, top_performers_task] >> redis_sync_task >> cleanup_task >> summary_task
