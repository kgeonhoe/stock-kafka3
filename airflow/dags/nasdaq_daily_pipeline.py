#!/usr/bin/env python3
# -*- coding: utf-8 -*-

from airflow import DAG
from airflow.operators.python import PythonOperator
from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
from airflow.operators.trigger_dagrun import TriggerDagRunOperator
from datetime import datetime, timedelta
import sys
import os

# í”ŒëŸ¬ê·¸ì¸ ê²½ë¡œ ì¶”ê°€
sys.path.insert(0, '/opt/airflow/plugins')
sys.path.insert(0, '/opt/airflow/common')
sys.path.insert(0, '/opt/airflow/dags')

# í”ŒëŸ¬ê·¸ì¸ ìž„í¬íŠ¸
from collect_nasdaq_symbols_api import NasdaqSymbolCollector
from collect_stock_data_yfinance import collect_stock_data_yfinance_task
from technical_indicators import calculate_technical_indicators_task
from database import DuckDBManager
from utils.dag_coordination import BulkCollectionSensor, check_api_rate_limits

# ê¸°ë³¸ ì¸ìˆ˜ ì„¤ì •
default_args = {
    'owner': 'data-team',
    'depends_on_past': False,
    'start_date': datetime(2024, 1, 1),
    'retries': 1,
    'retry_delay': timedelta(minutes=5),
}

# DAG ì •ì˜
dag = DAG(
    'nasdaq_daily_pipeline',
    default_args=default_args,
    description='ðŸš€ ë‚˜ìŠ¤ë‹¥ ì™„ì „ íŒŒì´í”„ë¼ì¸: ìˆ˜ì§‘â†’ë¶„ì„â†’ìŠ¤ìº”â†’ë³µì œ (Kafka Ready)',
    schedule_interval='0 7 * * *',  # í•œêµ­ì‹œê°„ ì˜¤ì „ 7ì‹œ (ë¯¸êµ­ ìž¥ë§ˆê° í›„)
    catchup=False,
    max_active_runs=1,
    tags=['nasdaq', 'stock', 'spark', 'technical-analysis', 'watchlist', 'kafka']
)

# ë°ì´í„°ë² ì´ìŠ¤ ê²½ë¡œ
DB_PATH = "/data/duckdb/stock_data.db"

# 1. ë‚˜ìŠ¤ë‹¥ ì‹¬ë³¼ ìˆ˜ì§‘
def collect_nasdaq_symbols_func(**kwargs):
    """ë‚˜ìŠ¤ë‹¥ ì‹¬ë³¼ ìˆ˜ì§‘ í•¨ìˆ˜"""
    import sys
    sys.path.insert(0, '/opt/airflow/common')
    from database import DuckDBManager
    
    print("ðŸƒ ë‚˜ìŠ¤ë‹¥ ì‹¬ë³¼ ìˆ˜ì§‘ ì‹œìž‘...")
    
    db = None
    collector = None
    
    try:
        # DuckDB ì—°ê²° (ìƒˆ íŒŒì¼ ìƒì„±)
        print(f"ðŸ“ ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°: {DB_PATH}")
        db = DuckDBManager(DB_PATH)
        print("âœ… DuckDB ì—°ê²° ì„±ê³µ")
        
        # DB íŒŒì¼ ê¶Œí•œ ì„¤ì •
        if os.path.exists(DB_PATH):
            try:
                os.chmod(DB_PATH, 0o666)
                print("âœ… DB íŒŒì¼ ê¶Œí•œ ì„¤ì • ì™„ë£Œ (666)")
            except PermissionError as pe:
                print(f"âš ï¸ ê¶Œí•œ ë³€ê²½ ì‹¤íŒ¨ (ë¬´ì‹œí•˜ê³  ê³„ì†): {pe}")
                current_permissions = oct(os.stat(DB_PATH).st_mode)[-3:]
                print(f"ðŸ“‹ í˜„ìž¬ ê¶Œí•œìœ¼ë¡œ ì§„í–‰: {current_permissions}")
        
        # ì‹¤ì œ ë‚˜ìŠ¤ë‹¥ API ìˆ˜ì§‘ ì‹œë„
        print("ðŸ”§ ë‚˜ìŠ¤ë‹¥ API ì»¬ë ‰í„° ì´ˆê¸°í™”...")
        collector = NasdaqSymbolCollector()
        
        # ì¦ë¶„ ì—…ë°ì´íŠ¸ í™•ì¸ - ì˜¤ëŠ˜ ì´ë¯¸ ìˆ˜ì§‘í–ˆëŠ”ì§€ ì²´í¬
        if db.is_nasdaq_symbols_collected_today():
            last_collected = db.get_nasdaq_symbols_last_collected_date()
            print(f"âœ… ì˜¤ëŠ˜({last_collected}) ì´ë¯¸ NASDAQ ì‹¬ë³¼ ìˆ˜ì§‘ ì™„ë£Œ - ìŠ¤í‚µ")
            print("ðŸ’¡ ì¦ë¶„ ì—…ë°ì´íŠ¸: ë¶ˆí•„ìš”í•œ API í˜¸ì¶œ ë°©ì§€")
            
            # ê¸°ì¡´ ì‹¬ë³¼ ì¡°íšŒí•´ì„œ ë°˜í™˜
            existing_symbols_query = "SELECT symbol, name, market_cap, sector FROM nasdaq_symbols"
            existing_df = db.execute_query(existing_symbols_query)
            
            if not existing_df.empty:
                result_symbols = existing_df.to_dict('records')
                print(f"ðŸ“‹ ê¸°ì¡´ ì‹¬ë³¼ ì‚¬ìš©: {len(result_symbols)}ê°œ")
                return result_symbols
            else:
                print("âš ï¸ ê¸°ì¡´ ì‹¬ë³¼ì´ ì—†ì–´ì„œ ìƒˆë¡œ ìˆ˜ì§‘ ì§„í–‰")
        
        try:
            print("ðŸ“Š ë‚˜ìŠ¤ë‹¥ APIì—ì„œ ì¢…ëª© ë°ì´í„° ìˆ˜ì§‘ ì¤‘...")
            symbols = collector.collect_symbols()
            
            if symbols and len(symbols) > 0:
                print(f"ðŸ“ˆ APIì—ì„œ ìˆ˜ì§‘ëœ ì‹¬ë³¼ ìˆ˜: {len(symbols)}ê°œ")
                
                # ì²« ë²ˆì§¸ ì¢…ëª© ìƒ˜í”Œ ë°ì´í„° í™•ì¸
                if len(symbols) > 0:
                    sample = symbols[0]
                    print(f"ðŸ” ìƒ˜í”Œ ë°ì´í„° êµ¬ì¡°: {sample}")
                    print(f"ðŸ” ì‚¬ìš© ê°€ëŠ¥í•œ í‚¤ë“¤: {list(sample.keys())}")
                
                # ì „ì²´ ì¢…ëª© ì €ìž¥ (í•„í„°ë§ ì—†ìŒ)
                print("ðŸ’¾ ì „ì²´ ì¢…ëª©ì„ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ìž¥ ì¤‘...")
                db.save_nasdaq_symbols(symbols)
                
                result_symbols = symbols
                print(f"âœ… ì „ì²´ {len(symbols)}ê°œ ì¢…ëª© ì €ìž¥ ì™„ë£Œ")
            else:
                raise Exception("APIì—ì„œ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŒ")
                
        except Exception as api_error:
            print(f"âš ï¸ API ìˆ˜ì§‘ ì‹¤íŒ¨: {api_error}")
            print("ðŸ”„ ë°±ì—… ë°ì´í„°ë¡œ ì „í™˜...")
            
            # ë°±ì—…ìš© ì£¼ìš” ì¢…ëª© ë°ì´í„° (ì‹¤ì œ ëŒ€í˜•ì£¼ë“¤)
            backup_symbols = [
                {'symbol': 'AAPL', 'name': 'Apple Inc.', 'marketCap': '3500000000000', 'sector': 'Technology'},
                {'symbol': 'MSFT', 'name': 'Microsoft Corporation', 'marketCap': '3000000000000', 'sector': 'Technology'},
                {'symbol': 'GOOGL', 'name': 'Alphabet Inc.', 'marketCap': '2000000000000', 'sector': 'Technology'},
                {'symbol': 'AMZN', 'name': 'Amazon.com Inc.', 'marketCap': '1800000000000', 'sector': 'Consumer Discretionary'},
                {'symbol': 'TSLA', 'name': 'Tesla Inc.', 'marketCap': '800000000000', 'sector': 'Consumer Discretionary'},
                {'symbol': 'META', 'name': 'Meta Platforms Inc.', 'marketCap': '900000000000', 'sector': 'Technology'},
                {'symbol': 'NVDA', 'name': 'NVIDIA Corporation', 'marketCap': '1200000000000', 'sector': 'Technology'},
                {'symbol': 'NFLX', 'name': 'Netflix Inc.', 'marketCap': '200000000000', 'sector': 'Communication Services'},
                {'symbol': 'AMD', 'name': 'Advanced Micro Devices', 'marketCap': '250000000000', 'sector': 'Technology'},
                {'symbol': 'INTC', 'name': 'Intel Corporation', 'marketCap': '180000000000', 'sector': 'Technology'}
            ]
            
            print(f"ðŸ“ˆ ë°±ì—… ì‹¬ë³¼ ìˆ˜: {len(backup_symbols)}ê°œ")
            db.save_nasdaq_symbols(backup_symbols)
            result_symbols = backup_symbols
        
        print("âœ… ë°ì´í„°ë² ì´ìŠ¤ ì €ìž¥ ì™„ë£Œ")
        
        # ì €ìž¥ëœ ë°ì´í„° í™•ì¸
        print("ðŸ” ì €ìž¥ëœ ë°ì´í„° í™•ì¸...")
        saved_symbols = db.get_active_symbols()
        print(f"ðŸ“Š ì €ìž¥ëœ ì‹¬ë³¼: {saved_symbols}")
        
        # ìˆ˜ì§‘ ê²°ê³¼ ë°˜í™˜
        result = {
            'total_symbols': len(result_symbols),
            'filtered_symbols': len(result_symbols),
            'saved_symbols': len(saved_symbols),
            'timestamp': datetime.now().isoformat()
        }
        
        print(f"ðŸŽ‰ ë‚˜ìŠ¤ë‹¥ ì‹¬ë³¼ ìˆ˜ì§‘ ì™„ë£Œ!")
        print(f"ðŸ“Š ê²°ê³¼: {result}")
        
        if db:
            db.close()
        return result
    
    except Exception as e:
        print(f"âŒ ì‹¬ë³¼ ìˆ˜ì§‘ ì˜¤ë¥˜: {e}")
        print(f"ðŸ” ì˜¤ë¥˜ íƒ€ìž…: {type(e).__name__}")
        import traceback
        print(f"ðŸ“œ ìƒì„¸ ì˜¤ë¥˜:\n{traceback.format_exc()}")
        
        if db:
            db.close()
        raise
        
# 2. ì£¼ê°€ ë°ì´í„° ìˆ˜ì§‘
def collect_ohlcv_func(**kwargs):
    """yfinance ê¸°ë°˜ ì£¼ê°€ ë°ì´í„° ìˆ˜ì§‘ í•¨ìˆ˜"""
    print("ðŸ“Š yfinance ê¸°ë°˜ ì£¼ê°€ ë°ì´í„° ìˆ˜ì§‘ ì‹œìž‘...")
    
    # ë””ë²„ê¹…: DuckDBì—ì„œ ì‹¬ë³¼ ì¡°íšŒ
    import sys
    sys.path.insert(0, '/opt/airflow/common')
    from database import DuckDBManager
    
    try:
        # DB ë””ë ‰í† ë¦¬ ë° íŒŒì¼ ê¶Œí•œ í™•ì¸/ì„¤ì •
        import stat
        db_dir = os.path.dirname(DB_PATH)
        
        # ë””ë ‰í† ë¦¬ ê¶Œí•œ í™•ì¸
        if os.path.exists(db_dir):
            dir_permissions = oct(os.stat(db_dir).st_mode)[-3:]
            print(f"ðŸ” DB ë””ë ‰í† ë¦¬ ê¶Œí•œ: {dir_permissions}")
            
            try:
                os.chmod(db_dir, 0o777)
                print(f"âœ… ë””ë ‰í† ë¦¬ ê¶Œí•œ ìˆ˜ì •: 777")
            except PermissionError as pe:
                print(f"âš ï¸ ë””ë ‰í† ë¦¬ ê¶Œí•œ ë³€ê²½ ì‹¤íŒ¨: {pe}")
        else:
            print(f"âš ï¸ DB ë””ë ‰í† ë¦¬ê°€ ì¡´ìž¬í•˜ì§€ ì•ŠìŒ: {db_dir}")
            try:
                os.makedirs(db_dir, mode=0o777, exist_ok=True)
                print(f"âœ… DB ë””ë ‰í† ë¦¬ ìƒì„±: {db_dir}")
            except Exception as e:
                print(f"âš ï¸ ë””ë ‰í† ë¦¬ ìƒì„± ì‹¤íŒ¨: {e}")
        
        # DB íŒŒì¼ ê¶Œí•œ í™•ì¸ ë° ìˆ˜ì •
        if os.path.exists(DB_PATH):
            current_permissions = oct(os.stat(DB_PATH).st_mode)[-3:]
            print(f"ðŸ” í˜„ìž¬ DB íŒŒì¼ ê¶Œí•œ: {current_permissions}")
            
            try:
                os.chmod(DB_PATH, 0o666)
                print(f"âœ… DB íŒŒì¼ ê¶Œí•œ ìˆ˜ì •: 666")
            except PermissionError as pe:
                print(f"âš ï¸ íŒŒì¼ ê¶Œí•œ ë³€ê²½ ì‹¤íŒ¨ (ë¬´ì‹œí•˜ê³  ê³„ì†): {pe}")
                print(f"ðŸ“‹ í˜„ìž¬ ê¶Œí•œìœ¼ë¡œ ì§„í–‰: {current_permissions}")
        else:
            print(f"âš ï¸ DB íŒŒì¼ì´ ì¡´ìž¬í•˜ì§€ ì•ŠìŒ: {DB_PATH}")
            # ë¹ˆ íŒŒì¼ ìƒì„± ì‹œë„
            try:
                with open(DB_PATH, 'a'):
                    pass
                os.chmod(DB_PATH, 0o666)
                print(f"âœ… DB íŒŒì¼ ìƒì„± ë° ê¶Œí•œ ì„¤ì • ì™„ë£Œ")
            except Exception as e:
                print(f"âš ï¸ DB íŒŒì¼ ìƒì„± ì‹¤íŒ¨: {e}")
        
        # DB ì—°ê²° ì‹œë„
        print(f"ðŸ”— DuckDB ì—°ê²° ì‹œë„: {DB_PATH}")
        db = DuckDBManager(DB_PATH)
        saved_symbols = db.get_active_symbols()
        print(f"ðŸ” DBì—ì„œ ì¡°íšŒëœ ì‹¬ë³¼: {saved_symbols}")
        print(f"ðŸ” ì‹¬ë³¼ íƒ€ìž…: {type(saved_symbols)}")
        print(f"ðŸ” ì‹¬ë³¼ ê°œìˆ˜: {len(saved_symbols) if saved_symbols else 0}")
        
        if saved_symbols and len(saved_symbols) > 0:
            print(f"ðŸ” ì²« ë²ˆì§¸ ì‹¬ë³¼: {saved_symbols[0]}")
            print(f"ðŸ” ì²« ë²ˆì§¸ ì‹¬ë³¼ íƒ€ìž…: {type(saved_symbols[0])}")
        
        db.close()
        
        # ì›ëž˜ í•¨ìˆ˜ í˜¸ì¶œ
        result = collect_stock_data_yfinance_task(**kwargs)
        print(f"âœ… yfinance ì£¼ê°€ ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ: {result}")
        return result
    except Exception as e:
        print(f"âŒ yfinance ì£¼ê°€ ë°ì´í„° ìˆ˜ì§‘ ì˜¤ë¥˜: {e}")
        import traceback
        print(f"ðŸ“œ ìƒì„¸ ì˜¤ë¥˜:\n{traceback.format_exc()}")
        raise

# 3. ê¸°ìˆ ì  ì§€í‘œ ê³„ì‚°
def calculate_indicators_func(**kwargs):
    """ê¸°ìˆ ì  ì§€í‘œ ê³„ì‚° í•¨ìˆ˜"""
    print("ðŸš€ Spark ê¸°ë°˜ ê¸°ìˆ ì  ì§€í‘œ ê³„ì‚° ì‹œìž‘...")
    
    try:
        result = calculate_technical_indicators_task(**kwargs)
        print(f"ðŸŽ‰ ê¸°ìˆ ì  ì§€í‘œ ê³„ì‚° ì™„ë£Œ: {result}")
        return result
    except Exception as e:
        print(f"âŒ ê¸°ìˆ ì  ì§€í‘œ ê³„ì‚° ì˜¤ë¥˜: {e}")
        import traceback
        print(f"ðŸ“œ ìƒì„¸ ì˜¤ë¥˜:\n{traceback.format_exc()}")
        raise

# 4. ê´€ì‹¬ì¢…ëª© ìŠ¤ìº”
def watchlist_scan_func(**kwargs):
    """ë³¼ë¦°ì € ë°´ë“œ ê¸°ë°˜ ê´€ì‹¬ì¢…ëª© ìŠ¤ìº” í•¨ìˆ˜"""
    print("ðŸŽ¯ ê´€ì‹¬ì¢…ëª© ìŠ¤ìº” ì‹œìž‘...")
    
    import sys
    sys.path.insert(0, '/opt/airflow/common')
    from database import DuckDBManager
    from technical_scanner import TechnicalScanner
    
    try:
        # DB ì—°ê²°
        db = DuckDBManager(DB_PATH)
        scanner = TechnicalScanner(db)
        
        # ë°ì´í„° ê°€ìš©ì„± í™•ì¸
        data_status = scanner.check_data_availability()
        print(f"ðŸ“Š ë°ì´í„° ìƒíƒœ: {data_status}")
        
        if not data_status.get('has_sufficient_data', False):
            print("âš ï¸ ì¶©ë¶„í•œ ë°ì´í„°ê°€ ì—†ì–´ ìŠ¤ìº”ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
            return {'skipped': True, 'reason': 'insufficient_data'}
        
        # ë³¼ë¦°ì € ë°´ë“œ ìƒë‹¨ í„°ì¹˜ ì¢…ëª© ìŠ¤ìº”
        print("ðŸ” ë³¼ë¦°ì € ë°´ë“œ ìƒë‹¨ í„°ì¹˜ ì¢…ëª© ìŠ¤ìº” ì¤‘...")
        bb_upper_stocks = scanner.scan_bollinger_band_upper_touch()
        
        # ê²°ê³¼ ì •ë¦¬
        result = {
            'scan_type': 'bollinger_band_upper_touch',
            'total_candidates': len(bb_upper_stocks),
            'candidates': bb_upper_stocks[:10],  # ìƒìœ„ 10ê°œë§Œ ë¡œê·¸ì— ì¶œë ¥
            'timestamp': datetime.now().isoformat(),
            'data_status': data_status
        }
        
        print(f"ðŸŽ¯ ê´€ì‹¬ì¢…ëª© ìŠ¤ìº” ì™„ë£Œ!")
        print(f"ðŸ“Š ë°œê²¬ëœ ì¢…ëª©: {len(bb_upper_stocks)}ê°œ")
        if bb_upper_stocks:
            print(f"ðŸ”¥ ìƒìœ„ 5ê°œ ì¢…ëª©: {[stock['symbol'] for stock in bb_upper_stocks[:5]]}")
        
        db.close()
        return result
        
    except Exception as e:
        print(f"âŒ ê´€ì‹¬ì¢…ëª© ìŠ¤ìº” ì˜¤ë¥˜: {e}")
        import traceback
        print(f"ðŸ“œ ìƒì„¸ ì˜¤ë¥˜:\n{traceback.format_exc()}")
        if 'db' in locals():
            db.close()
        raise

# 5. ë°ì´í„°ë² ì´ìŠ¤ ë³µì œ ë° ê¶Œí•œ ì„¤ì •
def create_replica_and_permissions_func(**kwargs):
    """DB ë³µì œë³¸ ìƒì„± ë° Kafka Producerìš© ê¶Œí•œ ì„¤ì • í•¨ìˆ˜"""
    print("ðŸ”„ ë°ì´í„°ë² ì´ìŠ¤ ë³µì œ ë° ê¶Œí•œ ì„¤ì • ì‹œìž‘...")
    
    import shutil
    import stat
    
    try:
        # ë³µì œë³¸ ê²½ë¡œ ì„¤ì •
        replica_path = "/data/duckdb/stock_data_replica.db"
        
        # 1. ê¸°ì¡´ ë³µì œë³¸ ë°±ì—… (ìžˆë‹¤ë©´)
        if os.path.exists(replica_path):
            backup_path = f"{replica_path}.backup.{datetime.now().strftime('%Y%m%d_%H%M%S')}"
            try:
                shutil.copy2(replica_path, backup_path)
                print(f"âœ… ê¸°ì¡´ ë³µì œë³¸ ë°±ì—…: {backup_path}")
            except Exception as backup_error:
                print(f"âš ï¸ ë°±ì—… ì‹¤íŒ¨ (ë¬´ì‹œí•˜ê³  ê³„ì†): {backup_error}")
        
        # 2. ë©”ì¸ DBë¥¼ ë³µì œë³¸ìœ¼ë¡œ ë³µì‚¬
        if os.path.exists(DB_PATH):
            print(f"ðŸ“ ë©”ì¸ DB ë³µì‚¬: {DB_PATH} â†’ {replica_path}")
            shutil.copy2(DB_PATH, replica_path)
            print("âœ… ë°ì´í„°ë² ì´ìŠ¤ ë³µì œ ì™„ë£Œ")
        else:
            print(f"âŒ ë©”ì¸ DB íŒŒì¼ì´ ì—†ìŒ: {DB_PATH}")
            return {'error': 'main_db_not_found'}
        
        # 3. ë³µì œë³¸ ê¶Œí•œ ì„¤ì • (ì½ê¸° ì „ìš©ìœ¼ë¡œ ì„¤ì •)
        try:
            # ëª¨ë“  ì‚¬ìš©ìžì—ê²Œ ì½ê¸° ê¶Œí•œ ë¶€ì—¬
            os.chmod(replica_path, 0o644)  # rw-r--r--
            print("âœ… ë³µì œë³¸ ê¶Œí•œ ì„¤ì • ì™„ë£Œ (644 - ì½ê¸° ì „ìš©)")
            
            # ê¶Œí•œ í™•ì¸
            permissions = oct(os.stat(replica_path).st_mode)[-3:]
            print(f"ðŸ” ì„¤ì •ëœ ë³µì œë³¸ ê¶Œí•œ: {permissions}")
            
        except PermissionError as pe:
            print(f"âš ï¸ ê¶Œí•œ ì„¤ì • ì‹¤íŒ¨ (ë¬´ì‹œí•˜ê³  ê³„ì†): {pe}")
            # ì‹¤íŒ¨í•´ë„ íŒŒì¼ì€ ì¡´ìž¬í•˜ë¯€ë¡œ ê³„ì† ì§„í–‰
        
        # 4. ë””ë ‰í† ë¦¬ ê¶Œí•œë„ í™•ì¸ ë° ì„¤ì •
        db_dir = os.path.dirname(replica_path)
        try:
            os.chmod(db_dir, 0o755)  # rwxr-xr-x
            print("âœ… DB ë””ë ‰í† ë¦¬ ê¶Œí•œ ì„¤ì • ì™„ë£Œ (755)")
        except PermissionError as pe:
            print(f"âš ï¸ ë””ë ‰í† ë¦¬ ê¶Œí•œ ì„¤ì • ì‹¤íŒ¨: {pe}")
        
        # 5. íŒŒì¼ í¬ê¸° ë° ìƒíƒœ í™•ì¸
        if os.path.exists(replica_path):
            file_size = os.path.getsize(replica_path)
            file_size_mb = file_size / (1024 * 1024)
            print(f"ðŸ“Š ë³µì œë³¸ í¬ê¸°: {file_size_mb:.2f} MB")
        
        result = {
            'replica_path': replica_path,
            'file_size_mb': file_size_mb if 'file_size_mb' in locals() else 0,
            'permissions_set': True,
            'timestamp': datetime.now().isoformat()
        }
        
        print("ðŸŽ‰ ë°ì´í„°ë² ì´ìŠ¤ ë³µì œ ë° ê¶Œí•œ ì„¤ì • ì™„ë£Œ!")
        print(f"ðŸ“ ë³µì œë³¸ ìœ„ì¹˜: {replica_path}")
        print("ðŸš€ Kafka Producerê°€ ë³µì œë³¸ì„ ì½ì„ ìˆ˜ ìžˆìŠµë‹ˆë‹¤!")
        
        return result
        
    except Exception as e:
        print(f"âŒ ë³µì œ ë° ê¶Œí•œ ì„¤ì • ì˜¤ë¥˜: {e}")
        import traceback
        print(f"ðŸ“œ ìƒì„¸ ì˜¤ë¥˜:\n{traceback.format_exc()}")
        raise
    
# íƒœìŠ¤í¬ ì •ì˜

# 1. ëŒ€ëŸ‰ ìˆ˜ì§‘ ìƒíƒœ í™•ì¸ ì„¼ì„œ
bulk_collection_sensor = BulkCollectionSensor(
    task_id='wait_for_bulk_collection_completion',
    poke_interval=300,  # 5ë¶„ë§ˆë‹¤ í™•ì¸
    timeout=3600,       # 1ì‹œê°„ íƒ€ìž„ì•„ì›ƒ
    mode='poke',
    dag=dag,
    doc_md="""
    ## ðŸš¦ ëŒ€ëŸ‰ ìˆ˜ì§‘ ì¶©ëŒ ë°©ì§€ ì„¼ì„œ
    
    **ëª©ì **: ë‚˜ìŠ¤ë‹¥ ëŒ€ëŸ‰ ìˆ˜ì§‘(bulk collection)ê³¼ì˜ API ì¶©ëŒ ë°©ì§€
    
    **ë™ìž‘**:
    - ëŒ€ëŸ‰ ìˆ˜ì§‘ì´ ì‹¤í–‰ ì¤‘ì´ë©´ ëŒ€ê¸°
    - ëŒ€ëŸ‰ ìˆ˜ì§‘ì´ ì™„ë£Œë˜ê±°ë‚˜ ì‹¤í–‰ ì¤‘ì´ ì•„ë‹ˆë©´ ì§„í–‰
    - API ë ˆì´íŠ¸ ë¦¬ë¯¸íŠ¸ ë³´í˜¸
    """
)

# 2. API ìƒíƒœ í™•ì¸
api_check = PythonOperator(
    task_id='check_api_status',
    python_callable=check_api_rate_limits,
    dag=dag,
    doc_md="""
    ## ðŸŒ API ìƒíƒœ í™•ì¸
    
    **ëª©ì **: Yahoo Finance API ë ˆì´íŠ¸ ë¦¬ë¯¸íŠ¸ ìƒíƒœ í™•ì¸
    """
)

collect_symbols = PythonOperator(
    task_id='collect_nasdaq_symbols',
    python_callable=collect_nasdaq_symbols_func,
    dag=dag,
    doc_md="""
    ## ðŸ“Š ë‚˜ìŠ¤ë‹¥ ì‹¬ë³¼ ìˆ˜ì§‘
    
    **ëª©ì **: ë‚˜ìŠ¤ë‹¥ ê±°ëž˜ì†Œì˜ ì „ì²´ í™œì„± ì¢…ëª© ì •ë³´ ìˆ˜ì§‘
    
    **ì²˜ë¦¬ ê³¼ì •**:
    1. ë‚˜ìŠ¤ë‹¥ APIì—ì„œ ì „ì²´ ì¢…ëª© ì •ë³´ ì¡°íšŒ
    2. ì „ì²´ ì¢…ëª©ì„ DuckDBì— ì €ìž¥ (í•„í„°ë§ ì—†ìŒ)
    3. ì•½ 7000ê°œ ì¢…ëª© ìˆ˜ì§‘
    
    **ì¶œë ¥**: ìˆ˜ì§‘ëœ ì¢…ëª© ìˆ˜, ì €ìž¥ëœ ì¢…ëª© ìˆ˜
    """,
    retries=2,
    retry_delay=timedelta(minutes=3)
)

collect_ohlcv = PythonOperator(
    task_id='collect_ohlcv_data',
    python_callable=collect_ohlcv_func,
    dag=dag,
    doc_md="""
    ## ðŸ“Š yfinance ê¸°ë°˜ ì£¼ê°€ ë°ì´í„° ìˆ˜ì§‘ (OHLCV)
    
    **ëª©ì **: Yahoo Finance APIë¡œ ê³ ì† ì£¼ê°€ ë°ì´í„° ìˆ˜ì§‘
    
    **ì²˜ë¦¬ ê³¼ì •**:
    1. ì €ìž¥ëœ ì¢…ëª© ë¦¬ìŠ¤íŠ¸ ì¡°íšŒ
    2. yfinance APIë¡œ 5ë…„ì¹˜ ì£¼ê°€ ë°ì´í„° ìˆ˜ì§‘ (1íšŒ í˜¸ì¶œë¡œ ì „ì²´ ê¸°ê°„)
    3. ë°ì´í„° ì •ì œ ë° ê²€ì¦
    4. DuckDBì— ë°°ì¹˜ ì €ìž¥
    
    **ë°ì´í„°**: Open, High, Low, Close, Volume (ì¼ë³„)
    **ê¸°ê°„**: 5ë…„ (ì•½ 1,260 ê±°ëž˜ì¼)
    **ìž¥ì **: KIS API ëŒ€ë¹„ 5-10ë°° ë¹ ë¥¸ ì†ë„, ìž¥ê¸° íŠ¸ë Œë“œ ë¶„ì„ ê°€ëŠ¥
    """,
    retries=3,
    retry_delay=timedelta(minutes=5)
)

calculate_indicators = PythonOperator(
    task_id='calculate_technical_indicators',
    python_callable=calculate_indicators_func,
    dag=dag,
    doc_md="""
    ## ðŸš€ Spark ê¸°ë°˜ ê¸°ìˆ ì  ì§€í‘œ ê³„ì‚°
    
    **ëª©ì **: ê³ ì„±ëŠ¥ ë¶„ì‚° ì²˜ë¦¬ë¡œ ê¸°ìˆ ì  ì§€í‘œ ê³„ì‚°
    
    **ì²˜ë¦¬ ê³¼ì •**:
    1. DuckDBì—ì„œ ì£¼ê°€ ë°ì´í„° ë¡œë“œ
    2. Spark DataFrameìœ¼ë¡œ ë³€í™˜
    3. 7ê°€ì§€ ê¸°ìˆ ì  ì§€í‘œ ë³‘ë ¬ ê³„ì‚°:
       - ì´ë™í‰ê· ì„  (SMA): 5, 20, 60, 112, 224, 448ì¼
       - ì§€ìˆ˜ì´ë™í‰ê·  (EMA): 5, 20, 60ì¼
       - ë³¼ë¦°ì € ë°´ë“œ (BB): 20ì¼ Â±2Ïƒ
       - MACD: 12-26-9 ì„¤ì •
       - RSI: 14ì¼
       - CCI: 20ì¼
       - OBV: ê±°ëž˜ëŸ‰ ê¸°ë°˜
    4. ê²°ê³¼ë¥¼ DuckDBì— ì €ìž¥
    
    **ì„±ëŠ¥**: Spark ë¶„ì‚° ì²˜ë¦¬ë¡œ ê³ ì† ê³„ì‚°
    """,
    retries=2,
    retry_delay=timedelta(minutes=10)
)

# ê´€ì‹¬ì¢…ëª© ìŠ¤ìº” íƒœìŠ¤í¬
watchlist_scan = PythonOperator(
    task_id='watchlist_scan',
    python_callable=watchlist_scan_func,
    dag=dag,
    doc_md="""
    ## ðŸŽ¯ ê´€ì‹¬ì¢…ëª© ìŠ¤ìº”
    
    **ëª©ì **: ê¸°ìˆ ì  ë¶„ì„ì„ í†µí•œ íˆ¬ìž í›„ë³´ ì¢…ëª© ë°œêµ´
    
    **ì²˜ë¦¬ ê³¼ì •**:
    1. ë°ì´í„° ê°€ìš©ì„± í™•ì¸
    2. ë³¼ë¦°ì € ë°´ë“œ ìƒë‹¨ í„°ì¹˜ ì¢…ëª© ìŠ¤ìº”
    3. ì¡°ê±´ì„ ë§Œì¡±í•˜ëŠ” ì¢…ëª© ë¦¬ìŠ¤íŠ¸ ìƒì„±
    4. ìƒìœ„ ì¢…ëª©ë“¤ì„ ê´€ì‹¬ì¢…ëª©ìœ¼ë¡œ ì„ ì •
    
    **ìŠ¤ìº” ì¡°ê±´**:
    - ë³¼ë¦°ì € ë°´ë“œ ìƒë‹¨ ê·¼ì ‘ í„°ì¹˜
    - ì¶©ë¶„í•œ ê±°ëž˜ëŸ‰
    - ê¸°ìˆ ì  ì§€í‘œ ì¡°í•© ë¶„ì„
    
    **ì¶œë ¥**: ê´€ì‹¬ì¢…ëª© ë¦¬ìŠ¤íŠ¸ì™€ ë¶„ì„ ê²°ê³¼
    """,
    retries=2,
    retry_delay=timedelta(minutes=5)
)

# DB ë³µì œ ë° ê¶Œí•œ ì„¤ì • íƒœìŠ¤í¬
create_replica = PythonOperator(
    task_id='create_replica_and_permissions',
    python_callable=create_replica_and_permissions_func,
    dag=dag,
    doc_md="""
    ## ðŸ”„ ë°ì´í„°ë² ì´ìŠ¤ ë³µì œ ë° ê¶Œí•œ ì„¤ì •
    
    **ëª©ì **: Kafka Producerìš© ì½ê¸° ì „ìš© DB ë³µì œë³¸ ìƒì„±
    
    **ì²˜ë¦¬ ê³¼ì •**:
    1. ê¸°ì¡´ ë³µì œë³¸ ë°±ì—… (ìžˆë‹¤ë©´)
    2. ë©”ì¸ DBë¥¼ ë³µì œë³¸ìœ¼ë¡œ ë³µì‚¬
    3. ë³µì œë³¸ ê¶Œí•œ ì„¤ì • (644 - ì½ê¸° ì „ìš©)
    4. ë””ë ‰í† ë¦¬ ê¶Œí•œ ì„¤ì • (755)
    5. íŒŒì¼ í¬ê¸° ë° ìƒíƒœ í™•ì¸
    
    **ê²°ê³¼**:
    - stock_data_replica.db ìƒì„±
    - Kafka Producer ì ‘ê·¼ ê°€ëŠ¥í•œ ê¶Œí•œ ì„¤ì •
    - ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë°ì„ ìœ„í•œ ì¤€ë¹„ ì™„ë£Œ
    """,
    retries=2,
    retry_delay=timedelta(minutes=3)
)

# íŒŒì´í”„ë¼ì¸ ì™„ë£Œ í”Œëž˜ê·¸ ìƒì„±
def create_completion_flag_func(**kwargs):
    """íŒŒì´í”„ë¼ì¸ ì™„ë£Œ í”Œëž˜ê·¸ ìƒì„±"""
    import json
    from datetime import datetime
    
    try:
        # ì´ì „ Taskë“¤ì˜ ê²°ê³¼ ìˆ˜ì§‘
        collected_symbols = kwargs['ti'].xcom_pull(task_ids='collect_nasdaq_symbols')
        collected_ohlcv = kwargs['ti'].xcom_pull(task_ids='collect_stock_data_yfinance')
        calculated_indicators = kwargs['ti'].xcom_pull(task_ids='calculate_technical_indicators_spark')
        scanned_watchlist = kwargs['ti'].xcom_pull(task_ids='watchlist_scan_task')
        
        # ì™„ë£Œ ì •ë³´ êµ¬ì„±
        completion_info = {
            'completion_time': datetime.now().isoformat(),
            'dag_run_id': kwargs['dag_run'].run_id,
            'execution_date': str(kwargs['execution_date']),
            'pipeline_results': {
                'collected_symbols': collected_symbols or 0,
                'collected_ohlcv': collected_ohlcv or 0,
                'calculated_indicators': calculated_indicators or 0,
                'scanned_watchlist': scanned_watchlist or 0
            },
            'status': 'completed',
            'next_steps': ['redis_watchlist_sync', 'realtime_streaming']
        }
        
        # í”Œëž˜ê·¸ íŒŒì¼ ìƒì„±
        flag_file = "/tmp/nasdaq_pipeline_complete.flag"
        os.makedirs(os.path.dirname(flag_file), exist_ok=True)
        
        with open(flag_file, 'w') as f:
            f.write(json.dumps(completion_info, indent=2))
        
        print("ðŸŽ‰ ë‚˜ìŠ¤ë‹¥ ë°ì´í„° íŒŒì´í”„ë¼ì¸ ì™„ë£Œ!")
        print(f"ðŸ“Š ì²˜ë¦¬ ê²°ê³¼:")
        print(f"   ìˆ˜ì§‘ëœ ì‹¬ë³¼: {collected_symbols}ê°œ")
        print(f"   ìˆ˜ì§‘ëœ OHLCV: {collected_ohlcv}ê°œ")
        print(f"   ê³„ì‚°ëœ ì§€í‘œ: {calculated_indicators}ê°œ")
        print(f"   ìŠ¤ìº”ëœ ê´€ì‹¬ì¢…ëª©: {scanned_watchlist}ê°œ")
        print(f"âœ… ì™„ë£Œ í”Œëž˜ê·¸ ìƒì„±: {flag_file}")
        
        # Redis ë™ê¸°í™” DAG ìžë™ íŠ¸ë¦¬ê±°
        from airflow.operators.trigger_dagrun import TriggerDagRunOperator
        print("ðŸ”„ Redis ê´€ì‹¬ì¢…ëª© ë™ê¸°í™” DAG íŠ¸ë¦¬ê±° ì¤€ë¹„ ì™„ë£Œ")
        
        return completion_info
        
    except Exception as e:
        print(f"âŒ ì™„ë£Œ í”Œëž˜ê·¸ ìƒì„± ì‹¤íŒ¨: {e}")
        raise

create_completion_flag = PythonOperator(
    task_id='create_completion_flag',
    python_callable=create_completion_flag_func,
    dag=dag,
    doc_md="""
    ## ðŸ íŒŒì´í”„ë¼ì¸ ì™„ë£Œ í”Œëž˜ê·¸ ìƒì„±
    
    **ëª©ì **: ë‚˜ìŠ¤ë‹¥ ë°ì´í„° íŒŒì´í”„ë¼ì¸ ì™„ë£Œë¥¼ ë‹¤ë¥¸ DAGì— ì•Œë¦¼
    
    **ì²˜ë¦¬ ê³¼ì •**:
    1. ëª¨ë“  ì´ì „ Taskì˜ ê²°ê³¼ ìˆ˜ì§‘
    2. ì™„ë£Œ ì •ë³´ë¥¼ JSONìœ¼ë¡œ êµ¬ì„±
    3. /tmp/nasdaq_pipeline_complete.flag íŒŒì¼ ìƒì„±
    4. Redis ë™ê¸°í™” DAG íŠ¸ë¦¬ê±° ì¤€ë¹„
    
    **ì¶œë ¥ íŒŒì¼ ë‚´ìš©**:
    - ì™„ë£Œ ì‹œê°„
    - ì²˜ë¦¬ëœ ë°ì´í„° í†µê³„
    - ë‹¤ìŒ ë‹¨ê³„ ì •ë³´
    
    **ì—°ê²° DAG**: redis_watchlist_sync (ìžë™ íŠ¸ë¦¬ê±°)
    """,
    retries=1,
    retry_delay=timedelta(minutes=2)
)

# Redis ë™ê¸°í™” DAG ìžë™ íŠ¸ë¦¬ê±°
trigger_redis_sync = TriggerDagRunOperator(
    task_id='trigger_redis_watchlist_sync',
    trigger_dag_id='redis_watchlist_sync',
    conf={
        'triggered_by': 'nasdaq_daily_pipeline',
        'trigger_time': '{{ ts }}',
        'execution_date': '{{ ds }}'
    },
    dag=dag,
    doc_md="""
    ## ðŸ”„ Redis ë™ê¸°í™” DAG íŠ¸ë¦¬ê±°
    
    **ëª©ì **: ë©”ì¸ íŒŒì´í”„ë¼ì¸ ì™„ë£Œ í›„ ìžë™ìœ¼ë¡œ Redis ë™ê¸°í™” ì‹¤í–‰
    
    **íŠ¸ë¦¬ê±° ì¡°ê±´**: ëª¨ë“  ë°ì´í„° ì²˜ë¦¬ ë° ë³µì œ ì™„ë£Œ í›„
    **ëŒ€ìƒ DAG**: redis_watchlist_sync
    **ì „ë‹¬ ì •ë³´**: ì‹¤í–‰ ì‹œê°„, íŠ¸ë¦¬ê±° ì†ŒìŠ¤
    """
)

# íƒœìŠ¤í¬ ì˜ì¡´ì„± ì„¤ì • - ì™„ì „í•œ íŒŒì´í”„ë¼ì¸
# Task ì˜ì¡´ì„± ì„¤ì • - ëŒ€ëŸ‰ ìˆ˜ì§‘ ì¶©ëŒ ë°©ì§€ í¬í•¨
bulk_collection_sensor >> api_check >> collect_symbols >> collect_ohlcv >> calculate_indicators >> watchlist_scan >> create_replica >> create_completion_flag >> trigger_redis_sync
