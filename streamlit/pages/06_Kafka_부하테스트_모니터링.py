import streamlit as st
import json
import time
import subprocess
from datetime import datetime, timedelta
import pytz
import sys
import os

# í•œêµ­ ì‹œê°„ëŒ€ ì„¤ì •
KST = pytz.timezone('Asia/Seoul')

def format_korean_time(timestamp_str):
    """íƒ€ì„ìŠ¤íƒ¬í”„ë¥¼ í•œêµ­ì‹œê°„ìœ¼ë¡œ í¬ë§·íŒ…"""
    try:
        if isinstance(timestamp_str, str):
            if 'T' in timestamp_str:
                dt = datetime.fromisoformat(timestamp_str.replace('Z', '+00:00'))
            else:
                dt = datetime.strptime(timestamp_str[:19], '%Y-%m-%d %H:%M:%S')
                dt = dt.replace(tzinfo=pytz.UTC)
            
            kst_time = dt.astimezone(KST)
            return kst_time.strftime('%Y-%m-%d %H:%M:%S KST')
        else:
            return str(timestamp_str)
    except:
        return str(timestamp_str)

def get_current_kst_time():
    """í˜„ì¬ í•œêµ­ì‹œê°„ ë°˜í™˜"""
    return datetime.now(KST)

# ì„ íƒì  import - ì—†ìœ¼ë©´ ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œë¡œ ë™ì‘
try:
    import pandas as pd
    HAS_PANDAS = True
except ImportError:
    st.warning("ğŸ“¦ pandasê°€ ì„¤ì¹˜ë˜ì§€ ì•ŠìŒ - ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œë¡œ ë™ì‘í•©ë‹ˆë‹¤.")
    HAS_PANDAS = False

try:
    import plotly.graph_objects as go
    import plotly.express as px
    HAS_PLOTLY = True
except ImportError:
    st.warning("ğŸ“¦ plotlyê°€ ì„¤ì¹˜ë˜ì§€ ì•ŠìŒ - ê¸°ë³¸ ì°¨íŠ¸ë¡œ ëŒ€ì²´ë©ë‹ˆë‹¤.")
    HAS_PLOTLY = False

try:
    import psutil
    HAS_PSUTIL = True
except ImportError:
    st.warning("ğŸ“¦ psutilì´ ì„¤ì¹˜ë˜ì§€ ì•ŠìŒ - ì‹œìŠ¤í…œ ì •ë³´ë¥¼ ì‹œë®¬ë ˆì´ì…˜í•©ë‹ˆë‹¤.")
    HAS_PSUTIL = False

# ê³µí†µ ëª¨ë“ˆ ê²½ë¡œ ì¶”ê°€
sys.path.insert(0, '/home/grey1/stock-kafka3/common')
sys.path.insert(0, '/opt/airflow/common')

try:
    from redis_client import RedisClient
    HAS_REDIS = True
except ImportError:
    st.warning("ğŸ“¦ Redis í´ë¼ì´ì–¸íŠ¸ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤ - ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œë¡œ ë™ì‘í•©ë‹ˆë‹¤.")
    HAS_REDIS = False

st.set_page_config(
    page_title="Kafka ë¶€í•˜í…ŒìŠ¤íŠ¸ ëª¨ë‹ˆí„°ë§", 
    page_icon="ğŸš€", 
    layout="wide"
)

st.title("ğŸš€ Kafka ë¶€í•˜í…ŒìŠ¤íŠ¸ ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§")

# í˜„ì¬ í•œêµ­ ì‹œê°„ í‘œì‹œ
current_time = get_current_kst_time()
st.info(f"ğŸ• í˜„ì¬ ì‹œê°„: {current_time.strftime('%Yë…„ %mì›” %dì¼ %H:%M:%S KST')}")

# ì‚¬ì´ë“œë°” ì„¤ì •
st.sidebar.header("âš™ï¸ ë¶€í•˜í…ŒìŠ¤íŠ¸ ì œì–´")

# ë¶€í•˜í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ë²„íŠ¼ë“¤
test_type = st.sidebar.selectbox(
    "í…ŒìŠ¤íŠ¸ íƒ€ì… ì„ íƒ",
    ["ê°€ë²¼ìš´ í…ŒìŠ¤íŠ¸ (5ëª…, 3ë¶„)", "ì¤‘ê°„ í…ŒìŠ¤íŠ¸ (20ëª…, 10ë¶„)", "ë¬´ê±°ìš´ í…ŒìŠ¤íŠ¸ (50ëª…, 20ë¶„)", "Kafka ì „ìš© í…ŒìŠ¤íŠ¸", "ì»¤ìŠ¤í…€ ì„¤ì •"]
)

if st.sidebar.button("ğŸš€ ë¶€í•˜í…ŒìŠ¤íŠ¸ ì‹œì‘"):
    if test_type == "ê°€ë²¼ìš´ í…ŒìŠ¤íŠ¸ (5ëª…, 3ë¶„)":
        st.sidebar.success("ê°€ë²¼ìš´ í…ŒìŠ¤íŠ¸ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...")
        # ì‹¤ì œë¡œëŠ” subprocessë¡œ ë¶€í•˜í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    elif test_type == "Kafka ì „ìš© í…ŒìŠ¤íŠ¸":
        st.sidebar.success("Kafka ì „ìš© í…ŒìŠ¤íŠ¸ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...")

if st.sidebar.button("â¹ï¸ í…ŒìŠ¤íŠ¸ ì¤‘ì§€"):
    st.sidebar.warning("í…ŒìŠ¤íŠ¸ë¥¼ ì¤‘ì§€í•©ë‹ˆë‹¤...")

# ìë™ ìƒˆë¡œê³ ì¹¨ ì„¤ì •
auto_refresh = st.sidebar.checkbox("ìë™ ìƒˆë¡œê³ ì¹¨ (5ì´ˆ)", value=True)
if auto_refresh:
    time.sleep(5)
    st.rerun()

# ë©”ì¸ íƒ­ êµ¬ì„±
tab1, tab2, tab3, tab4 = st.tabs(["ğŸ“Š ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§", "ğŸ“ˆ ì„±ëŠ¥ ë©”íŠ¸ë¦­", "ğŸ” ìƒì„¸ ë¶„ì„", "ğŸ“‹ í…ŒìŠ¤íŠ¸ ì„¤ì •"])

with tab1:
    st.header("ğŸ“Š ì‹¤ì‹œê°„ Kafka ë¶€í•˜í…ŒìŠ¤íŠ¸ í˜„í™©")
    
    # ìƒë‹¨ ë©”íŠ¸ë¦­ ì¹´ë“œ
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        # ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„° (ì‹¤ì œë¡œëŠ” Redisë‚˜ Kafkaì—ì„œ ê°€ì ¸ì˜´)
        current_rps = 125.3
        st.metric(
            label="âš¡ í˜„ì¬ RPS",
            value=f"{current_rps:.1f}",
            delta=f"+{15.2:.1f}"
        )
    
    with col2:
        active_consumers = 3
        st.metric(
            label="ğŸ‘¥ í™œì„± Consumer",
            value=active_consumers,
            delta=1
        )
    
    with col3:
        total_messages = 125430
        st.metric(
            label="ğŸ“¤ ì´ ë©”ì‹œì§€",
            value=f"{total_messages:,}",
            delta=f"+{1250}"
        )
    
    with col4:
        error_rate = 0.67
        st.metric(
            label="âŒ ì˜¤ë¥˜ìœ¨",
            value=f"{error_rate:.2f}%",
            delta=f"-{0.12:.2f}%"
        )
    
    # ì‹¤ì‹œê°„ ì°¨íŠ¸
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("ğŸ“ˆ ì‹¤ì‹œê°„ RPS (Requests Per Second)")
        
        # ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„° ìƒì„± (í•œêµ­ì‹œê°„ ê¸°ì¤€)
        current_kst = get_current_kst_time()
        timestamps = [current_kst - timedelta(minutes=x) for x in range(10, 0, -1)]
        rps_values = [100 + (x * 5) + (x % 3 * 10) for x in range(10)]
        
        if HAS_PLOTLY:
            fig_rps = go.Figure()
            fig_rps.add_trace(go.Scatter(
                x=timestamps,
                y=rps_values,
                mode='lines+markers',
                name='RPS',
                line=dict(color='#00C851', width=3),
                marker=dict(size=6)
            ))
            
            fig_rps.update_layout(
                title="ì‹¤ì‹œê°„ ì²˜ë¦¬ëŸ‰ ì¶”ì´",
                xaxis_title="ì‹œê°„",
                yaxis_title="RPS",
                template="plotly_white",
                height=300
            )
            
            st.plotly_chart(fig_rps, use_container_width=True)
        else:
            # plotlyê°€ ì—†ì„ ë•Œ ê¸°ë³¸ ë¼ì¸ ì°¨íŠ¸
            chart_data = {
                'ì‹œê°„': [t.strftime('%H:%M') for t in timestamps],
                'RPS': rps_values
            }
            st.line_chart(chart_data, x='ì‹œê°„', y='RPS')
    
    with col2:
        st.subheader("â±ï¸ ì‘ë‹µì‹œê°„ ë¶„í¬")
        
        # ì‘ë‹µì‹œê°„ íˆìŠ¤í† ê·¸ë¨ ë°ì´í„°
        response_times = [25, 45, 35, 55, 40, 60, 50, 30, 65, 45, 52, 38, 48, 42, 58]
        
        if HAS_PLOTLY:
            fig_hist = go.Figure()
            fig_hist.add_trace(go.Histogram(
                x=response_times,
                nbinsx=8,
                name="ì‘ë‹µì‹œê°„",
                marker_color='#FF6384',
                opacity=0.7
            ))
            
            fig_hist.update_layout(
                title="ì‘ë‹µì‹œê°„ ë¶„í¬ (ms)",
                xaxis_title="ì‘ë‹µì‹œê°„ (ms)",
                yaxis_title="ë¹ˆë„",
                template="plotly_white",
                height=300
            )
            
            st.plotly_chart(fig_hist, use_container_width=True)
        else:
            # plotlyê°€ ì—†ì„ ë•Œ ê¸°ë³¸ íˆìŠ¤í† ê·¸ë¨
            st.write("**ì‘ë‹µì‹œê°„ ë¶„í¬ (ms)**")
            bins = {}
            for rt in response_times:
                bin_key = f"{(rt//10)*10}-{(rt//10)*10+9}ms"
                bins[bin_key] = bins.get(bin_key, 0) + 1
            
            for bin_range, count in bins.items():
                st.write(f"â€¢ {bin_range}: {count}ê°œ")
            
            # ê°„ë‹¨í•œ ë°” ì°¨íŠ¸
            st.bar_chart(bins)
    
    # í† í”½ë³„ ìƒì„¸ í˜„í™©
    st.subheader("ğŸ“‹ í† í”½ë³„ ì²˜ë¦¬ í˜„í™©")
    
    # ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„°
    topic_data = {
        "Topic Name": ["realtime-stock", "yfinance-stock", "kis-stock", "signal-test"],
        "Messages": [125430, 89220, 45100, 23560],
        "Consumers": [3, 2, 1, 1],
        "Throughput (msg/s)": [1250, 890, 451, 235],
        "Lag": [45, 128, 12, 8],
        "Status": ["ğŸŸ¢ ì •ìƒ", "ğŸŸ¡ ì§€ì—°", "ğŸŸ¢ ì •ìƒ", "ğŸŸ¢ ì •ìƒ"]
    }
    
    if HAS_PANDAS:
        df_topics = pd.DataFrame(topic_data)
        st.dataframe(df_topics, use_container_width=True, height=200)
    else:
        # pandasê°€ ì—†ì„ ë•Œ ê¸°ë³¸ í…Œì´ë¸”
        st.write("**í† í”½ë³„ ìƒì„¸ í˜„í™©**")
        for i, topic in enumerate(topic_data["Topic Name"]):
            col1, col2, col3, col4, col5, col6 = st.columns(6)
            with col1:
                st.write(topic)
            with col2:
                st.write(f"{topic_data['Messages'][i]:,}")
            with col3:
                st.write(topic_data['Consumers'][i])
            with col4:
                st.write(topic_data['Throughput (msg/s)'][i])
            with col5:
                st.write(topic_data['Lag'][i])
            with col6:
                st.write(topic_data['Status'][i])

with tab2:
    st.header("ğŸ“ˆ ìƒì„¸ ì„±ëŠ¥ ë©”íŠ¸ë¦­")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("ğŸ–¥ï¸ ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤")
        
        # ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤ ë©”íŠ¸ë¦­
        if HAS_PSUTIL:
            cpu_usage = psutil.cpu_percent()
            memory = psutil.virtual_memory()
        else:
            # psutilì´ ì—†ì„ ë•Œ ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„°
            cpu_usage = 45.2
            class SimMemory:
                percent = 67.8
                used = 4 * 1024 * 1024 * 1024  # 4GB
            memory = SimMemory()
        
        if HAS_PLOTLY:
            # CPU ê²Œì´ì§€
            fig_cpu = go.Figure(go.Indicator(
                mode = "gauge+number",
                value = cpu_usage,
                domain = {'x': [0, 1], 'y': [0, 1]},
                title = {'text': "CPU ì‚¬ìš©ë¥  (%)"},
                gauge = {
                    'axis': {'range': [None, 100]},
                    'bar': {'color': "darkblue"},
                    'steps': [
                        {'range': [0, 50], 'color': "lightgray"},
                        {'range': [50, 80], 'color': "yellow"},
                        {'range': [80, 100], 'color': "red"}
                    ],
                    'threshold': {
                        'line': {'color': "red", 'width': 4},
                        'thickness': 0.75,
                        'value': 90
                    }
                }
            ))
            
            fig_cpu.update_layout(height=250)
            st.plotly_chart(fig_cpu, use_container_width=True)
        else:
            # plotlyê°€ ì—†ì„ ë•Œ ê°„ë‹¨í•œ í”„ë¡œê·¸ë ˆìŠ¤ ë°”
            st.write("**CPU ì‚¬ìš©ë¥ **")
            st.progress(cpu_usage / 100, text=f"CPU: {cpu_usage:.1f}%")
        
        # ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ 
        memory_percent = memory.percent
        st.metric(
            label="ğŸ’¾ ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ ",
            value=f"{memory_percent:.1f}%",
            delta=f"{memory.used / 1024 / 1024 / 1024:.1f}GB ì‚¬ìš© ì¤‘"
        )
    
    with col2:
        st.subheader("ğŸ“Š Kafka í´ëŸ¬ìŠ¤í„° ìƒíƒœ")
        
        # Consumer Group ì§€ì—°ì‹œê°„
        consumer_groups = ["signal-detector", "data-processor", "analytics-worker"]
        lag_values = [45, 128, 67]
        
        fig_lag = go.Figure()
        fig_lag.add_trace(go.Bar(
            x=consumer_groups,
            y=lag_values,
            marker_color=['green' if x < 100 else 'orange' for x in lag_values],
            text=lag_values,
            textposition='auto'
        ))
        
        fig_lag.update_layout(
            title="Consumer Group Lag",
            xaxis_title="Consumer Group",
            yaxis_title="Lag (messages)",
            template="plotly_white",
            height=300
        )
        
        st.plotly_chart(fig_lag, use_container_width=True)
    
    # ì„±ëŠ¥ ì¶”ì´ ì°¨íŠ¸
    st.subheader("â±ï¸ ì„±ëŠ¥ ì§€í‘œ ì‹œê°„ë³„ ì¶”ì´")
    
    # ì‹œë®¬ë ˆì´ì…˜ ì‹œê³„ì—´ ë°ì´í„° (í•œêµ­ì‹œê°„ ê¸°ì¤€)
    current_kst = get_current_kst_time()
    time_range = pd.date_range(start=current_kst - timedelta(hours=1), end=current_kst, freq='5min')
    performance_data = {
        'timestamp': time_range,
        'rps': [100 + (i % 5) * 20 + (i % 3) * 10 for i in range(len(time_range))],
        'latency_p95': [50 + (i % 4) * 15 + (i % 2) * 5 for i in range(len(time_range))],
        'error_rate': [0.5 + (i % 6) * 0.2 for i in range(len(time_range))]
    }
    
    df_perf = pd.DataFrame(performance_data)
    
    # ë©€í‹° ë¼ì¸ ì°¨íŠ¸
    fig_multi = go.Figure()
    
    fig_multi.add_trace(go.Scatter(
        x=df_perf['timestamp'],
        y=df_perf['rps'],
        mode='lines+markers',
        name='RPS',
        yaxis='y',
        line=dict(color='blue')
    ))
    
    fig_multi.add_trace(go.Scatter(
        x=df_perf['timestamp'],
        y=df_perf['latency_p95'],
        mode='lines+markers',
        name='ì§€ì—°ì‹œê°„ P95 (ms)',
        yaxis='y2',
        line=dict(color='red')
    ))
    
    fig_multi.add_trace(go.Scatter(
        x=df_perf['timestamp'],
        y=df_perf['error_rate'],
        mode='lines+markers',
        name='ì˜¤ë¥˜ìœ¨ (%)',
        yaxis='y3',
        line=dict(color='orange')
    ))
    
    fig_multi.update_layout(
        title="ì„±ëŠ¥ ì§€í‘œ ì¶”ì´ (ìµœê·¼ 1ì‹œê°„)",
        xaxis_title="ì‹œê°„",
        yaxis=dict(title="RPS", side="left"),
        yaxis2=dict(title="ì§€ì—°ì‹œê°„ (ms)", side="right", overlaying="y"),
        yaxis3=dict(title="ì˜¤ë¥˜ìœ¨ (%)", side="right", overlaying="y", position=0.85),
        template="plotly_white",
        height=400
    )
    
    st.plotly_chart(fig_multi, use_container_width=True)

with tab3:
    st.header("ğŸ” ìƒì„¸ ë¶„ì„ ë° ì§„ë‹¨")
    
    # ì‹¤ì‹œê°„ ë¡œê·¸ ìŠ¤íŠ¸ë¦¼
    st.subheader("ğŸ“‹ ì‹¤ì‹œê°„ ë¡œê·¸ ìŠ¤íŠ¸ë¦¼")
    
    log_container = st.container()
    with log_container:
        # ì‹œë®¬ë ˆì´ì…˜ ë¡œê·¸ ë°ì´í„°
        log_messages = [
            "2025-07-30 14:30:15 INFO: Kafka message sent successfully - Topic: realtime-stock, Partition: 2",
            "2025-07-30 14:30:16 INFO: Consumer processed 125 messages - Group: signal-detector",
            "2025-07-30 14:30:17 WARN: High consumer lag detected - Group: data-processor, Lag: 128",
            "2025-07-30 14:30:18 INFO: Signal detected for AAPL - Type: bollinger_upper_touch",
            "2025-07-30 14:30:19 ERROR: Redis connection timeout - Retrying...",
            "2025-07-30 14:30:20 INFO: Performance metrics updated - RPS: 125.3, Latency: 45ms"
        ]
        
        for log in log_messages[-10:]:  # ìµœê·¼ 10ê°œ ë¡œê·¸ë§Œ í‘œì‹œ
            if "ERROR" in log:
                st.error(log)
            elif "WARN" in log:
                st.warning(log)
            else:
                st.info(log)
    
    # ì˜¤ë¥˜ ë¶„ì„
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("âŒ ì˜¤ë¥˜ ìœ í˜• ë¶„ì„")
        
        error_types = ["Connection Timeout", "Message Parse Error", "Redis Error", "Network Error"]
        error_counts = [5, 2, 8, 3]
        
        fig_errors = px.pie(
            values=error_counts,
            names=error_types,
            title="ì˜¤ë¥˜ ìœ í˜•ë³„ ë¶„í¬"
        )
        
        fig_errors.update_layout(height=300)
        st.plotly_chart(fig_errors, use_container_width=True)
    
    with col2:
        st.subheader("ğŸ“Š ì²˜ë¦¬ëŸ‰ vs ì§€ì—°ì‹œê°„ ìƒê´€ê´€ê³„")
        
        # ìŠ¤ìºí„° í”Œë¡¯ ë°ì´í„°
        rps_data = [80, 100, 120, 140, 160, 180, 200, 220]
        latency_data = [20, 25, 35, 50, 75, 100, 140, 200]
        
        fig_scatter = go.Figure()
        fig_scatter.add_trace(go.Scatter(
            x=rps_data,
            y=latency_data,
            mode='markers+lines',
            marker=dict(size=10, color='purple'),
            name='RPS vs Latency'
        ))
        
        fig_scatter.update_layout(
            title="ì²˜ë¦¬ëŸ‰-ì§€ì—°ì‹œê°„ ìƒê´€ê´€ê³„",
            xaxis_title="RPS",
            yaxis_title="ì§€ì—°ì‹œê°„ (ms)",
            template="plotly_white",
            height=300
        )
        
        st.plotly_chart(fig_scatter, use_container_width=True)
    
    # ë³‘ëª© ì§€ì  ë¶„ì„
    st.subheader("ğŸ” ë³‘ëª© ì§€ì  ë¶„ì„")
    
    bottleneck_data = {
        "êµ¬ì„±ìš”ì†Œ": ["Kafka Producer", "Kafka Consumer", "Redis Client", "Database", "Network"],
        "ì‚¬ìš©ë¥  (%)": [45, 67, 23, 34, 12],
        "ìƒíƒœ": ["ğŸŸ¢ ì •ìƒ", "ğŸŸ¡ ì£¼ì˜", "ğŸŸ¢ ì •ìƒ", "ğŸŸ¢ ì •ìƒ", "ğŸŸ¢ ì •ìƒ"],
        "ê¶Œì¥ì‚¬í•­": [
            "í˜„ì¬ ìƒíƒœ ìœ ì§€",
            "Consumer ìˆ˜ ì¦ê°€ ê³ ë ¤",
            "í˜„ì¬ ìƒíƒœ ìœ ì§€", 
            "í˜„ì¬ ìƒíƒœ ìœ ì§€",
            "í˜„ì¬ ìƒíƒœ ìœ ì§€"
        ]
    }
    
    df_bottleneck = pd.DataFrame(bottleneck_data)
    st.dataframe(df_bottleneck, use_container_width=True)

with tab4:
    st.header("ğŸ“‹ ë¶€í•˜í…ŒìŠ¤íŠ¸ ì„¤ì • ë° ì œì–´")
    
    # ì›Œì»¤ ê°œë… ëª…í™•í™”
    st.info("""
    **ğŸ”§ ë¶€í•˜í…ŒìŠ¤íŠ¸ì—ì„œ ì‚¬ìš©í•˜ëŠ” ì›Œì»¤ íƒ€ì… ì •ì˜:**
    
    **ğŸ“¤ Kafka Producer ì›Œì»¤** 
    - **ì—­í• **: ì£¼ì‹ ë°ì´í„° ë©”ì‹œì§€ë¥¼ ìƒì„±í•˜ì—¬ Kafka í† í”½ìœ¼ë¡œ ì „ì†¡
    - **ëŒ€ìƒ í† í”½**: `realtime-stock`, `yfinance-stock-data`
    - **ë¶€í•˜ ê°•ë„ ì¡°ì ˆ**: ì›Œì»¤ ìˆ˜ëŸ‰ìœ¼ë¡œ ë™ì‹œ ì „ì†¡ ì„±ëŠ¥ ì œì–´
    
    **ğŸ“¥ Kafka Consumer ì›Œì»¤**
    - **ì—­í• **: Kafka í† í”½ì—ì„œ ë©”ì‹œì§€ë¥¼ ì†Œë¹„í•˜ê³  ì‹ í˜¸ ê°ì§€ ì²˜ë¦¬
    - **ì²˜ë¦¬ ë°©ì‹**: ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¼ ì²˜ë¦¬ ë° ê¸°ìˆ ì  ì§€í‘œ ê³„ì‚°
    - **ë¶€í•˜ ê°•ë„ ì¡°ì ˆ**: ì›Œì»¤ ìˆ˜ëŸ‰ìœ¼ë¡œ ë™ì‹œ ì²˜ë¦¬ ì„±ëŠ¥ ì œì–´
    
    **ğŸŒ API í˜¸ì¶œ ì›Œì»¤**
    - **ì—­í• **: ì™¸ë¶€ API (yfinance, KIS API ë“±) ë™ì‹œ í˜¸ì¶œ í…ŒìŠ¤íŠ¸
    - **ì—°ê´€**: BulkDataCollectorì˜ `max_workers=4` ì„¤ì •ê³¼ ë™ì¼ ê°œë…
    - **ë¶€í•˜ ê°•ë„ ì¡°ì ˆ**: ì›Œì»¤ ìˆ˜ëŸ‰ìœ¼ë¡œ ë™ì‹œ API ìš”ì²­ ìˆ˜ ì œì–´
    
    âš ï¸ **ì£¼ì˜**: Docker ì»¨í…Œì´ë„ˆ ì›Œì»¤(`airflow-worker`, `spark-worker`)ì™€ëŠ” ë‹¤ë¥¸ ê°œë…ì…ë‹ˆë‹¤.
    """)
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("âš™ï¸ í…ŒìŠ¤íŠ¸ ë§¤ê°œë³€ìˆ˜")
        
        # í…ŒìŠ¤íŠ¸ ì„¤ì • í¼
        with st.form("load_test_config"):
            st.markdown("**â±ï¸ í…ŒìŠ¤íŠ¸ ê¸°ë³¸ ì„¤ì •**")
            test_duration = st.slider("í…ŒìŠ¤íŠ¸ ì§€ì†ì‹œê°„ (ë¶„)", 1, 60, 10)
            signal_probability = st.slider("ì‹ í˜¸ ë°œìƒ í™•ë¥  (%)", 0, 100, 30)
            
            st.markdown("**ğŸ“¤ Kafka Producer ì›Œì»¤ ì„¤ì •**")
            col_prod1, col_prod2 = st.columns(2)
            with col_prod1:
                kafka_producers = st.slider("Producer ì›Œì»¤ ìˆ˜", 1, 20, 10)
            with col_prod2:
                messages_per_producer = st.slider("Producerë‹¹ ë©”ì‹œì§€ ìˆ˜", 100, 5000, 1000)
            
            st.markdown("**ğŸ“¥ Kafka Consumer ì›Œì»¤ ì„¤ì •**")
            col_cons1, col_cons2 = st.columns(2)
            with col_cons1:
                kafka_consumers = st.slider("Consumer ì›Œì»¤ ìˆ˜", 1, 15, 5)
            with col_cons2:
                consumer_timeout = st.slider("Consumer íƒ€ì„ì•„ì›ƒ (ì´ˆ)", 30, 300, 60)
            
            st.markdown("**ğŸŒ API í˜¸ì¶œ ì›Œì»¤ ì„¤ì •**")
            col_api1, col_api2 = st.columns(2)
            with col_api1:
                api_workers = st.slider("API ì›Œì»¤ ìˆ˜ (BulkDataCollector max_workers)", 1, 10, 4)
            with col_api2:
                calls_per_api_worker = st.slider("ì›Œì»¤ë‹¹ API í˜¸ì¶œ ìˆ˜", 50, 500, 100)
            
            st.markdown("**ğŸ“Š í† í”½ ë° ì—”ë“œí¬ì¸íŠ¸ ì„¤ì •**")
            test_topics = st.multiselect(
                "í…ŒìŠ¤íŠ¸ ëŒ€ìƒ í† í”½",
                ["realtime-stock", "yfinance-stock-data", "kis-stock", "signal-test"],
                default=["realtime-stock", "yfinance-stock-data"]
            )
            
            api_endpoints = st.multiselect(
                "API í…ŒìŠ¤íŠ¸ ì—”ë“œí¬ì¸íŠ¸",
                [
                    "http://localhost:8080/api/kafka/health",
                    "http://localhost:8081/api/v1/health",
                    "http://localhost:6379/ping",
                    "https://query1.finance.yahoo.com/v8/finance/chart/AAPL"
                ],
                default=["http://localhost:8080/api/kafka/health"]
            )
            
            submitted = st.form_submit_button("ğŸš€ ë¶€í•˜í…ŒìŠ¤íŠ¸ ì‹œì‘", use_container_width=True)
            
            if submitted:
                st.success(f"ğŸ¯ ë¶€í•˜í…ŒìŠ¤íŠ¸ ì„¤ì • ì™„ë£Œ!")
                
                # ì‹¤ì œ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ëª…ë ¹ì–´ ìƒì„± (kafka_load_tester.py ì‚¬ìš©)
                test_command = f"""
# Kafka + API í†µí•© ë¶€í•˜í…ŒìŠ¤íŠ¸ ì‹¤í–‰
cd /home/grey1/stock-kafka3
python3 scripts/kafka_load_tester.py \\
    --duration {test_duration} \\
    --kafka-producers {kafka_producers} \\
    --kafka-consumers {kafka_consumers} \\
    --api-workers {api_workers} \\
    --messages-per-worker {messages_per_producer} \\
    --topics {' '.join(test_topics)}

# ë˜ëŠ” Docker í™˜ê²½ì—ì„œ ì‹¤í–‰
docker exec kafka-producer python3 /app/scripts/kafka_load_tester.py \\
    --duration {test_duration} --kafka-producers {kafka_producers}
                """.strip()
                
                st.code(test_command, language="bash")
                
                with st.expander("ğŸ“‹ ì„¤ì • ìš”ì•½", expanded=True):
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        st.metric("â±ï¸ ì§€ì†ì‹œê°„", f"{test_duration}ë¶„")
                        st.metric("ğŸ“¤ Producer ì›Œì»¤", f"{kafka_producers}ê°œ")
                        st.metric("ğŸ“¥ Consumer ì›Œì»¤", f"{kafka_consumers}ê°œ")
                    with col2:
                        st.metric("ğŸŒ API ì›Œì»¤", f"{api_workers}ê°œ")
                        st.metric("ğŸ“¨ ì´ ë©”ì‹œì§€", f"{kafka_producers * messages_per_producer:,}")
                        st.metric("ğŸ“ ì´ API í˜¸ì¶œ", f"{api_workers * calls_per_api_worker:,}")
                    with col3:
                        st.metric("ğŸ¯ ì‹ í˜¸ í™•ë¥ ", f"{signal_probability}%")
                        st.metric("ğŸ“Š í† í”½ ìˆ˜", f"{len(test_topics)}ê°œ")
                        st.metric("ğŸ”— API ì—”ë“œí¬ì¸íŠ¸", f"{len(api_endpoints)}ê°œ")
    
    with col2:
        st.subheader("ğŸ“Š ì˜ˆìƒ ì„±ëŠ¥ ê³„ì‚°")
        
        # ì„±ëŠ¥ ì˜ˆì¸¡ ê³„ì‚° (ì›Œì»¤ë³„)
        total_producer_messages = kafka_producers * messages_per_producer
        total_api_calls = api_workers * calls_per_api_worker
        producer_rps = total_producer_messages / (test_duration * 60) if test_duration > 0 else 0
        api_rps = total_api_calls / (test_duration * 60) if test_duration > 0 else 0
        
        col_metric1, col_metric2 = st.columns(2)
        with col_metric1:
            st.metric("ğŸ“¤ ì˜ˆìƒ Producer RPS", f"{producer_rps:.1f}")
            st.metric("ğŸ¯ ì˜ˆìƒ ì‹ í˜¸ ìˆ˜", f"{int(total_producer_messages * signal_probability / 100):,}")
            st.metric("ğŸ”„ í† í”½ë‹¹ ë©”ì‹œì§€", f"{total_producer_messages // len(test_topics) if test_topics else 0:,}")
        
        with col_metric2:
            st.metric("ğŸŒ ì˜ˆìƒ API RPS", f"{api_rps:.1f}")
            st.metric("ğŸ“Š ì²˜ë¦¬ ì˜ˆìƒ ì§€ì—°", f"{kafka_consumers * 10:.0f}ms")
            st.metric("ğŸ’¾ ì˜ˆìƒ ìºì‹œ ì ì¤‘ë¥ ", "85%")
        
        # ë¦¬ì†ŒìŠ¤ ìš”êµ¬ì‚¬í•­ ì¶”ì • (ì›Œì»¤ë³„ë¡œ ë” ì •í™•í•˜ê²Œ)
        st.subheader("ğŸ’» ì˜ˆìƒ ë¦¬ì†ŒìŠ¤ ìš”êµ¬ì‚¬í•­")
        
        # CPU: Producer(2%), Consumer(3%), API(1%) per worker
        estimated_cpu = min((kafka_producers * 2) + (kafka_consumers * 3) + (api_workers * 1), 80)
        # Memory: Producer(50MB), Consumer(80MB), API(30MB) per worker  
        estimated_memory = (kafka_producers * 50) + (kafka_consumers * 80) + (api_workers * 30)
        
        col_resource1, col_resource2 = st.columns(2)
        with col_resource1:
            cpu_color = "ğŸŸ¢" if estimated_cpu < 50 else "ğŸŸ¡" if estimated_cpu < 70 else "ğŸ”´"
            st.metric("ğŸ”¥ ì˜ˆìƒ CPU ì‚¬ìš©ë¥ ", f"{cpu_color} {estimated_cpu}%")
            
            network_usage = (total_producer_messages * 0.5) + (total_api_calls * 2)  # KB ë‹¨ìœ„
            st.metric("ğŸŒ ì˜ˆìƒ ë„¤íŠ¸ì›Œí¬ ì‚¬ìš©", f"{network_usage:.1f} KB")
        
        with col_resource2:
            memory_color = "ğŸŸ¢" if estimated_memory < 1000 else "ğŸŸ¡" if estimated_memory < 1500 else "ğŸ”´"
            st.metric("ğŸ’¾ ì˜ˆìƒ ë©”ëª¨ë¦¬ ì‚¬ìš©", f"{memory_color} {estimated_memory} MB")
            
            disk_io = total_producer_messages * 0.1  # ë¡œê·¸, ë©”íŠ¸ë¦­ ì €ì¥
            st.metric("ğŸ’½ ì˜ˆìƒ ë””ìŠ¤í¬ I/O", f"{disk_io:.1f} KB")
        
        # ì„±ëŠ¥ ì°¨íŠ¸
        st.subheader("ğŸ“ˆ ì˜ˆìƒ ë¶€í•˜ ë¶„í¬")
        
        if HAS_PLOTLY:
            workload_data = {
                'ì›Œì»¤ íƒ€ì…': ['Kafka Producer', 'Kafka Consumer', 'API Worker'],
                'ì›Œì»¤ ìˆ˜': [kafka_producers, kafka_consumers, api_workers],
                'ì˜ˆìƒ ì²˜ë¦¬ëŸ‰': [producer_rps, producer_rps * 0.9, api_rps],  # ConsumerëŠ” Producerì˜ 90% ì²˜ë¦¬
                'CPU ì‚¬ìš©ë¥ ': [kafka_producers * 2, kafka_consumers * 3, api_workers * 1]
            }
            
            df_workload = pd.DataFrame(workload_data)
            
            fig_workload = go.Figure()
            fig_workload.add_trace(go.Bar(
                name='ì›Œì»¤ ìˆ˜',
                x=df_workload['ì›Œì»¤ íƒ€ì…'],
                y=df_workload['ì›Œì»¤ ìˆ˜'],
                yaxis='y',
                marker_color='lightblue'
            ))
            
            fig_workload.add_trace(go.Scatter(
                name='ì˜ˆìƒ ì²˜ë¦¬ëŸ‰ (msg/sec)',
                x=df_workload['ì›Œì»¤ íƒ€ì…'],
                y=df_workload['ì˜ˆìƒ ì²˜ë¦¬ëŸ‰'],
                yaxis='y2',
                mode='lines+markers',
                line=dict(color='red'),
                marker=dict(size=10)
            ))
            
            fig_workload.update_layout(
                title="ì›Œì»¤ë³„ ë¶€í•˜ ë¶„í¬ ì˜ˆì¸¡",
                xaxis_title="ì›Œì»¤ íƒ€ì…",
                yaxis=dict(title="ì›Œì»¤ ìˆ˜", side="left"),
                yaxis2=dict(title="ì²˜ë¦¬ëŸ‰ (msg/sec)", side="right", overlaying="y"),
                template="plotly_white",
                height=300
            )
            
            st.plotly_chart(fig_workload, use_container_width=True)
        
        # ê²½ê³  ë° ê¶Œì¥ì‚¬í•­
        warnings = []
        if estimated_cpu > 70:
            warnings.append("âš ï¸ ë†’ì€ CPU ì‚¬ìš©ë¥ ì´ ì˜ˆìƒë©ë‹ˆë‹¤. Producer ì›Œì»¤ ìˆ˜ë¥¼ ì¤„ì´ì„¸ìš”.")
        if estimated_memory > 1500:
            warnings.append("âš ï¸ ë†’ì€ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì´ ì˜ˆìƒë©ë‹ˆë‹¤. Consumer ì›Œì»¤ ìˆ˜ë¥¼ ì¡°ì ˆí•˜ì„¸ìš”.")
        if producer_rps > 200:
            warnings.append("âš ï¸ ë†’ì€ ë©”ì‹œì§€ ì²˜ë¦¬ìœ¨ì´ ì˜ˆìƒë©ë‹ˆë‹¤. Kafka í´ëŸ¬ìŠ¤í„° ìƒíƒœë¥¼ í™•ì¸í•˜ì„¸ìš”.")
        if len(test_topics) > 2 and kafka_consumers < len(test_topics):
            warnings.append("ğŸ’¡ í† í”½ ìˆ˜ë³´ë‹¤ Consumer ì›Œì»¤ê°€ ì ìŠµë‹ˆë‹¤. ë³‘ë ¬ ì²˜ë¦¬ íš¨ìœ¨ì„±ì„ ê³ ë ¤í•˜ì„¸ìš”.")
            
        for warning in warnings:
            st.warning(warning)
        
        if not warnings:
            st.success("âœ… ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰ì´ ì ì ˆí•©ë‹ˆë‹¤. í…ŒìŠ¤íŠ¸ë¥¼ ì‹œì‘í•˜ì„¸ìš”!")
    
    # ì‹¤ì‹œê°„ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ë° ëª¨ë‹ˆí„°ë§
    st.subheader("ğŸ”´ ì‹¤ì‹œê°„ í…ŒìŠ¤íŠ¸ ì‹¤í–‰")
    
    col_control1, col_control2, col_control3, col_control4 = st.columns(4)
    
    with col_control1:
        if st.button("ğŸš€ ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ (1ë¶„)", use_container_width=True):
            st.info("1ë¶„ ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ê°€ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤...")
            # ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” subprocessë¡œ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    
    with col_control2:
        if st.button("ğŸ“Š API ì „ìš© í…ŒìŠ¤íŠ¸", use_container_width=True):
            st.info("API í˜¸ì¶œ ì „ìš© í…ŒìŠ¤íŠ¸ê°€ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤...")
    
    with col_control3:
        if st.button("ğŸ” ì‹ í˜¸ ê°ì§€ í…ŒìŠ¤íŠ¸", use_container_width=True):
            st.info("ì‹ í˜¸ ê°ì§€ ì§‘ì¤‘ í…ŒìŠ¤íŠ¸ê°€ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤...")
    
    with col_control4:
        if st.button("ğŸ›‘ í…ŒìŠ¤íŠ¸ ì¤‘ë‹¨", use_container_width=True, type="secondary"):
            st.warning("ì§„í–‰ ì¤‘ì¸ ëª¨ë“  í…ŒìŠ¤íŠ¸ê°€ ì¤‘ë‹¨ë©ë‹ˆë‹¤...")
    
    # í…ŒìŠ¤íŠ¸ íˆìŠ¤í† ë¦¬ (ì›Œì»¤ë³„ ìƒì„¸ ì •ë³´ í¬í•¨)
    st.subheader("ğŸ“š ìµœê·¼ í…ŒìŠ¤íŠ¸ íˆìŠ¤í† ë¦¬")
    
    test_history = {
        "ì‹¤í–‰ ì‹œê°„": [
            "2025-08-07 14:20:00",
            "2025-08-07 13:45:00", 
            "2025-08-07 13:15:00",
            "2025-08-07 12:30:00"
        ],
        "í…ŒìŠ¤íŠ¸ íƒ€ì…": ["í†µí•© ë¶€í•˜í…ŒìŠ¤íŠ¸", "API ì „ìš©", "ì‹ í˜¸ ê°ì§€", "Producer ìŠ¤íŠ¸ë ˆìŠ¤"],
        "ì§€ì†ì‹œê°„": ["10ë¶„", "15ë¶„", "5ë¶„", "20ë¶„"],
        "Producer ì›Œì»¤": [10, 0, 5, 20],
        "Consumer ì›Œì»¤": [5, 0, 8, 10],
        "API ì›Œì»¤": [4, 6, 2, 0],
        "í‰ê·  RPS": [125.3, 45.8, 78.2, 256.7],
        "ì„±ê³µë¥ ": ["98.5%", "99.2%", "97.8%", "96.1%"],
        "CPU í‰ê· ": ["45%", "25%", "35%", "72%"],
        "ìƒíƒœ": ["âœ… ì™„ë£Œ", "âœ… ì™„ë£Œ", "âœ… ì™„ë£Œ", "âš ï¸ ë†’ì€ ë¶€í•˜"]
    }
    
    df_history = pd.DataFrame(test_history)
    st.dataframe(df_history, use_container_width=True)
    
    # í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìƒì„¸ ë¶„ì„
    with st.expander("ğŸ“Š ìµœê·¼ í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìƒì„¸ ë¶„ì„", expanded=False):
        col_detail1, col_detail2 = st.columns(2)
        
        with col_detail1:
            st.subheader("ì›Œì»¤ë³„ ì„±ëŠ¥ ë¹„êµ")
            if HAS_PLOTLY:
                worker_performance = {
                    'ì›Œì»¤ íƒ€ì…': ['Producer', 'Consumer', 'API'] * 4,
                    'í…ŒìŠ¤íŠ¸': ['í†µí•©'] * 3 + ['APIì „ìš©'] * 3 + ['ì‹ í˜¸ê°ì§€'] * 3 + ['ìŠ¤íŠ¸ë ˆìŠ¤'] * 3,
                    'ì²˜ë¦¬ëŸ‰': [125, 110, 45, 0, 0, 46, 78, 75, 25, 257, 240, 0],
                    'ì„±ê³µë¥ ': [98.5, 98.2, 99.2, 0, 0, 99.2, 97.8, 98.1, 97.0, 96.1, 95.8, 0]
                }
                
                df_performance = pd.DataFrame(worker_performance)
                df_performance = df_performance[df_performance['ì²˜ë¦¬ëŸ‰'] > 0]  # 0ì¸ ê°’ ì œì™¸
                
                fig_performance = px.bar(
                    df_performance, 
                    x='í…ŒìŠ¤íŠ¸', 
                    y='ì²˜ë¦¬ëŸ‰', 
                    color='ì›Œì»¤ íƒ€ì…',
                    title="í…ŒìŠ¤íŠ¸ë³„ ì›Œì»¤ ì„±ëŠ¥",
                    barmode='group'
                )
                fig_performance.update_layout(height=300)
                st.plotly_chart(fig_performance, use_container_width=True)
        
        with col_detail2:
            st.subheader("ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ë¥  ì¶”ì´")
            if HAS_PLOTLY:
                resource_trend = {
                    'ì‹œê°„': ['12:30', '13:15', '13:45', '14:20'],
                    'CPU (%)': [72, 35, 25, 45],
                    'ë©”ëª¨ë¦¬ (%)': [68, 42, 38, 52],
                    'ë„¤íŠ¸ì›Œí¬ (MB/s)': [15.2, 8.5, 4.2, 12.8]
                }
                
                df_resource = pd.DataFrame(resource_trend)
                
                fig_resource = go.Figure()
                fig_resource.add_trace(go.Scatter(x=df_resource['ì‹œê°„'], y=df_resource['CPU (%)'], mode='lines+markers', name='CPU'))
                fig_resource.add_trace(go.Scatter(x=df_resource['ì‹œê°„'], y=df_resource['ë©”ëª¨ë¦¬ (%)'], mode='lines+markers', name='ë©”ëª¨ë¦¬'))
                fig_resource.update_layout(title="ì‹œê°„ëŒ€ë³„ ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ë¥ ", height=300)
                st.plotly_chart(fig_resource, use_container_width=True)

# í˜ì´ì§€ í•˜ë‹¨ ì •ë³´
st.markdown("---")
st.markdown("""
### ğŸ“Œ ëª¨ë‹ˆí„°ë§ ë„êµ¬ ë§í¬
- ğŸŒ **Kafka UI**: [http://localhost:8080](http://localhost:8080) - Kafka í´ëŸ¬ìŠ¤í„° ìƒíƒœ
- ğŸ•·ï¸ **Locust UI**: [http://localhost:8089](http://localhost:8089) - API ë¶€í•˜í…ŒìŠ¤íŠ¸  
- ğŸ“Š **Streamlit**: [http://localhost:8501](http://localhost:8501) - í†µí•© ëª¨ë‹ˆí„°ë§
- ğŸ³ **Docker Stats**: `docker stats` - ì»¨í…Œì´ë„ˆ ë¦¬ì†ŒìŠ¤ ìƒíƒœ

### ğŸ”§ ë¹ ë¥¸ ëª…ë ¹ì–´
```bash
# ìƒˆë¡œìš´ Kafka + API í†µí•© ë¶€í•˜í…ŒìŠ¤íŠ¸ ì‹¤í–‰ (kafka_load_tester.py ì‚¬ìš©)
python3 /home/grey1/stock-kafka3/scripts/kafka_load_tester.py --kafka-producers 10 --kafka-consumers 5 --api-workers 4 --duration 5

# Producer ì „ìš© ë¶€í•˜í…ŒìŠ¤íŠ¸
python3 /home/grey1/stock-kafka3/scripts/kafka_load_tester.py --kafka-producers 15 --kafka-consumers 0 --api-workers 0 --duration 3

# Consumer + API í…ŒìŠ¤íŠ¸
python3 /home/grey1/stock-kafka3/scripts/kafka_load_tester.py --kafka-producers 0 --kafka-consumers 8 --api-workers 6 --duration 10

# ë¡œê·¸ ëª¨ë‹ˆí„°ë§  
docker compose logs kafka-producer kafka-consumer -f
```
""")
