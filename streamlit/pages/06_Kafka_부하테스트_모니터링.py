import streamlit as st
import json
import time
import subprocess
from datetime import datetime, timedelta
import pytz
import sys
import os

# í•œêµ­ ì‹œê°„ëŒ€ ì„¤ì •
KST = pytz.timezone('Asia/Seoul')

def format_korean_time(timestamp_str):
    """íƒ€ì„ìŠ¤íƒ¬í”„ë¥¼ í•œêµ­ì‹œê°„ìœ¼ë¡œ í¬ë§·íŒ…"""
    try:
        if isinstance(timestamp_str, str):
            if 'T' in timestamp_str:
                dt = datetime.fromisoformat(timestamp_str.replace('Z', '+00:00'))
            else:
                dt = datetime.strptime(timestamp_str[:19], '%Y-%m-%d %H:%M:%S')
                dt = dt.replace(tzinfo=pytz.UTC)
            
            kst_time = dt.astimezone(KST)
            return kst_time.strftime('%Y-%m-%d %H:%M:%S KST')
        else:
            return str(timestamp_str)
    except:
        return str(timestamp_str)

def get_current_kst_time():
    """í˜„ì¬ í•œêµ­ì‹œê°„ ë°˜í™˜"""
    return datetime.now(KST)

# ì„ íƒì  import - ì—†ìœ¼ë©´ ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œë¡œ ë™ì‘
try:
    import pandas as pd
    HAS_PANDAS = True
except ImportError:
    st.warning("ğŸ“¦ pandasê°€ ì„¤ì¹˜ë˜ì§€ ì•ŠìŒ - ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œë¡œ ë™ì‘í•©ë‹ˆë‹¤.")
    HAS_PANDAS = False

try:
    import plotly.graph_objects as go
    import plotly.express as px
    HAS_PLOTLY = True
except ImportError:
    st.warning("ğŸ“¦ plotlyê°€ ì„¤ì¹˜ë˜ì§€ ì•ŠìŒ - ê¸°ë³¸ ì°¨íŠ¸ë¡œ ëŒ€ì²´ë©ë‹ˆë‹¤.")
    HAS_PLOTLY = False

try:
    import psutil
    HAS_PSUTIL = True
except ImportError:
    st.warning("ğŸ“¦ psutilì´ ì„¤ì¹˜ë˜ì§€ ì•ŠìŒ - ì‹œìŠ¤í…œ ì •ë³´ë¥¼ ì‹œë®¬ë ˆì´ì…˜í•©ë‹ˆë‹¤.")
    HAS_PSUTIL = False

# ê³µí†µ ëª¨ë“ˆ ê²½ë¡œ ì¶”ê°€
sys.path.insert(0, '/home/grey1/stock-kafka3/common')
sys.path.insert(0, '/opt/airflow/common')

try:
    from redis_client import RedisClient
    HAS_REDIS = True
except ImportError:
    st.warning("ğŸ“¦ Redis í´ë¼ì´ì–¸íŠ¸ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤ - ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œë¡œ ë™ì‘í•©ë‹ˆë‹¤.")
    HAS_REDIS = False

st.set_page_config(
    page_title="Kafka ë¶€í•˜í…ŒìŠ¤íŠ¸ ëª¨ë‹ˆí„°ë§", 
    page_icon="ğŸš€", 
    layout="wide"
)

st.title("ğŸš€ Kafka ë¶€í•˜í…ŒìŠ¤íŠ¸ ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§")

# í˜„ì¬ í•œêµ­ ì‹œê°„ í‘œì‹œ
current_time = get_current_kst_time()
st.info(f"ğŸ• í˜„ì¬ ì‹œê°„: {current_time.strftime('%Yë…„ %mì›” %dì¼ %H:%M:%S KST')}")

# ì‚¬ì´ë“œë°” ì„¤ì •
st.sidebar.header("âš™ï¸ ë¶€í•˜í…ŒìŠ¤íŠ¸ ì œì–´")

# ë¶€í•˜í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ë²„íŠ¼ë“¤
test_type = st.sidebar.selectbox(
    "í…ŒìŠ¤íŠ¸ íƒ€ì… ì„ íƒ",
    ["ê°€ë²¼ìš´ í…ŒìŠ¤íŠ¸ (5ëª…, 3ë¶„)", "ì¤‘ê°„ í…ŒìŠ¤íŠ¸ (20ëª…, 10ë¶„)", "ë¬´ê±°ìš´ í…ŒìŠ¤íŠ¸ (50ëª…, 20ë¶„)", "Kafka ì „ìš© í…ŒìŠ¤íŠ¸", "ì»¤ìŠ¤í…€ ì„¤ì •"]
)

if st.sidebar.button("ğŸš€ ë¶€í•˜í…ŒìŠ¤íŠ¸ ì‹œì‘"):
    if test_type == "ê°€ë²¼ìš´ í…ŒìŠ¤íŠ¸ (5ëª…, 3ë¶„)":
        st.sidebar.success("ê°€ë²¼ìš´ í…ŒìŠ¤íŠ¸ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...")
        # ì‹¤ì œë¡œëŠ” subprocessë¡œ ë¶€í•˜í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    elif test_type == "Kafka ì „ìš© í…ŒìŠ¤íŠ¸":
        st.sidebar.success("Kafka ì „ìš© í…ŒìŠ¤íŠ¸ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...")

if st.sidebar.button("â¹ï¸ í…ŒìŠ¤íŠ¸ ì¤‘ì§€"):
    st.sidebar.warning("í…ŒìŠ¤íŠ¸ë¥¼ ì¤‘ì§€í•©ë‹ˆë‹¤...")

# ìë™ ìƒˆë¡œê³ ì¹¨ ì„¤ì •
auto_refresh = st.sidebar.checkbox("ìë™ ìƒˆë¡œê³ ì¹¨ (5ì´ˆ)", value=True)
if auto_refresh:
    time.sleep(5)
    st.rerun()

# ë©”ì¸ íƒ­ êµ¬ì„±
tab1, tab2, tab3, tab4 = st.tabs(["ğŸ“Š ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§", "ğŸ“ˆ ì„±ëŠ¥ ë©”íŠ¸ë¦­", "ğŸ” ìƒì„¸ ë¶„ì„", "ğŸ“‹ í…ŒìŠ¤íŠ¸ ì„¤ì •"])

with tab1:
    st.header("ğŸ“Š ì‹¤ì‹œê°„ Kafka ë¶€í•˜í…ŒìŠ¤íŠ¸ í˜„í™©")
    
    # ìƒë‹¨ ë©”íŠ¸ë¦­ ì¹´ë“œ
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        # ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„° (ì‹¤ì œë¡œëŠ” Redisë‚˜ Kafkaì—ì„œ ê°€ì ¸ì˜´)
        current_rps = 125.3
        st.metric(
            label="âš¡ í˜„ì¬ RPS",
            value=f"{current_rps:.1f}",
            delta=f"+{15.2:.1f}"
        )
    
    with col2:
        active_consumers = 3
        st.metric(
            label="ğŸ‘¥ í™œì„± Consumer",
            value=active_consumers,
            delta=1
        )
    
    with col3:
        total_messages = 125430
        st.metric(
            label="ğŸ“¤ ì´ ë©”ì‹œì§€",
            value=f"{total_messages:,}",
            delta=f"+{1250}"
        )
    
    with col4:
        error_rate = 0.67
        st.metric(
            label="âŒ ì˜¤ë¥˜ìœ¨",
            value=f"{error_rate:.2f}%",
            delta=f"-{0.12:.2f}%"
        )
    
    # ì‹¤ì‹œê°„ ì°¨íŠ¸
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("ğŸ“ˆ ì‹¤ì‹œê°„ RPS (Requests Per Second)")
        
        # ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„° ìƒì„± (í•œêµ­ì‹œê°„ ê¸°ì¤€)
        current_kst = get_current_kst_time()
        timestamps = [current_kst - timedelta(minutes=x) for x in range(10, 0, -1)]
        rps_values = [100 + (x * 5) + (x % 3 * 10) for x in range(10)]
        
        if HAS_PLOTLY:
            fig_rps = go.Figure()
            fig_rps.add_trace(go.Scatter(
                x=timestamps,
                y=rps_values,
                mode='lines+markers',
                name='RPS',
                line=dict(color='#00C851', width=3),
                marker=dict(size=6)
            ))
            
            fig_rps.update_layout(
                title="ì‹¤ì‹œê°„ ì²˜ë¦¬ëŸ‰ ì¶”ì´",
                xaxis_title="ì‹œê°„",
                yaxis_title="RPS",
                template="plotly_white",
                height=300
            )
            
            st.plotly_chart(fig_rps, use_container_width=True)
        else:
            # plotlyê°€ ì—†ì„ ë•Œ ê¸°ë³¸ ë¼ì¸ ì°¨íŠ¸
            chart_data = {
                'ì‹œê°„': [t.strftime('%H:%M') for t in timestamps],
                'RPS': rps_values
            }
            st.line_chart(chart_data, x='ì‹œê°„', y='RPS')
    
    with col2:
        st.subheader("â±ï¸ ì‘ë‹µì‹œê°„ ë¶„í¬")
        
        # ì‘ë‹µì‹œê°„ íˆìŠ¤í† ê·¸ë¨ ë°ì´í„°
        response_times = [25, 45, 35, 55, 40, 60, 50, 30, 65, 45, 52, 38, 48, 42, 58]
        
        if HAS_PLOTLY:
            fig_hist = go.Figure()
            fig_hist.add_trace(go.Histogram(
                x=response_times,
                nbinsx=8,
                name="ì‘ë‹µì‹œê°„",
                marker_color='#FF6384',
                opacity=0.7
            ))
            
            fig_hist.update_layout(
                title="ì‘ë‹µì‹œê°„ ë¶„í¬ (ms)",
                xaxis_title="ì‘ë‹µì‹œê°„ (ms)",
                yaxis_title="ë¹ˆë„",
                template="plotly_white",
                height=300
            )
            
            st.plotly_chart(fig_hist, use_container_width=True)
        else:
            # plotlyê°€ ì—†ì„ ë•Œ ê¸°ë³¸ íˆìŠ¤í† ê·¸ë¨
            st.write("**ì‘ë‹µì‹œê°„ ë¶„í¬ (ms)**")
            bins = {}
            for rt in response_times:
                bin_key = f"{(rt//10)*10}-{(rt//10)*10+9}ms"
                bins[bin_key] = bins.get(bin_key, 0) + 1
            
            for bin_range, count in bins.items():
                st.write(f"â€¢ {bin_range}: {count}ê°œ")
            
            # ê°„ë‹¨í•œ ë°” ì°¨íŠ¸
            st.bar_chart(bins)
    
    # í† í”½ë³„ ìƒì„¸ í˜„í™©
    st.subheader("ğŸ“‹ í† í”½ë³„ ì²˜ë¦¬ í˜„í™©")
    
    # ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„°
    topic_data = {
        "Topic Name": ["realtime-stock", "yfinance-stock", "kis-stock", "signal-test"],
        "Messages": [125430, 89220, 45100, 23560],
        "Consumers": [3, 2, 1, 1],
        "Throughput (msg/s)": [1250, 890, 451, 235],
        "Lag": [45, 128, 12, 8],
        "Status": ["ğŸŸ¢ ì •ìƒ", "ğŸŸ¡ ì§€ì—°", "ğŸŸ¢ ì •ìƒ", "ğŸŸ¢ ì •ìƒ"]
    }
    
    if HAS_PANDAS:
        df_topics = pd.DataFrame(topic_data)
        st.dataframe(df_topics, use_container_width=True, height=200)
    else:
        # pandasê°€ ì—†ì„ ë•Œ ê¸°ë³¸ í…Œì´ë¸”
        st.write("**í† í”½ë³„ ìƒì„¸ í˜„í™©**")
        for i, topic in enumerate(topic_data["Topic Name"]):
            col1, col2, col3, col4, col5, col6 = st.columns(6)
            with col1:
                st.write(topic)
            with col2:
                st.write(f"{topic_data['Messages'][i]:,}")
            with col3:
                st.write(topic_data['Consumers'][i])
            with col4:
                st.write(topic_data['Throughput (msg/s)'][i])
            with col5:
                st.write(topic_data['Lag'][i])
            with col6:
                st.write(topic_data['Status'][i])

with tab2:
    st.header("ğŸ“ˆ ìƒì„¸ ì„±ëŠ¥ ë©”íŠ¸ë¦­")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("ğŸ–¥ï¸ ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤")
        
        # ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤ ë©”íŠ¸ë¦­
        if HAS_PSUTIL:
            cpu_usage = psutil.cpu_percent()
            memory = psutil.virtual_memory()
        else:
            # psutilì´ ì—†ì„ ë•Œ ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„°
            cpu_usage = 45.2
            class SimMemory:
                percent = 67.8
                used = 4 * 1024 * 1024 * 1024  # 4GB
            memory = SimMemory()
        
        if HAS_PLOTLY:
            # CPU ê²Œì´ì§€
            fig_cpu = go.Figure(go.Indicator(
                mode = "gauge+number",
                value = cpu_usage,
                domain = {'x': [0, 1], 'y': [0, 1]},
                title = {'text': "CPU ì‚¬ìš©ë¥  (%)"},
                gauge = {
                    'axis': {'range': [None, 100]},
                    'bar': {'color': "darkblue"},
                    'steps': [
                        {'range': [0, 50], 'color': "lightgray"},
                        {'range': [50, 80], 'color': "yellow"},
                        {'range': [80, 100], 'color': "red"}
                    ],
                    'threshold': {
                        'line': {'color': "red", 'width': 4},
                        'thickness': 0.75,
                        'value': 90
                    }
                }
            ))
            
            fig_cpu.update_layout(height=250)
            st.plotly_chart(fig_cpu, use_container_width=True)
        else:
            # plotlyê°€ ì—†ì„ ë•Œ ê°„ë‹¨í•œ í”„ë¡œê·¸ë ˆìŠ¤ ë°”
            st.write("**CPU ì‚¬ìš©ë¥ **")
            st.progress(cpu_usage / 100, text=f"CPU: {cpu_usage:.1f}%")
        
        # ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ 
        memory_percent = memory.percent
        st.metric(
            label="ğŸ’¾ ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ ",
            value=f"{memory_percent:.1f}%",
            delta=f"{memory.used / 1024 / 1024 / 1024:.1f}GB ì‚¬ìš© ì¤‘"
        )
    
    with col2:
        st.subheader("ğŸ“Š Kafka í´ëŸ¬ìŠ¤í„° ìƒíƒœ")
        
        # Consumer Group ì§€ì—°ì‹œê°„
        consumer_groups = ["signal-detector", "data-processor", "analytics-worker"]
        lag_values = [45, 128, 67]
        
        fig_lag = go.Figure()
        fig_lag.add_trace(go.Bar(
            x=consumer_groups,
            y=lag_values,
            marker_color=['green' if x < 100 else 'orange' for x in lag_values],
            text=lag_values,
            textposition='auto'
        ))
        
        fig_lag.update_layout(
            title="Consumer Group Lag",
            xaxis_title="Consumer Group",
            yaxis_title="Lag (messages)",
            template="plotly_white",
            height=300
        )
        
        st.plotly_chart(fig_lag, use_container_width=True)
    
    # ì„±ëŠ¥ ì¶”ì´ ì°¨íŠ¸
    st.subheader("â±ï¸ ì„±ëŠ¥ ì§€í‘œ ì‹œê°„ë³„ ì¶”ì´")
    
    # ì‹œë®¬ë ˆì´ì…˜ ì‹œê³„ì—´ ë°ì´í„° (í•œêµ­ì‹œê°„ ê¸°ì¤€)
    current_kst = get_current_kst_time()
    time_range = pd.date_range(start=current_kst - timedelta(hours=1), end=current_kst, freq='5min')
    performance_data = {
        'timestamp': time_range,
        'rps': [100 + (i % 5) * 20 + (i % 3) * 10 for i in range(len(time_range))],
        'latency_p95': [50 + (i % 4) * 15 + (i % 2) * 5 for i in range(len(time_range))],
        'error_rate': [0.5 + (i % 6) * 0.2 for i in range(len(time_range))]
    }
    
    df_perf = pd.DataFrame(performance_data)
    
    # ë©€í‹° ë¼ì¸ ì°¨íŠ¸
    fig_multi = go.Figure()
    
    fig_multi.add_trace(go.Scatter(
        x=df_perf['timestamp'],
        y=df_perf['rps'],
        mode='lines+markers',
        name='RPS',
        yaxis='y',
        line=dict(color='blue')
    ))
    
    fig_multi.add_trace(go.Scatter(
        x=df_perf['timestamp'],
        y=df_perf['latency_p95'],
        mode='lines+markers',
        name='ì§€ì—°ì‹œê°„ P95 (ms)',
        yaxis='y2',
        line=dict(color='red')
    ))
    
    fig_multi.add_trace(go.Scatter(
        x=df_perf['timestamp'],
        y=df_perf['error_rate'],
        mode='lines+markers',
        name='ì˜¤ë¥˜ìœ¨ (%)',
        yaxis='y3',
        line=dict(color='orange')
    ))
    
    fig_multi.update_layout(
        title="ì„±ëŠ¥ ì§€í‘œ ì¶”ì´ (ìµœê·¼ 1ì‹œê°„)",
        xaxis_title="ì‹œê°„",
        yaxis=dict(title="RPS", side="left"),
        yaxis2=dict(title="ì§€ì—°ì‹œê°„ (ms)", side="right", overlaying="y"),
        yaxis3=dict(title="ì˜¤ë¥˜ìœ¨ (%)", side="right", overlaying="y", position=0.85),
        template="plotly_white",
        height=400
    )
    
    st.plotly_chart(fig_multi, use_container_width=True)

with tab3:
    st.header("ğŸ” ìƒì„¸ ë¶„ì„ ë° ì§„ë‹¨")
    
    # ì‹¤ì‹œê°„ ë¡œê·¸ ìŠ¤íŠ¸ë¦¼
    st.subheader("ğŸ“‹ ì‹¤ì‹œê°„ ë¡œê·¸ ìŠ¤íŠ¸ë¦¼")
    
    log_container = st.container()
    with log_container:
        # ì‹œë®¬ë ˆì´ì…˜ ë¡œê·¸ ë°ì´í„°
        log_messages = [
            "2025-07-30 14:30:15 INFO: Kafka message sent successfully - Topic: realtime-stock, Partition: 2",
            "2025-07-30 14:30:16 INFO: Consumer processed 125 messages - Group: signal-detector",
            "2025-07-30 14:30:17 WARN: High consumer lag detected - Group: data-processor, Lag: 128",
            "2025-07-30 14:30:18 INFO: Signal detected for AAPL - Type: bollinger_upper_touch",
            "2025-07-30 14:30:19 ERROR: Redis connection timeout - Retrying...",
            "2025-07-30 14:30:20 INFO: Performance metrics updated - RPS: 125.3, Latency: 45ms"
        ]
        
        for log in log_messages[-10:]:  # ìµœê·¼ 10ê°œ ë¡œê·¸ë§Œ í‘œì‹œ
            if "ERROR" in log:
                st.error(log)
            elif "WARN" in log:
                st.warning(log)
            else:
                st.info(log)
    
    # ì˜¤ë¥˜ ë¶„ì„
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("âŒ ì˜¤ë¥˜ ìœ í˜• ë¶„ì„")
        
        error_types = ["Connection Timeout", "Message Parse Error", "Redis Error", "Network Error"]
        error_counts = [5, 2, 8, 3]
        
        fig_errors = px.pie(
            values=error_counts,
            names=error_types,
            title="ì˜¤ë¥˜ ìœ í˜•ë³„ ë¶„í¬"
        )
        
        fig_errors.update_layout(height=300)
        st.plotly_chart(fig_errors, use_container_width=True)
    
    with col2:
        st.subheader("ğŸ“Š ì²˜ë¦¬ëŸ‰ vs ì§€ì—°ì‹œê°„ ìƒê´€ê´€ê³„")
        
        # ìŠ¤ìºí„° í”Œë¡¯ ë°ì´í„°
        rps_data = [80, 100, 120, 140, 160, 180, 200, 220]
        latency_data = [20, 25, 35, 50, 75, 100, 140, 200]
        
        fig_scatter = go.Figure()
        fig_scatter.add_trace(go.Scatter(
            x=rps_data,
            y=latency_data,
            mode='markers+lines',
            marker=dict(size=10, color='purple'),
            name='RPS vs Latency'
        ))
        
        fig_scatter.update_layout(
            title="ì²˜ë¦¬ëŸ‰-ì§€ì—°ì‹œê°„ ìƒê´€ê´€ê³„",
            xaxis_title="RPS",
            yaxis_title="ì§€ì—°ì‹œê°„ (ms)",
            template="plotly_white",
            height=300
        )
        
        st.plotly_chart(fig_scatter, use_container_width=True)
    
    # ë³‘ëª© ì§€ì  ë¶„ì„
    st.subheader("ğŸ” ë³‘ëª© ì§€ì  ë¶„ì„")
    
    bottleneck_data = {
        "êµ¬ì„±ìš”ì†Œ": ["Kafka Producer", "Kafka Consumer", "Redis Client", "Database", "Network"],
        "ì‚¬ìš©ë¥  (%)": [45, 67, 23, 34, 12],
        "ìƒíƒœ": ["ğŸŸ¢ ì •ìƒ", "ğŸŸ¡ ì£¼ì˜", "ğŸŸ¢ ì •ìƒ", "ğŸŸ¢ ì •ìƒ", "ğŸŸ¢ ì •ìƒ"],
        "ê¶Œì¥ì‚¬í•­": [
            "í˜„ì¬ ìƒíƒœ ìœ ì§€",
            "Consumer ìˆ˜ ì¦ê°€ ê³ ë ¤",
            "í˜„ì¬ ìƒíƒœ ìœ ì§€", 
            "í˜„ì¬ ìƒíƒœ ìœ ì§€",
            "í˜„ì¬ ìƒíƒœ ìœ ì§€"
        ]
    }
    
    df_bottleneck = pd.DataFrame(bottleneck_data)
    st.dataframe(df_bottleneck, use_container_width=True)

with tab4:
    st.header("ğŸ“‹ ë¶€í•˜í…ŒìŠ¤íŠ¸ ì„¤ì • ë° ì œì–´")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("âš™ï¸ í…ŒìŠ¤íŠ¸ ë§¤ê°œë³€ìˆ˜")
        
        # í…ŒìŠ¤íŠ¸ ì„¤ì • í¼
        with st.form("load_test_config"):
            test_duration = st.slider("í…ŒìŠ¤íŠ¸ ì§€ì†ì‹œê°„ (ë¶„)", 1, 60, 10)
            kafka_threads = st.slider("Kafka ìŠ¤ë ˆë“œ ìˆ˜", 1, 50, 10)
            messages_per_thread = st.slider("ìŠ¤ë ˆë“œë‹¹ ë©”ì‹œì§€ ìˆ˜", 100, 5000, 1000)
            signal_probability = st.slider("ì‹ í˜¸ ë°œìƒ í™•ë¥  (%)", 0, 100, 30)
            
            test_topics = st.multiselect(
                "í…ŒìŠ¤íŠ¸ ëŒ€ìƒ í† í”½",
                ["realtime-stock", "yfinance-stock", "kis-stock", "signal-test"],
                default=["realtime-stock"]
            )
            
            submitted = st.form_submit_button("ğŸš€ í…ŒìŠ¤íŠ¸ ì‹œì‘")
            
            if submitted:
                st.success(f"ë¶€í•˜í…ŒìŠ¤íŠ¸ ì„¤ì • ì™„ë£Œ!")
                st.info(f"""
                **ì„¤ì • ìš”ì•½:**
                - ì§€ì†ì‹œê°„: {test_duration}ë¶„
                - Kafka ìŠ¤ë ˆë“œ: {kafka_threads}ê°œ
                - ë©”ì‹œì§€/ìŠ¤ë ˆë“œ: {messages_per_thread}ê°œ
                - ì‹ í˜¸ í™•ë¥ : {signal_probability}%
                - ëŒ€ìƒ í† í”½: {', '.join(test_topics)}
                """)
    
    with col2:
        st.subheader("ğŸ“Š ì˜ˆìƒ ì„±ëŠ¥ ê³„ì‚°")
        
        # ì„±ëŠ¥ ì˜ˆì¸¡ ê³„ì‚°
        total_messages = kafka_threads * messages_per_thread
        messages_per_minute = total_messages / test_duration
        expected_rps = messages_per_minute / 60
        
        st.metric("ğŸ“¤ ì´ ì˜ˆìƒ ë©”ì‹œì§€ ìˆ˜", f"{total_messages:,}")
        st.metric("âš¡ ì˜ˆìƒ í‰ê·  RPS", f"{expected_rps:.1f}")
        st.metric("ğŸ¯ ì˜ˆìƒ ì‹ í˜¸ ë°œìƒ ìˆ˜", f"{int(total_messages * signal_probability / 100):,}")
        
        # ë¦¬ì†ŒìŠ¤ ìš”êµ¬ì‚¬í•­ ì¶”ì •
        st.subheader("ğŸ’» ì˜ˆìƒ ë¦¬ì†ŒìŠ¤ ìš”êµ¬ì‚¬í•­")
        
        estimated_cpu = min(kafka_threads * 2, 80)  # ìŠ¤ë ˆë“œë‹¹ 2% CPU, ìµœëŒ€ 80%
        estimated_memory = min(kafka_threads * 50, 2000)  # ìŠ¤ë ˆë“œë‹¹ 50MB, ìµœëŒ€ 2GB
        
        st.progress(estimated_cpu / 100, text=f"ì˜ˆìƒ CPU ì‚¬ìš©ë¥ : {estimated_cpu}%")
        st.progress(estimated_memory / 2000, text=f"ì˜ˆìƒ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {estimated_memory}MB")
        
        if estimated_cpu > 70:
            st.warning("âš ï¸ ë†’ì€ CPU ì‚¬ìš©ë¥ ì´ ì˜ˆìƒë©ë‹ˆë‹¤. ìŠ¤ë ˆë“œ ìˆ˜ë¥¼ ì¤„ì´ëŠ” ê²ƒì„ ê³ ë ¤í•˜ì„¸ìš”.")
        
        if estimated_memory > 1500:
            st.warning("âš ï¸ ë†’ì€ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì´ ì˜ˆìƒë©ë‹ˆë‹¤. ë©”ì‹œì§€ í¬ê¸°ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
    
    # í…ŒìŠ¤íŠ¸ íˆìŠ¤í† ë¦¬
    st.subheader("ğŸ“š ìµœê·¼ í…ŒìŠ¤íŠ¸ íˆìŠ¤í† ë¦¬")
    
    test_history = {
        "ì‹¤í–‰ ì‹œê°„": [
            "2025-07-30 14:20:00",
            "2025-07-30 13:45:00", 
            "2025-07-30 13:15:00"
        ],
        "í…ŒìŠ¤íŠ¸ íƒ€ì…": ["Kafka ì „ìš©", "í†µí•© í…ŒìŠ¤íŠ¸", "ì‹ í˜¸ ê°ì§€"],
        "ì§€ì†ì‹œê°„": ["10ë¶„", "15ë¶„", "5ë¶„"],
        "í‰ê·  RPS": [125.3, 98.7, 156.2],
        "ì„±ê³µë¥ ": ["98.5%", "99.2%", "97.8%"],
        "ìƒíƒœ": ["âœ… ì™„ë£Œ", "âœ… ì™„ë£Œ", "âœ… ì™„ë£Œ"]
    }
    
    df_history = pd.DataFrame(test_history)
    st.dataframe(df_history, use_container_width=True)

# í˜ì´ì§€ í•˜ë‹¨ ì •ë³´
st.markdown("---")
st.markdown("""
### ğŸ“Œ ëª¨ë‹ˆí„°ë§ ë„êµ¬ ë§í¬
- ğŸŒ **Kafka UI**: [http://localhost:8080](http://localhost:8080) - Kafka í´ëŸ¬ìŠ¤í„° ìƒíƒœ
- ğŸ•·ï¸ **Locust UI**: [http://localhost:8089](http://localhost:8089) - API ë¶€í•˜í…ŒìŠ¤íŠ¸  
- ğŸ“Š **Streamlit**: [http://localhost:8501](http://localhost:8501) - í†µí•© ëª¨ë‹ˆí„°ë§
- ğŸ³ **Docker Stats**: `docker stats` - ì»¨í…Œì´ë„ˆ ë¦¬ì†ŒìŠ¤ ìƒíƒœ

### ğŸ”§ ë¹ ë¥¸ ëª…ë ¹ì–´
```bash
# Kafka ë¶€í•˜í…ŒìŠ¤íŠ¸ ì‹¤í–‰
python3 run_load_test.py --test-type kafka --kafka-threads 10 --kafka-messages 1000

# ì‹ í˜¸ ê°ì§€ í…ŒìŠ¤íŠ¸
docker compose exec kafka-producer python /app/kafka/signal_test_producer.py --interval 5 --signal-prob 0.3

# ë¡œê·¸ ëª¨ë‹ˆí„°ë§  
docker compose logs kafka-consumer kafka-producer -f
```
""")
