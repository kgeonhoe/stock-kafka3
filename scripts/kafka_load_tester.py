#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Kafka ë¶€í•˜í…ŒìŠ¤íŠ¸ ëª¨ë“ˆ (ìƒˆë¡œìš´ ë²„ì „)
- ë‹¤ì¤‘ í† í”½ ì§€ì›
- ì›Œì»¤ ìˆ˜ëŸ‰ ì¡°ì ˆ
- API í˜¸ì¶œ í…ŒìŠ¤íŠ¸
- ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§
"""

import json
import time
import threading
import random
from datetime import datetime
from typing import Dict, List, Optional
from dataclasses import dataclass
from kafka import KafkaProducer, KafkaConsumer
from kafka.errors import KafkaError
import logging
import concurrent.futures
import psutil
import requests

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

@dataclass
class LoadTestConfig:
    """ë¶€í•˜í…ŒìŠ¤íŠ¸ ì„¤ì •"""
    duration_minutes: int = 5
    kafka_producer_workers: int = 10  # Kafka Producer ì›Œì»¤ ìˆ˜
    kafka_consumer_workers: int = 5   # Kafka Consumer ì›Œì»¤ ìˆ˜
    api_call_workers: int = 4         # API í˜¸ì¶œ ì›Œì»¤ ìˆ˜ (BulkDataCollectorì˜ max_workers)
    messages_per_worker: int = 1000
    topics: List[str] = None
    api_endpoints: List[str] = None
    signal_probability: float = 0.3
    
    def __post_init__(self):
        if self.topics is None:
            self.topics = ["realtime-stock", "yfinance-stock-data"]
        if self.api_endpoints is None:
            self.api_endpoints = [
                "http://localhost:8080/api/kafka/health",
                "http://localhost:8081/api/v1/health",  # Airflow API
                "http://localhost:6379/ping"            # Redis API (ê°€ìƒ)
            ]

@dataclass
class WorkerStats:
    """ì›Œì»¤ í†µê³„"""
    worker_id: str
    worker_type: str
    success_count: int = 0
    error_count: int = 0
    total_messages: int = 0
    duration: float = 0.0
    throughput: float = 0.0
    errors: List[str] = None
    
    def __post_init__(self):
        if self.errors is None:
            self.errors = []

class KafkaLoadTester:
    """Kafka ë¶€í•˜í…ŒìŠ¤íŠ¸ í´ë˜ìŠ¤"""
    
    def __init__(self, config: LoadTestConfig):
        self.config = config
        self.results = []
        self.is_running = False
        self.start_time = None
        
    def generate_stock_message(self, worker_id: str, message_id: int) -> Dict:
        """ì£¼ì‹ ë°ì´í„° ë©”ì‹œì§€ ìƒì„±"""
        symbols = [
            'AAPL', 'MSFT', 'GOOGL', 'AMZN', 'TSLA', 'META', 'NVDA', 'NFLX',
            'AMD', 'INTC', 'CRM', 'ORCL', 'IBM', 'CSCO', 'QCOM'
        ]
        
        symbol = random.choice(symbols)
        base_price = random.uniform(100, 500)
        
        message = {
            'symbol': symbol,
            'price': round(base_price + random.uniform(-10, 10), 2),
            'volume': random.randint(1000, 1000000),
            'timestamp': time.time(),
            'datetime': datetime.now().isoformat(),
            'worker_id': worker_id,
            'message_id': message_id,
            'test_type': 'load_test',
            'change': round(random.uniform(-5, 5), 2),
            'change_percent': round(random.uniform(-10, 10), 2),
            # ê¸°ìˆ ì  ì§€í‘œ (ì‹œë®¬ë ˆì´ì…˜)
            'rsi': random.uniform(20, 80),
            'macd': random.uniform(-2, 2),
            'bb_upper': round(base_price * 1.05, 2),
            'bb_lower': round(base_price * 0.95, 2),
            # ì‹ í˜¸ ê°ì§€ (í™•ë¥  ê¸°ë°˜)
            'signal': self._generate_signal() if random.random() < self.config.signal_probability else None
        }
        
        return message
    
    def _generate_signal(self) -> Dict:
        """ì‹ í˜¸ ìƒì„±"""
        signal_types = [
            'bollinger_upper_touch', 'bollinger_lower_touch',
            'rsi_overbought', 'rsi_oversold',
            'macd_bullish_crossover', 'macd_bearish_crossover',
            'volume_spike', 'price_breakout'
        ]
        
        return {
            'type': random.choice(signal_types),
            'strength': random.uniform(0.5, 1.0),
            'timestamp': time.time()
        }
    
    def kafka_producer_worker(self, worker_id: str, topic: str, message_count: int) -> WorkerStats:
        """Kafka Producer ì›Œì»¤"""
        stats = WorkerStats(
            worker_id=f"producer_{worker_id}",
            worker_type="kafka_producer"
        )
        
        try:
            producer = KafkaProducer(
                bootstrap_servers=['localhost:9092'],
                value_serializer=lambda v: json.dumps(v).encode('utf-8'),
                retries=3,
                retry_backoff_ms=1000,
                compression_type='gzip',  # ì••ì¶• í™œì„±í™”
                batch_size=16384,        # ë°°ì¹˜ í¬ê¸° ìµœì í™”
                linger_ms=10             # ë°°ì¹˜ ëŒ€ê¸° ì‹œê°„
            )
            
            start_time = time.time()
            
            for i in range(message_count):
                if not self.is_running:
                    break
                    
                try:
                    message = self.generate_stock_message(worker_id, i)
                    
                    # ë©”ì‹œì§€ ì „ì†¡
                    future = producer.send(topic, message)
                    
                    # ë…¼ë¸”ë¡œí‚¹ìœ¼ë¡œ ê²°ê³¼ í™•ì¸ (ì„ íƒì )
                    if i % 100 == 0:  # 100ê°œë§ˆë‹¤ í™•ì¸
                        future.get(timeout=5)
                    
                    stats.success_count += 1
                    
                    # ì²˜ë¦¬ëŸ‰ ì¡°ì ˆ (CPU ë¶€í•˜ ë°©ì§€)
                    if i % 50 == 0:
                        time.sleep(0.01)
                        
                except KafkaError as e:
                    stats.error_count += 1
                    stats.errors.append(f"Kafka error: {str(e)}")
                    logger.error(f"Producer {worker_id} Kafka error: {e}")
                    
                except Exception as e:
                    stats.error_count += 1
                    stats.errors.append(f"General error: {str(e)}")
                    logger.error(f"Producer {worker_id} error: {e}")
            
            producer.flush(timeout=30)  # ëª¨ë“  ë©”ì‹œì§€ ì „ì†¡ ì™„ë£Œ ëŒ€ê¸°
            producer.close()
            
            end_time = time.time()
            stats.duration = end_time - start_time
            stats.total_messages = message_count
            stats.throughput = stats.success_count / stats.duration if stats.duration > 0 else 0
            
            logger.info(f"âœ… Producer {worker_id} ì™„ë£Œ: {stats.success_count}/{message_count}, {stats.throughput:.2f} msg/sec")
            
        except Exception as e:
            stats.error_count = message_count
            stats.errors.append(f"Worker initialization error: {str(e)}")
            logger.error(f"âŒ Producer {worker_id} ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        
        return stats
    
    def kafka_consumer_worker(self, worker_id: str, topic: str, timeout_seconds: int) -> WorkerStats:
        """Kafka Consumer ì›Œì»¤"""
        stats = WorkerStats(
            worker_id=f"consumer_{worker_id}",
            worker_type="kafka_consumer"
        )
        
        try:
            consumer = KafkaConsumer(
                topic,
                bootstrap_servers=['localhost:9092'],
                group_id=f'load_test_consumer_group_{worker_id}',
                value_deserializer=lambda m: json.loads(m.decode('utf-8')),
                auto_offset_reset='latest',
                enable_auto_commit=True,
                consumer_timeout_ms=1000  # 1ì´ˆ íƒ€ì„ì•„ì›ƒ
            )
            
            start_time = time.time()
            end_time = start_time + timeout_seconds
            
            while time.time() < end_time and self.is_running:
                try:
                    message_batch = consumer.poll(timeout_ms=500)
                    
                    for topic_partition, messages in message_batch.items():
                        for message in messages:
                            stats.success_count += 1
                            
                            # ë©”ì‹œì§€ ì²˜ë¦¬ ì‹œë®¬ë ˆì´ì…˜ (ì‹¤ì œë¡œëŠ” ì‹ í˜¸ ê°ì§€ ë“±)
                            if 'signal' in message.value and message.value['signal']:
                                logger.debug(f"Consumer {worker_id} ì‹ í˜¸ ê°ì§€: {message.value['signal']}")
                            
                            # ì²˜ë¦¬ ì‹œê°„ ì‹œë®¬ë ˆì´ì…˜
                            time.sleep(0.001)  # 1ms ì²˜ë¦¬ ì‹œê°„
                    
                except Exception as e:
                    stats.error_count += 1
                    stats.errors.append(f"Consumption error: {str(e)}")
                    logger.warning(f"Consumer {worker_id} error: {e}")
            
            consumer.close()
            
            stats.duration = time.time() - start_time
            stats.total_messages = stats.success_count + stats.error_count
            stats.throughput = stats.success_count / stats.duration if stats.duration > 0 else 0
            
            logger.info(f"âœ… Consumer {worker_id} ì™„ë£Œ: {stats.success_count} consumed, {stats.throughput:.2f} msg/sec")
            
        except Exception as e:
            stats.errors.append(f"Consumer initialization error: {str(e)}")
            logger.error(f"âŒ Consumer {worker_id} ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        
        return stats
    
    def api_call_worker(self, worker_id: str, endpoints: List[str], calls_per_endpoint: int) -> WorkerStats:
        """API í˜¸ì¶œ ì›Œì»¤ (BulkDataCollector ìŠ¤íƒ€ì¼)"""
        stats = WorkerStats(
            worker_id=f"api_{worker_id}",
            worker_type="api_caller"
        )
        
        session = requests.Session()
        session.timeout = 5
        
        start_time = time.time()
        
        try:
            for endpoint in endpoints:
                for i in range(calls_per_endpoint):
                    if not self.is_running:
                        break
                        
                    try:
                        # API í˜¸ì¶œ (ì‹¤ì œë¡œëŠ” yfinance, KIS API ë“±)
                        response = session.get(
                            endpoint,
                            timeout=5,
                            params={
                                'test': True,
                                'worker_id': worker_id,
                                'call_id': i
                            }
                        )
                        
                        if response.status_code == 200:
                            stats.success_count += 1
                        else:
                            stats.error_count += 1
                            stats.errors.append(f"HTTP {response.status_code}: {endpoint}")
                            
                    except requests.RequestException as e:
                        stats.error_count += 1
                        stats.errors.append(f"Request error: {str(e)}")
                        logger.warning(f"API Worker {worker_id} error: {e}")
                    
                    # API í˜¸ì¶œ ê°„ê²© (ì‹¤ì œë¡œëŠ” rate limiting)
                    time.sleep(0.1)
        
        except Exception as e:
            stats.errors.append(f"API worker error: {str(e)}")
            logger.error(f"âŒ API Worker {worker_id} ì „ì²´ ì‹¤íŒ¨: {e}")
        
        finally:
            session.close()
        
        stats.duration = time.time() - start_time
        stats.total_messages = stats.success_count + stats.error_count
        stats.throughput = stats.success_count / stats.duration if stats.duration > 0 else 0
        
        logger.info(f"âœ… API Worker {worker_id} ì™„ë£Œ: {stats.success_count}/{stats.total_messages}, {stats.throughput:.2f} calls/sec")
        
        return stats
    
    def run_load_test(self) -> Dict:
        """ì „ì²´ ë¶€í•˜í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
        logger.info("ğŸš€ Kafka + API ë¶€í•˜í…ŒìŠ¤íŠ¸ ì‹œì‘!")
        logger.info(f"âš™ï¸ ì„¤ì •: {self.config}")
        
        self.is_running = True
        self.start_time = time.time()
        
        # ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤ ëª¨ë‹ˆí„°ë§ ì‹œì‘
        system_stats = self._start_system_monitoring()
        
        # ì›Œì»¤ ìŠ¤ë ˆë“œ ì‹¤í–‰
        with concurrent.futures.ThreadPoolExecutor(max_workers=50) as executor:
            futures = []
            
            # 1. Kafka Producer ì›Œì»¤ë“¤
            for i in range(self.config.kafka_producer_workers):
                topic = self.config.topics[i % len(self.config.topics)]  # í† í”½ ìˆœí™˜
                future = executor.submit(
                    self.kafka_producer_worker,
                    f"prod_{i}",
                    topic,
                    self.config.messages_per_worker
                )
                futures.append(future)
            
            # 2. Kafka Consumer ì›Œì»¤ë“¤
            test_duration = self.config.duration_minutes * 60
            for i in range(self.config.kafka_consumer_workers):
                topic = self.config.topics[i % len(self.config.topics)]
                future = executor.submit(
                    self.kafka_consumer_worker,
                    f"cons_{i}",
                    topic,
                    test_duration
                )
                futures.append(future)
            
            # 3. API í˜¸ì¶œ ì›Œì»¤ë“¤
            calls_per_worker = 100  # ì›Œì»¤ë‹¹ API í˜¸ì¶œ ìˆ˜
            for i in range(self.config.api_call_workers):
                future = executor.submit(
                    self.api_call_worker,
                    f"api_{i}",
                    self.config.api_endpoints,
                    calls_per_worker
                )
                futures.append(future)
            
            # ì§€ì •ëœ ì‹œê°„ë§Œí¼ ì‹¤í–‰
            logger.info(f"â±ï¸ {self.config.duration_minutes}ë¶„ê°„ ì‹¤í–‰ ì¤‘...")
            time.sleep(self.config.duration_minutes * 60)
            
            # í…ŒìŠ¤íŠ¸ ì¢…ë£Œ
            self.is_running = False
            logger.info("ğŸ›‘ í…ŒìŠ¤íŠ¸ ì¢…ë£Œ ì‹ í˜¸ ì „ì†¡...")
            
            # ëª¨ë“  ì›Œì»¤ ì™„ë£Œ ëŒ€ê¸°
            for future in concurrent.futures.as_completed(futures, timeout=120):
                try:
                    result = future.result()
                    self.results.append(result)
                except Exception as e:
                    logger.error(f"ì›Œì»¤ ì‹¤í–‰ ì˜¤ë¥˜: {e}")
        
        # ì‹œìŠ¤í…œ ëª¨ë‹ˆí„°ë§ ì¢…ë£Œ
        final_system_stats = self._stop_system_monitoring(system_stats)
        
        # ê²°ê³¼ ì§‘ê³„
        summary = self._generate_test_summary(final_system_stats)
        
        logger.info("âœ… ë¶€í•˜í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
        logger.info(f"ğŸ“Š ê²°ê³¼ ìš”ì•½: {summary['total_messages']} ë©”ì‹œì§€, ì„±ê³µë¥  {summary['success_rate']:.1f}%")
        
        return summary
    
    def _start_system_monitoring(self) -> Dict:
        """ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤ ëª¨ë‹ˆí„°ë§ ì‹œì‘"""
        return {
            'start_cpu_percent': psutil.cpu_percent(),
            'start_memory': psutil.virtual_memory(),
            'start_time': time.time()
        }
    
    def _stop_system_monitoring(self, start_stats: Dict) -> Dict:
        """ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤ ëª¨ë‹ˆí„°ë§ ì¢…ë£Œ"""
        end_stats = {
            'end_cpu_percent': psutil.cpu_percent(),
            'end_memory': psutil.virtual_memory(),
            'end_time': time.time()
        }
        
        return {**start_stats, **end_stats}
    
    def _generate_test_summary(self, system_stats: Dict) -> Dict:
        """í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½ ìƒì„±"""
        total_success = sum(r.success_count for r in self.results)
        total_errors = sum(r.error_count for r in self.results)
        total_messages = total_success + total_errors
        
        # ì›Œì»¤ íƒ€ì…ë³„ ì§‘ê³„
        producer_results = [r for r in self.results if r.worker_type == 'kafka_producer']
        consumer_results = [r for r in self.results if r.worker_type == 'kafka_consumer']
        api_results = [r for r in self.results if r.worker_type == 'api_caller']
        
        summary = {
            'test_config': self.config,
            'total_duration': time.time() - self.start_time,
            'total_messages': total_messages,
            'total_success': total_success,
            'total_errors': total_errors,
            'success_rate': (total_success / total_messages * 100) if total_messages > 0 else 0,
            'overall_throughput': total_success / (time.time() - self.start_time),
            
            # ì›Œì»¤ë³„ í†µê³„
            'producer_stats': {
                'worker_count': len(producer_results),
                'avg_throughput': sum(r.throughput for r in producer_results) / len(producer_results) if producer_results else 0,
                'total_sent': sum(r.success_count for r in producer_results)
            },
            'consumer_stats': {
                'worker_count': len(consumer_results),
                'avg_throughput': sum(r.throughput for r in consumer_results) / len(consumer_results) if consumer_results else 0,
                'total_consumed': sum(r.success_count for r in consumer_results)
            },
            'api_stats': {
                'worker_count': len(api_results),
                'avg_throughput': sum(r.throughput for r in api_results) / len(api_results) if api_results else 0,
                'total_calls': sum(r.success_count for r in api_results)
            },
            
            # ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤
            'system_resources': {
                'avg_cpu_usage': (system_stats['start_cpu_percent'] + system_stats['end_cpu_percent']) / 2,
                'memory_used_gb': system_stats['end_memory'].used / (1024**3),
                'memory_percent': system_stats['end_memory'].percent
            },
            
            # ê°œë³„ ì›Œì»¤ ê²°ê³¼
            'worker_results': [
                {
                    'worker_id': r.worker_id,
                    'worker_type': r.worker_type,
                    'success_count': r.success_count,
                    'error_count': r.error_count,
                    'throughput': r.throughput,
                    'duration': r.duration,
                    'error_sample': r.errors[:3] if r.errors else []  # ì²« 3ê°œ ì˜¤ë¥˜ë§Œ
                }
                for r in self.results
            ]
        }
        
        return summary

def main():
    """ë©”ì¸ í•¨ìˆ˜ - CLI í…ŒìŠ¤íŠ¸ìš©"""
    import argparse
    
    parser = argparse.ArgumentParser(description="Kafka + API ë¶€í•˜í…ŒìŠ¤íŠ¸")
    parser.add_argument("--duration", type=int, default=5, help="í…ŒìŠ¤íŠ¸ ì§€ì†ì‹œê°„ (ë¶„)")
    parser.add_argument("--kafka-producers", type=int, default=10, help="Kafka Producer ì›Œì»¤ ìˆ˜")
    parser.add_argument("--kafka-consumers", type=int, default=5, help="Kafka Consumer ì›Œì»¤ ìˆ˜")
    parser.add_argument("--api-workers", type=int, default=4, help="API í˜¸ì¶œ ì›Œì»¤ ìˆ˜")
    parser.add_argument("--messages-per-worker", type=int, default=1000, help="ì›Œì»¤ë‹¹ ë©”ì‹œì§€ ìˆ˜")
    parser.add_argument("--topics", nargs='+', default=["realtime-stock", "yfinance-stock-data"], help="í…ŒìŠ¤íŠ¸ í† í”½ ëª©ë¡")
    
    args = parser.parse_args()
    
    # ì„¤ì • ìƒì„±
    config = LoadTestConfig(
        duration_minutes=args.duration,
        kafka_producer_workers=args.kafka_producers,
        kafka_consumer_workers=args.kafka_consumers,
        api_call_workers=args.api_workers,
        messages_per_worker=args.messages_per_worker,
        topics=args.topics
    )
    
    # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    tester = KafkaLoadTester(config)
    results = tester.run_load_test()
    
    # ê²°ê³¼ ì¶œë ¥
    print("\n" + "="*60)
    print("ğŸ“Š KAFKA + API ë¶€í•˜í…ŒìŠ¤íŠ¸ ê²°ê³¼")
    print("="*60)
    print(f"ì „ì²´ ë©”ì‹œì§€: {results['total_messages']:,}")
    print(f"ì„±ê³µ: {results['total_success']:,}")
    print(f"ì‹¤íŒ¨: {results['total_errors']:,}")
    print(f"ì„±ê³µë¥ : {results['success_rate']:.1f}%")
    print(f"ì „ì²´ ì²˜ë¦¬ëŸ‰: {results['overall_throughput']:.2f} msg/sec")
    print(f"í…ŒìŠ¤íŠ¸ ì‹œê°„: {results['total_duration']:.2f}ì´ˆ")
    print(f"CPU ì‚¬ìš©ë¥ : {results['system_resources']['avg_cpu_usage']:.1f}%")
    print(f"ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ : {results['system_resources']['memory_percent']:.1f}%")
    
    # ì›Œì»¤ë³„ í†µê³„
    print(f"\nğŸ“¤ Producer: {results['producer_stats']['total_sent']:,} sent, {results['producer_stats']['avg_throughput']:.2f} avg msg/sec")
    print(f"ğŸ“¥ Consumer: {results['consumer_stats']['total_consumed']:,} consumed, {results['consumer_stats']['avg_throughput']:.2f} avg msg/sec")
    print(f"ğŸŒ API: {results['api_stats']['total_calls']:,} calls, {results['api_stats']['avg_throughput']:.2f} avg calls/sec")

if __name__ == "__main__":
    main()
